[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaume Amores",
    "section": "",
    "text": "Hello, and welcome to my home page! I currently work as a Principal Data Scientist in Johnson Controls. I have been working on Data Science for more than 20 years, in both academia and industry. I received a Ph.D. in Machine Learning and Computer vision in 2006, and have been in industry for more than 10 years, working both as individual contributor and technical lead in multi-disciplinary teams. I enjoy both the theoretical and practical aspects of Data Science, I like developing high quality software based on best practices, and have experience generating intellectual property.\nApart from my work, I am a dad of a little child and I am interested in early childhood education and health. I intend to write about those subjects in my blog posts, above."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Jaume Amores",
    "section": "",
    "text": "Hello, and welcome to my home page! I currently work as a Principal Data Scientist in Johnson Controls. I have been working on Data Science for more than 20 years, in both academia and industry. I received a Ph.D. in Machine Learning and Computer vision in 2006, and have been in industry for more than 10 years, working both as individual contributor and technical lead in multi-disciplinary teams. I enjoy both the theoretical and practical aspects of Data Science, I like developing high quality software based on best practices, and have experience generating intellectual property.\nApart from my work, I am a dad of a little child and I am interested in early childhood education and health. I intend to write about those subjects in my blog posts, above."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jaume Amores",
    "section": "Education",
    "text": "Education\n\nPh.D. in Machine Learning and Computer Vision | Universitat Autonoma de Barcelona | 2006\nM.Sc. in Machine Learning and Computer Vision | Universitat Autonoma de Barcelona | 2003\nB.Sc. in Computer Science | Universitat de Valencia | 2000"
  },
  {
    "objectID": "index.html#open-source",
    "href": "index.html#open-source",
    "title": "Jaume Amores",
    "section": "Open Source",
    "text": "Open Source\nAt the moment I have published one open source library written in python, based on the nbdev+quarto publishing framework. I intend to publish more projects in the future.\n\nnbmodular: link Convert data science notebooks with poor modularity to fully modular notebooks that are automatically exported as python modules."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Hello and welcome to my blog posts. In this website I will be publishing a series of blogs, mostly on health, data science, early childhood education, and software engineering. The blogs will be originally mostly personal notes, which I intend to polish and extend during successive reviews."
  },
  {
    "objectID": "posts.html#introduction",
    "href": "posts.html#introduction",
    "title": "Posts",
    "section": "",
    "text": "Hello and welcome to my blog posts. In this website I will be publishing a series of blogs, mostly on health, data science, early childhood education, and software engineering. The blogs will be originally mostly personal notes, which I intend to polish and extend during successive reviews."
  },
  {
    "objectID": "posts.html#posts",
    "href": "posts.html#posts",
    "title": "Posts",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "posts/others/podcasts.html",
    "href": "posts/others/podcasts.html",
    "title": "Podcasts",
    "section": "",
    "text": "Note: this post is, at this moment, just a draft in progress.\nI have been a podcast and audio-book listener for the last few years. In this post, I would like to list and briefly describe the podcasts that I find interesting, and point to relevant sources."
  },
  {
    "objectID": "posts/others/podcasts.html#list-of-podcasts",
    "href": "posts/others/podcasts.html#list-of-podcasts",
    "title": "Podcasts",
    "section": "List of podcasts",
    "text": "List of podcasts\n\nGeneral\n\nLex Fridman Podcast: long-format (&gt;= 3h) interviews with interesting people of all types: literature, education, health, science, religion, politics… It started focusing on AI (the domain he is expert on), then expanded to science and software in general, then to everything. Very interesting guests IMO, most of them previously unknown by me.\nJoe Rogan Experience: Similar to Lex Fridman podcast. i found many interesting personalities in this podcast, and Joe has this capacity of making every conversation a fascinating one, and showing respect and interest towards points of view that are quite different from his own ones. However, there are few things that make me get away from it sometimes: he tends to bring many UFC fighters and comedians, which are the two things he is expert on. I like martial arts, but this high bias towards this type of guests is not ideal for me. He also tends to criticize previous guests when they are not there, even if he doesn’t do any criticism when the guest is there (at least not during the time I listen, sometimes I stop after one or two hours, and I should wait until the end to be sure about this).\n\n\n\nHealth\n\nHuberman Lab Podcast: mental and physical health, performance, and well-being in general. Dr. Andrew Huberman is a neuroscientist and professor at the Standford School of Medicine. This podcast combines interviews with guests, many of them well-known scientists and pioneers in their field, with discussions about where he covers specific topics that he and his team have been researching for the podcast.\nThe Peter Attia Drive Podcast: focused on latest research for increasing longevity, healthspan and lifespan. Dr. Peter Attia is the author of Outlive, and has a dedicated practice for studying and researching causes and solutions of age-related diseases, and how to stay healthy until the last years of our life.\nDr Chaterjee: mostly interviews with guests from the health sector, occasionally having well-known guests from other domains, usually with some relationship with health and well-being in general.\n\n\n\nEducation\n\nMr Barton Maths Podcast: education in mathematics (mostly secondary education), but extrapolable to education in general, as it talks about research in education, which in turn comes from fields such as neuroscience and psychology, and is applicable to many fields beyond mathematics.\n3blue1brown podcast: interviews, mostly with mathematicians. Even if you don’t like maths (which to be honest it is not something I’m really an expert on), i find the conversations very interesting, and amenable for non-mathematicians like myself.\n\n\n\nParenting\n\nRasing Good Humans: I listened to some of the episodes but still have to listen to more.\nParent-Driven Development: just listened to a couple of podcasts. Informal conversations with parents involved in technology and software in particular: how they teach their children, what strategies they use to keep a good work-life balance, etc.\n\n\n\nMisc.\n\nThe Rest is History: Great podcast about both recent and ancient history, with in-depth coverage of different curious and interesting events, personalities, and cultures.\nThe Rest is Money: I discovered this through the Rest is History. It is a different way to follow recent developments, here focused on the ones having impact on the economy.\nGlobal News Podcast from the BBC. It has two episodes per day, 30 min each."
  },
  {
    "objectID": "posts/education/index.html",
    "href": "posts/education/index.html",
    "title": "Education and Parenting",
    "section": "",
    "text": "Learning visually\n\n\nShort notes on learning by practice and visualization.\n\n\n\n\n\n\n\n\n\n\nParenting coach notes\n\n\n\n\n\n\n\n\n\n\n\n\n\nResources on Parenting & Early Childhood Education\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject-driven learning\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/education/learning_visually.html",
    "href": "posts/education/learning_visually.html",
    "title": "Learning visually",
    "section": "",
    "text": "I recently joined the amazing exercism community. Exercism is an online free coding platform that encourages learning programming languages through practice, free mentorship by volunteers, and exposure to similar solutions once our own solution has been submitted and passes the tests. Each exercise comes with associated learning material, which is a concise description of the concepts that are strictly required for attempting the exercise. However, the focus is always to encourage the students to learn through problem solving, while autonomously investigating the bits that are required. This follows closely recent research on education and neuroscience.\nI would like to share related thoughts on learning through practice, visual learning, and mathematics or related disciplines. The following are just short notes on this matter, that can serve both as a high-level roadmap to a potential long-term project, and contain some references that I would like to keep in mind and expand in the future.\nI found exercism to be a nicely designed platform that, being open source, could be extended to be applied to other domains beyond programming languages, and in particular to math problems. We could then use libraries to describe the problems visually, similar to what 3blue1brown does. By presenting math problems as both visual puzzles and in its original text form, we can make the problem more appealing, following the the ideas of Jo Boaler, e.g., in Mathematical mindsets, and visual mathematics. It would be nice if the student could manipulate the problem visually (i.e., manipulating and transforming the graphical elements with a mouse), and if the problem could be presented not only in 2D but also in 3D (using Virtual Reality, ideally), so that the student is able to also manipulate the objects in a sort-of “physical” world (be it through a game that emulates this world, or through gadgets like glasses and gloves, to have a better sensorial experience, although this would only be accessible by people able to buy those gadgets, unfortunately).\nMichael Nielsen has written very nice essays on these lines, under the title “Tools for Thought”. In particular, his essays Toward an exploratory medium for mathematics, Thought as a Technology, How can we develop transformative tools for thought? and Reinventing Explanation. Similar ideas are recently being developed by many scientists and educators and put in practice in journals such as Distill. I will be including those references in here as I find them, with a brief description, to serve as sources for the future."
  },
  {
    "objectID": "posts/health/agency_and_gratitude.html",
    "href": "posts/health/agency_and_gratitude.html",
    "title": "Agency and gratitude",
    "section": "",
    "text": "I would like to start contributing following the framework from Dr. Paul Conti. The basic idea is to do things that make me feel good and can help other people at the same time. This can be small things as:\n\nCommenting on interesting reads.\nContributing to open source: my personal project nbmodular, exercism, clojure data science community, and others.\nDo clojure pipeline ala dsblocks.\nReach out to people that are influencing me and ask them questions that may be of interest to others as well, e.g., in twitter, youtube, etc. Examples: David Sinclair, Andrew Huberman, and Peter Attia.\n\nHuberman: difficult task after tenacy task. Did they try to wait until drive/motivation/dopamine comes back to baseline (from the experimented valley)? Are the results as strong in that case? Idea basically is to separate the experiments for long time.\nSinclair: some of the suggested strategies require a lot of will power and tenacity. Do you know of mental strategies that can help us achieve those goals? Tricks such as drinking tea or coffee can be quite effective, but I wonder about strategies focused on dieting, which involve a large amount of tenacity.\nFast.ai: nbdev_export done, link to test tutorials, include examples / demos.\nFinish tenacity podcast and maybe re-listen Paul Conti podcasts book\nFor each X personal things, do one thing that may help (even just a bit) to the community. - Can be for my son - for others Try to find best strategy here, something that makes me feel good and works.\nPotential next project.\n\nLearn R language.\nApplied Statistics for Data Science: null hypothesis tests, etc.\nVisualization techniques and libraries: blogs, kaggle notebooks, other material.\n\nReveal.js / quarto notebooks.\n\nPapers discussed by Huberman, Attia and maybe Sinclair: analyze them from an statistics point of view and write a blog summarizing the findings. Have a list of blogs about this subject.\n\nPotential pitfalls, which ones are stronger from a statistics viewpoint.\nDo rating. Can even be a website with ratings / open review about this type of papers, automatic review that includes ChatGPT type of analysis, etc. With the AI piece we may be able to automatically find sources references and more context information (opinions, rebuttals, etc.) for these papers.\n\nFind kaggle projects, mostly focused on medicine, that can be good to participate in.\n\nAlso for Kaggle Days and social interaction.\n\nCommit myself to write a blog or something everytime I learn something, e.g., TIL like Simon Willison - see his github’s TIL"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html",
    "href": "posts/health/huberman_podcast_will_power.html",
    "title": "Tenacity and will power TIL",
    "section": "",
    "text": "This post is an in-progress Today-I-Learned (TIL) on the awesome Huberman podcast “How to Increase Tenacity & Will Power”"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html#introduction",
    "href": "posts/health/huberman_podcast_will_power.html#introduction",
    "title": "Tenacity and will power TIL",
    "section": "",
    "text": "This post is an in-progress Today-I-Learned (TIL) on the awesome Huberman podcast “How to Increase Tenacity & Will Power”"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html#short-notes-lessons-learned",
    "href": "posts/health/huberman_podcast_will_power.html#short-notes-lessons-learned",
    "title": "Tenacity and will power TIL",
    "section": "Short notes / lessons learned",
    "text": "Short notes / lessons learned\n\nExperts differ on whether Tenacity & Will Power are constant and limited in the individual. I interpret this as whether or not an individual is able to increase their maximum capacity of tenacity & will-power. If the answer is no, this means that each person can only have X amount of tenacity & will power, and nothing they do can increase this amount. That is not the same as saying that our tenacity & will power is constant and cannot change. It can increase throghout life through practice, but it cannot exceed a certain limit, which is fixed. It is this limit or upper bound what is fixed and cannot change.\nOn the previous topic, Dr. Huberman tends to lean towards the camp that, indeed, the maximum achievable Tenacity & Will Power is constant and cannot change.\nOne way of increasing Tenacity & Will Power is through exercise / practice. This means, in a nutshell, to do tasks that one doesn’t want to do, or, conversely don’t engage in activities or behaviours that one would like to engage in, and that are presumably unhealthy or not recommendable in some sense. Huberman informally refers to these tasks as micro-sucks, i.e., things that one doesn’t really feel like doing at some point, but that they are safe and, I interpret, not extremely challenging.\nBiological remarks:\n\nIncreasing testosterone seems to be related with increasing Tenacity & Will Power.\nThere is a specific region of the brain that is strongly associated with Tenacity & Will Power. The bigger this region grows, the more Tenacity & Will Power one has. So-called super-agers (or centenarians, as Dr. Attia calls them) tend to have such regions much bigger than the rest of people. And they tend to engage in activities that they would normally don’t feel like engaging in (at least at the beginning, e.g., things out of their comfort-zone and that they do not feel particularly inclined to do), and avoid unheatlhy or not-recommendable things that they normally desire. Another way of looking at this is that elderly people (in their 60s to 90s) that do not cease trying to improve, evolve, and explore unchartered and mildly not-attractive territories, show in some sense a strong desire of living longer while growing personally, and this usually translates into them living longer. It looks to me, to some extent, as a sort-of self-fulfilling wish."
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html",
    "href": "posts/health/tenacity_and_will_power.html",
    "title": "Tenacity and will power",
    "section": "",
    "text": "This post is just a series of short notes I wrote for myself, on general strategies to achieve tenacity / will power goals."
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html#introduction",
    "href": "posts/health/tenacity_and_will_power.html#introduction",
    "title": "Tenacity and will power",
    "section": "",
    "text": "This post is just a series of short notes I wrote for myself, on general strategies to achieve tenacity / will power goals."
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html#strategies",
    "href": "posts/health/tenacity_and_will_power.html#strategies",
    "title": "Tenacity and will power",
    "section": "Strategies",
    "text": "Strategies\nThese are the (evolving) strategies I would like to follow:\n\nClearly write goal objectives before trying. Dieting example: always write I will be eating that day,before eating. This is what I can eat today: menu with 2000 calories for example, 30% fat, 25% protein, 10% sugar.\n\nWrite down times: time when I start breakfast, and duration (end time). Time when I start lunch (if I do it), and duration (end time). Total eating window time (end lunch - beginning breakfast). It should always be lower than 8 hours. No snacks in between.\nWrite down all the coffees and teas, and their times.\nExtra: may be also the regular drinks (e.g., water), to see how this affects sleep.\nAt least something at coarse level, that has just a reasonable accuracy.\n\nDieting or other goals: Always write down what I have eaten (or whatever the goal was). That’s even more important than meeting objectives. I need to know, if I don’t meet them, why I haven’t and what could’ve done better or changed for meeting them. Write this down as well, every time.\n\nAbout writing down what I eat, it doesn’t need to be super-accurate. But at least something at coarse level, that has just a reasonable accuracy.\n\nSleep objectives. If I don’t meet them, what should I’ve done better, what subset of objectives (e.g., number of coffees) I didn’t meet and which strategies I could’ve followed to meet them. Always have empathy and kindness towards myself, not be harsh, but do not stop trying.\nBuy all the necessary wearables: sleep, glucose, lactose and maybe heart rate (because of its relantionship with will power).\nContinue reading, for instance papers about super-agers and how they get will power. Write down a blog summarizing my findings.\nIzan:\n\nwrite down notes from Anita and publish them.\nlook for strategies on savings, and publish them."
  },
  {
    "objectID": "posts/data_science/hello_world.html",
    "href": "posts/data_science/hello_world.html",
    "title": "Hello World AML pipeline with components",
    "section": "",
    "text": "In this section, we will write our code in a notebook and make sure it works well. Then, we will convert it to a script and run it from the terminal. Finally, we will add some logs with MLFlow.\nAlthough not required, as a very first step we can create a environment and kernel following the tutorial in https://learn.microsoft.com/en-gb/azure/machine-learning/tutorial-cloud-workstation?view=azureml-api-2\nFollowing the previous tutorial, create a notebook and type the following hello world code:\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\nhello_world (\"Jaume\")\n\nHello Jaume and world\n\n\nFantastic, the code works ;-). Now, let’s convert it to a script that can be run from terminal. The tutorial above explains how to convert the notebook to a python file. In our case, we will first add an argument parser and then write it to file using the magic cell %%writefile\n\n%%writefile hello_world_core.py\nimport argparse\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", type=str, help=\"person to greet\")\n    args = parser.parse_args()\n    \n    return args\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    hello_world (args.name)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_core.py\n\n\nNow, we can open up a terminal, as illustrated in the tutorial above, cd to the folder where the script is and run it:\ncd  Users/&lt;my_user&gt;/hello_world\npython hello_world_core.py --name Jaume\n\n\n\n%%writefile hello_world_with_logs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n\ndef start_logging (args):\n    # set name for logging\n    mlflow.set_experiment(\"Hello World with logging\")\n    mlflow.start_run()\n    mlflow.log_param (\"name to log\", args.name)\n    \ndef finish_logging ():\n    mlflow.end_run ()\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    args = parse_args ()\n    start_logging (args)\n    hello_world (args.name)\n    finish_logging ()\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_with_logs.py\n\n\nLet’s run it and see:\npython hello_world_with_logs.py --name Peter\nHere is the newly created job:\n\nAnd the name passed as argument:\n\nWe start by getting a connection to our Azure ML (AML for short) workspace. We use here a simple connection mechanism that doesn’t require writting your subscription, resource group and workspace details:\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "posts/data_science/hello_world.html#starting-development-with-a-notebook",
    "href": "posts/data_science/hello_world.html#starting-development-with-a-notebook",
    "title": "Hello World AML pipeline with components",
    "section": "",
    "text": "In this section, we will write our code in a notebook and make sure it works well. Then, we will convert it to a script and run it from the terminal. Finally, we will add some logs with MLFlow.\nAlthough not required, as a very first step we can create a environment and kernel following the tutorial in https://learn.microsoft.com/en-gb/azure/machine-learning/tutorial-cloud-workstation?view=azureml-api-2\nFollowing the previous tutorial, create a notebook and type the following hello world code:\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\nhello_world (\"Jaume\")\n\nHello Jaume and world\n\n\nFantastic, the code works ;-). Now, let’s convert it to a script that can be run from terminal. The tutorial above explains how to convert the notebook to a python file. In our case, we will first add an argument parser and then write it to file using the magic cell %%writefile\n\n%%writefile hello_world_core.py\nimport argparse\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", type=str, help=\"person to greet\")\n    args = parser.parse_args()\n    \n    return args\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    hello_world (args.name)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_core.py\n\n\nNow, we can open up a terminal, as illustrated in the tutorial above, cd to the folder where the script is and run it:\ncd  Users/&lt;my_user&gt;/hello_world\npython hello_world_core.py --name Jaume\n\n\n\n%%writefile hello_world_with_logs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n\ndef start_logging (args):\n    # set name for logging\n    mlflow.set_experiment(\"Hello World with logging\")\n    mlflow.start_run()\n    mlflow.log_param (\"name to log\", args.name)\n    \ndef finish_logging ():\n    mlflow.end_run ()\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    args = parse_args ()\n    start_logging (args)\n    hello_world (args.name)\n    finish_logging ()\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_with_logs.py\n\n\nLet’s run it and see:\npython hello_world_with_logs.py --name Peter\nHere is the newly created job:\n\nAnd the name passed as argument:\n\nWe start by getting a connection to our Azure ML (AML for short) workspace. We use here a simple connection mechanism that doesn’t require writting your subscription, resource group and workspace details:\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "posts/data_science/hello_world.html#running-script-as-a-job",
    "href": "posts/data_science/hello_world.html#running-script-as-a-job",
    "title": "Hello World AML pipeline with components",
    "section": "Running script as a job",
    "text": "Running script as a job\nWe now convert the previous script into a job that can be run from the UI.\n\nSetting connection\nFor the remaining part of this tutorial, we will be needing an ml_client handle. This will allow us to create and use resources from our workspace. The simplest way to get such handle is with the following code:\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\nSpecifying and submitting job\nWe specify a job using the command decorator:\n\nfrom azure.ai.ml import command\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Simplest Hello World\",\n)\n\n\nNote: we indicate as environment “AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest”, which actually contains more libraries than we need, such as sklearn. Simpler environments to use can be found in the “Environments” section of the workspace.\n\n… and submit it using create_or_update from ml_client:\n\nml_client.create_or_update(job)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nUploading hello_world (8.59 MBs): 100%|██████████| 8591281/8591281 [00:00&lt;00:00, 40584539.30it/s]\n\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nhello_world\nclever_spade_sq4jwcg67r\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nIn the link that appears, we can see the status of the job, which initially is “Queued”. We need to wait until it is completed (and refresh the page to see this). Once it is completed, we can look at the logs:\n\nIn the logs, we can see the messages printed in console:\n\n\n\nChanging the input\nAbove, we indicated a default value for the input argument name. It would be good to be able to submit jobs with different values for that argument. One way to do that is:\n\nIn the job’s Overview tab, click on “Edit and submit”\n\n\n\nIn the “Training script” section, edit the “Inputs” by clicking on the pencil next to it:\n\n\n\nIn the “Input value” field, type the new value you want for the argument:\n\n\n\nHit Next several times and then Submit.\nIf we go to the jobs section of the workspace, and enter again our job (“helloworld”), we can see that a new job has been submitted:\n\n\nIn its Overview tab, under “See all properties”, we can inspect the json file:\n\n… and see that the new value (Peter) is used in its “parameters” dictionary:\n\nThe std_log.txt for this job shows the new message with Peter:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#creating-single-component-pipeline",
    "href": "posts/data_science/hello_world.html#creating-single-component-pipeline",
    "title": "Hello World AML pipeline with components",
    "section": "Creating single component pipeline",
    "text": "Creating single component pipeline\n\nhello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.58 MBs): 100%|██████████| 8578531/8578531 [00:00&lt;00:00, 21700197.27it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\nfrom azure.ai.ml import dsl\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input,\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\n# Let's instantiate the pipeline with the parameters of our choice\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"David\",\n)\n\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_registered_components\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:08:19Z] Submitting 1 runs, first five are: 605cf9a7:d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6\n[2024-03-26 14:12:40Z] Completing processing run id d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6.\n\nExecution Summary\n=================\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\nAdding an input\n\nfrom azure.ai.ml import Input\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World witn Input\",\n)\n\nhello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8589758/8589758 [00:00&lt;00:00, 24178345.78it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\nfrom azure.ai.ml import dsl\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input,\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Joseph\",\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_input\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:38:43Z] Submitting 1 runs, first five are: cd1599c4:ce24c41e-946d-48cd-99b2-70ebde3befb2\n[2024-03-26 14:44:58Z] Completing processing run id ce24c41e-946d-48cd-99b2-70ebde3befb2.\n\nExecution Summary\n=================\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nNotes about Input:\n\nWhen using Input(type=“uri_folder”) or Input(type=“uri_file”), the value passed cannot be a string, it must be an Input type, for example:\n\njob = command(\n    inputs=dict(\n        file_name=Input (type=\"uri_file\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(path=\"/path/to/file\"),\n)\n\nHowever, when using Input(type=“string”) or Input(type=“number”), the input must be a string or number, not Input\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Mary\",\n)\n\nIn the latter case, the input does not appear in the graph of the pipeline, in the UI.\n\n\n\nUsing uri_file as input\n\n# Component definition and registration\njob = command(\n    inputs=dict(\n        name=Input (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with uri_file\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input,\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(type=\"uri_file\", path=\"./hello_world_core.py\"),\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8588206/8588206 [00:00&lt;00:00, 24482901.98it/s]\n\n\nUploading hello_world_core.py (&lt; 1 MB): 0.00B [00:00, ?B/s] (&lt; 1 MB): 100%|██████████| 514/514 [00:00&lt;00:00, 12.0kB/s]\n\n\n\n\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:06:11Z] Submitting 1 runs, first five are: a08118c5:2099b6ad-fb3a-4cac-9557-c8cf355b8b1b\n[2024-03-26 15:11:50Z] Completing processing run id 2099b6ad-fb3a-4cac-9557-c8cf355b8b1b.\n\nExecution Summary\n=================\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\nIf you click on the “Data” component and inside it click on “Explore”, you can see the contents of the file, since it is a text python file.\n\n\n\nAdding an output\n\nfrom azure.ai.ml import Output\n\n\n# Component definition and registration\njob = command(\n    outputs=dict(\n        name=Output (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{outputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with uri_file as output\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component()\n\npipeline = hello_world_pipeline()\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file_as_output\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (9.48 MBs): 100%|██████████| 9483085/9483085 [00:00&lt;00:00, 22969826.09it/s]\n\n\n\n\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:36:23Z] Submitting 1 runs, first five are: 528b20ac:27e32a0a-71a0-4bc3-abec-eaeae70ff08e\n[2024-03-26 15:41:30Z] Completing processing run id 27e32a0a-71a0-4bc3-abec-eaeae70ff08e.\n\nExecution Summary\n=================\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld"
  },
  {
    "objectID": "posts/data_science/hello_world.html#pipeline-with-two-components",
    "href": "posts/data_science/hello_world.html#pipeline-with-two-components",
    "title": "Hello World AML pipeline with components",
    "section": "Pipeline with two components",
    "text": "Pipeline with two components\nIn order to have something more meaningful, we create a pipeline with two components. The first one “pre-processes” the input data frame by adding one (or a specified number) to it, storing the output as a csv file. The second component builds a “model” by calculating the mean and standard deviation, and saves it as pickle file.\n\nmake subfolders and create dummy data\nWhenever we have multiple components, a common practice in Azure ML is to have a dedicated subfolder for each one. The subfolder contains the source .py file implementing the component, and may contain a conda yaml file with dependencies that are specific for this component. In our case, we use a pre-built environment so that we don’t need to include any conda yaml file.\n\nimport os\n\nos.makedirs (\"preprocessing\", exist_ok=True)\nos.makedirs (\"training\", exist_ok=True)\nos.makedirs (\"data\", exist_ok=True)\n\n\nimport pandas as pd\n\ndf = pd.DataFrame (\n    {\n        \"a\": [1,2,3],\n        \"b\": [4,5,6],\n    },\n)\n\ndf.to_csv (\"data/dummy_input.csv\")\n\n\n\npreprocessing component\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data frame\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data frame\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data,\n    x,\n    preprocessed_data,\n):\n    df = pd.read_csv (input_data)\n    df = preprocessing (df, args.x)\n    df.to_csv (preprocessed_data)\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (args.input_data, args.x, args.preprocessed_data)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\n# Component definition and registration\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_file\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\nUploading preprocessing (0.0 MBs): 100%|██████████| 993/993 [00:00&lt;00:00, 109270.22it/s]\n\n\n\n\n\n\ntraining component\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to preprocessed data\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    preprocessed_data,\n    model_path,\n):\n    df = pd.read_csv (preprocessed_data)\n    model = train_model (df)\n    joblib.dump (model_path)\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (args.preprocessed_data, args.model)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_file\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_file\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntry:\n    training_component = ml_client.create_or_update(training_command.component)\nexcept Exception as e:\n    print (e)\n\nUploading training (0.0 MBs): 100%|██████████| 923/923 [00:00&lt;00:00, 107564.19it/s]\n\n\n\n\nNotes:\n\nNote that the input to the training component is the output from the preprocessing component, and this is indicated in the command argument, where we say --preprocessed_data ${{preprocessing_component.outputs.preprocessed_data}}\nThe previous code fails because we cannot indicate uri_file as output from one component to the next one.\n\n\n\nalternative\n\n# Component definition and registration\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_file\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntry:\n    training_component = ml_client.create_or_update(training_command.component)\nexcept Exception as e:\n    print (e)\n\n{\n  \"result\": \"Failed\",\n  \"errors\": [\n    {\n      \"message\": \"Invalid data binding expression: preprocessing_component.outputs.preprocessed_data\",\n      \"path\": \"command\",\n      \"value\": \"python training.py --preprocessed_data ${{preprocessing_component.outputs.preprocessed_data}} --model ${{outputs.model}}\"\n    }\n  ]\n}\n\n\n\n\npipeline\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef two_components_pipeline(\n    pipeline_job_data_input,\n    pipeline_job_x,\n):\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\n\ntwo_components_pipeline = two_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n)\n\ntwo_components_pipeline_job = ml_client.jobs.create_or_update(\n    two_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_two_components_pipeline\",\n)\n\n# Pipeline running\nml_client.jobs.stream(two_components_pipeline_job.name)\n\nRunId: helpful_panda_s0cjx957fh\nWeb View: https://ml.azure.com/runs/helpful_panda_s0cjx957fh?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 16:34:39Z] Submitting 1 runs, first five are: 78ed9672:be3e3ff7-e099-4b2e-8d47-ca6235673370\n[2024-03-26 16:36:14Z] Execution of experiment failed, update experiment status and cancel running nodes.\n\nExecution Summary\n=================\nRunId: helpful_panda_s0cjx957fh\nWeb View: https://ml.azure.com/runs/helpful_panda_s0cjx957fh?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\nJobException: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /preprocessing_job. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus2\",\n    \"location\": \"eastus2\",\n    \"time\": \"2024-03-26T16:36:14.233106Z\",\n    \"component_name\": \"\"\n} \n\n\n\nExecution failed. User process 'python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n  File \"preprocessing.py\", line 32, in &lt;module&gt;\n    main()\n  File \"preprocessing.py\", line 27, in main\n    df = pd.read_csv (args.input_data)\nNameError: name 'pd' is not defined"
  },
  {
    "objectID": "posts/health/index.html",
    "href": "posts/health/index.html",
    "title": "Health",
    "section": "",
    "text": "Tenacity and will power\n\n\nPotential strategies\n\n\n\n\n\n\n\n\n\n\nTenacity and will power TIL\n\n\nLessons from Huberman podcast\n\n\n\n\n\n\n\n\n\n\nHealthspan and lifespan\n\n\nPhysical health: resources and protocols\n\n\n\n\n\n\n\n\n\n\nAgency and gratitude\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/health/physical_health.html",
    "href": "posts/health/physical_health.html",
    "title": "Healthspan and lifespan",
    "section": "",
    "text": "Findings regarding best protocols on health."
  },
  {
    "objectID": "posts/health/physical_health.html#sleep",
    "href": "posts/health/physical_health.html#sleep",
    "title": "Healthspan and lifespan",
    "section": "Sleep",
    "text": "Sleep\n\nThe single most important thing seems to be sleeping well, close to eight hours per day.\nCoffee, while having its benefits, needs to be avoided from noon. Ideally, the latest coffee should be taken no later than twelve hours before going to sleep."
  },
  {
    "objectID": "posts/health/physical_health.html#nutrition",
    "href": "posts/health/physical_health.html#nutrition",
    "title": "Healthspan and lifespan",
    "section": "Nutrition",
    "text": "Nutrition\n\nFasting\n\nIntermitent fasting. Specifically, time-restricted fasting, although there are other appropriate forms of intermitent fasting.\nFasting up to one week, three times per year, with keto diet the week before and the week after.\n\nIf fasting is done for more than three days, we might have our sleep affected. To avoid that, we need to take some supplements. I need to find their name.\n\nFasting for up to 48 hours once per month.\n\n\n\nDiet: plant-based with fish\n\nSpecifically, salmon and other blue fishes rich in omega-3\nIt seems to be slightly better than a pure vegan diet, which in turn is better than a meat-based western diet."
  },
  {
    "objectID": "posts/health/physical_health.html#nutrition-to-keep-guts-microbiome-healthy.",
    "href": "posts/health/physical_health.html#nutrition-to-keep-guts-microbiome-healthy.",
    "title": "Healthspan and lifespan",
    "section": "Nutrition to keep gut’s microbiome healthy.",
    "text": "Nutrition to keep gut’s microbiome healthy."
  },
  {
    "objectID": "posts/health/physical_health.html#exercise",
    "href": "posts/health/physical_health.html#exercise",
    "title": "Healthspan and lifespan",
    "section": "Exercise",
    "text": "Exercise\n\nCardio\n\nCardio seems to be the most important exercise of all.\nIn order to avoid removing the benefits of doing cardio, we need to stay on stand-up position at least 50% of the day, rather than sitting. For office jobs, a standing desk is advisable.\nCardio can be done by running, using air-bike, or using stairs, among others.\nWe need to arrive to Zone 2, several days per week. A proxy for this is to achieve the maximum intensity while still being able to keep a conversation while doing the exercise.\nWe need to have a high-intensity exercise at least 10 minutes? (I need to check this) per week. This is exercise would be the next level to zone 2, i.e., not being able to have a conversation while doing it.\n\n\nAvoiding injuries while running\n\nWarmup before running: exercises.\nStrecth after running: exercises\nDo knee exercises\nStart running progressively: plan"
  },
  {
    "objectID": "posts/education/parenting_coach.html",
    "href": "posts/education/parenting_coach.html",
    "title": "Parenting coach notes",
    "section": "",
    "text": "Note: this post is just a draft in progress. As of now, it consists of a collection of random notes.\nSome months ago we started to attend parenting coach sessions that would help us learn a suit of strategies for early-childhood parenting that we would like to apply to our son, who is three years old at the moment. This post summarizes some of these strategies and other lessons gathered from those sessions."
  },
  {
    "objectID": "posts/education/parenting_coach.html#following-a-routine",
    "href": "posts/education/parenting_coach.html#following-a-routine",
    "title": "Parenting coach notes",
    "section": "Following a routine",
    "text": "Following a routine\n“I see to it that my child does the following:”\n\n\n\nIn the morning\nIn the evening\n\n\n\n\nDress up\nWash hands\n\n\nGo to the car\nTidy up\n\n\n…\nHave dinner"
  },
  {
    "objectID": "posts/education/parenting_coach.html#general-guidelines",
    "href": "posts/education/parenting_coach.html#general-guidelines",
    "title": "Parenting coach notes",
    "section": "General guidelines",
    "text": "General guidelines\n\nPrevention is better than cure. For instance, if we see that the child might do something wrong, instead of waiting and checking if they actually end up doing it, we might avoid it altogether.\nAvoid non-positive attention-seeking mechanisms. For instance, when asking the child to dress-up, it is important to not ask it repeatedly, or otherwise they might just not do it as a way of obtaining a type of attention that we don’t want to encourage, in which case they might happily ignore our request and expect us to be paying this attention continuously. Instead, a better strategy is to say something like “While you dress up I will be getting ready myself. If you have any difficulties while dressing up, please let me know and I can help you, but I would like to see that you try to do it by yourself first”. It is very important that, even when things are a bit challenging, they are encouraged to try them a few times before seeking help."
  },
  {
    "objectID": "posts/education/parenting_coach.html#q-a",
    "href": "posts/education/parenting_coach.html#q-a",
    "title": "Parenting coach notes",
    "section": "Q & A",
    "text": "Q & A\nTo better reflect the parenting sessions, each one of the discussed topics is placed in a separate a sub-section, and within it we write a Q & A expressed as a dialogue between parents and coach. Parent questions or observations are indicated with P while coach responses with C.\n\nHitting\n\nP: My child is hitting me a lot lately. It seems as if he doesn’t control his emotions.\nC: When this happens, the first thing we need to ask is whether something changed at school or in other domain that might have affected him in some way.\nP: He’s not saying anything, nor his teachers. We are concerned that we wouldn’t notice if something happened at school. One reason for that concern is that all the staff has recently changed and the new staff is not communicating so much.\nC: If he had a behaviour issue, your teachers would certainly tell you. (Then I remember that one teacher told me about one event when our son pushed another kid). I wouldn’t worry about that.\nC: Regarding your initial question, you need to set your boundaries early in the day. Something like “I’m not going to allow you to hit me anymore”. Say it in an “I love you” manner. Use the last example when that happened. We tell him that this is ok because it happened yesterday (for example), so he feels safe when we talk about this. Then we can say something like “I don’t want that because it hurts me.”\n\nThen, if we see the child is going to hit us, we need to stop him/her before that happens (note for self: this falls under the “prevention is better than cure” general guideline, mentioned above). While we stop him, we can say something like - “Hang on, remember we spoke about this early today? I’m not going to allow you to hit me.”\nIf the child stops trying to hit, then we can the following type of dialogue (just an example situation) with our child:\n- What is it that you need?\n- I want to have yoghurt!\n- Hang on, I see. Let's talk about that without hitting. When was the last time you had one?\n- I had it this morning.\n- That's great, you can have it tomorrow morning.\nThis type of dialogue makes the child learn to rationalize cause and effect.\nThe previous dialogue can happen if the child stops to trying to hit. However, they don’t stop, it is better that we leave the room so that they don’t get the opportunity to do it. We say that we are going to leave because we don’t want to allow them to hit us. By doing so we are not allowing the negativity of the behaviour to last for long time.\n\n\nChild talking bad about school\nP: Our son always talks in a negative way about school.\nC: First of all, we have to be careful that there’s nothing concerning at school. Tell the teachers about his feeling and see what they say about this. After that, we also need to be careful to not be continuously asking our child whether or not he had a good day or, more specifically, if there was any issue at school that day. Especially, we need to avoid asking about in a way that provides an image of us being concerned. This might make our child feel uncomfortable, like investigated, and this doesn’t help them having an honest and open communication.\nInstead of that we could simply ask something general like “how was your day” and, after they respond, we can say something like “Let me tell you how was my day” so that they don’t feel the conversation is just about them or about investigating if there was any issue that day.\nRather than investigating on potential negative things, it’s better to talk about positive things. We can ask what activities he had or what games he played and then ask specific details about those (“What was this painting about?” “Do you remember what colors did you use?” or “What animals there were in that jig-saw?” This helps them practice and strengthen their memory, something especially important at early ages."
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html",
    "href": "posts/education/resources_early_childhood_education.html",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "",
    "text": "The following provides a compact listing about resources and material I found interesting, on both parenting and early childhood education. This includes books, blogs, and podcasts. The intent is to make use of those resources, plus notes collectedfrom our parenting coach, as a source of material for subsequent posts on the topic of parenting and early childhood education. Some of the books are still in my to-read list, which I indicate by an un-checked box. Books in the “in-progress” list are colored in purple, and they are left unchecked if I read just a few chapters."
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#parenting",
    "href": "posts/education/resources_early_childhood_education.html#parenting",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Parenting",
    "text": "Parenting\n\nBooks\n\nThe Whole-Brain Child: 12 Revolutionary Strategies to Nurture Your Child’s Developing Mind by Daniel J. Siegel and Tina Payne Bryson\nBrain Rules for Baby (Updated and Expanded): How to Raise a Smart and Happy Baby Child from Zero to Five by John Medina\nHow Children Succeed: Grit, Curiosity, and the Hidden Power of Character by Paul Tough\nHow to Talk So Kids Will Listen & Listen So Kids Will Talk by Adele Faber and Elaine Mazlish\nNo-Drama Discipline. The Whole-Brain Way to Calm the Chaos and Nurture Your Child’s Developing Mind by Daniel J. Siegel and Tina Payne Bryson\nParenting from the Inside Out. How A Deeper Self-Understanding Can Help You Raise Children Who Thrive by Daniel J. Siegel and Mary Hartzell\nHow To Get Kids To Say Yes!: Using the Secret Four Color Languages to Get Kids to Listen by\n\n\n\nBlogs and websites\n\n50 OF THE BEST BOOKS FOR PARENTS\nPathways\nResources from Erikson Institute"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#early-childhood-education",
    "href": "posts/education/resources_early_childhood_education.html#early-childhood-education",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Early Childhood Education",
    "text": "Early Childhood Education\n\nBooks\n\nWhere’s the Math? Books, Games, and Routines to Spark Children’s Thinking\nTools of the Mind: The Vygotskian Approach to Early Childhood Education (2nd Edition) by elena Bodrova and Deorah J. Leong\nWho Am I in the Lives of Children? An Introduction to Early Childhood Education (10th Edition) by Stephanie Feeney and Eva Moravick\nMind in the Making: The Seven Essential Life Skills Every Child Needs by Ellen Galinsky\nThe Complete Resource Book for Preschoolers: Over 2000 Activities and Ideas (Complete Resource Series) by Pam Schiller and Kay Hastings\n\n\n\nBlogs and websites\n\nEarly Math Collaborative from Erikson Institute\nTHE 40 BEST BOOKS ON EARLY CHILDHOOD EDUCATION"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#general-education",
    "href": "posts/education/resources_early_childhood_education.html#general-education",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "General Education",
    "text": "General Education\n\nMath Education\n\nBooks\n\nHow I Wish I’d Taught Maths: Lessons learned from research, conversations with experts, and 12 years of mistakes: Reflections on research, conversations with experts, and 12 years of mistakes.\nMathematics for human flourishing\nMathematical mindsets\nChange Is the Only Constant: The Wisdom of Calculus in a Madcap World\nMath with bad drawings\n\n\n\nBlogs and websites\n\n3Blue1Brown"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#learning-to-learn",
    "href": "posts/education/resources_early_childhood_education.html#learning-to-learn",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Learning to learn",
    "text": "Learning to learn\n\nBooks\n\nMake It Stick: The Science of Successful Learning by Henry L. Roediger III, Mark A. McDaniel, Peter C. Brown\n\n\n\nBlogs and websites\n\nTechniques for Efficiently Learning Programming Languages. Despite the title, this post provides many useful tips for learning to learn in general.\nRecommendations about how to learn mathematics in an enjoyable way"
  },
  {
    "objectID": "posts/education/project_driven_learning.html",
    "href": "posts/education/project_driven_learning.html",
    "title": "Project-driven learning",
    "section": "",
    "text": "Note: this post is, at this moment, just a draft in progress.\nThe idea of writing this post came initially as a sort-of response / contribution to the excellent essay from Daniel Higginbotham entitled Techniques for Efficiently Learning Programming Languages. Despite the title of the essay, the ideas inside are very much generic for learning to learn basically anything. I will be adding a slighly new perspective which incorporates a “project-driven” approach to learning. This idea is not novel, and can be applied either in conjunction or as an alternative to the ideas expressed in post by D. Higginbotham, depending on what our final goals are. I will also use ideas such as Exploration vs Exploitation from the field of Reinforcement Learning, which I will be explaning for anyone not familiar in this field.\nThe gist of project-based learning is to focus our learning journey on those things that will prove to be important in our daily practice or life in general. It is motivated in part by the fact that, many times, when we learn a new field, e.g., in college, we study many concepts that we will never be using or needing in anyway, and end up completely forgotten. To be more concrete, let us take the field of mathematics as an example.\nGiven the vast amount of things that are actually interesting and relevant for our lives, this approach can be considered sub-optimal in many cases, making us waste a lot of time on topics that are not even connected to those parts that are relevant to us. Having said that, as I explore in this post, it all depends on what the final goal in our learning adventure. For this, I will be using a framework based on the Exploration vs Exploitation trade-off from Reinforcement Learning.\nThe gist of it is that, many times, when we start a learning"
  },
  {
    "objectID": "posts/others/index.html",
    "href": "posts/others/index.html",
    "title": "Other topics",
    "section": "",
    "text": "Podcasts\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]