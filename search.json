[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Hello and welcome to my blog posts. In this website I will be publishing a series of blogs, mostly on health, data science, early childhood education, and software engineering. The blogs will be originally mostly personal notes, which I intend to polish and extend during successive reviews."
  },
  {
    "objectID": "posts.html#introduction",
    "href": "posts.html#introduction",
    "title": "Posts",
    "section": "",
    "text": "Hello and welcome to my blog posts. In this website I will be publishing a series of blogs, mostly on health, data science, early childhood education, and software engineering. The blogs will be originally mostly personal notes, which I intend to polish and extend during successive reviews."
  },
  {
    "objectID": "posts.html#posts",
    "href": "posts.html#posts",
    "title": "Posts",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html",
    "href": "posts/data_science/playing_with_mlflow.html",
    "title": "Playing with MLflow",
    "section": "",
    "text": "# Standard imports\nimport os\n\n# Third-party imports\nimport pandas as pd\nimport numpy as np\n\n# AML imports\nfrom azure.ai.ml import command, MLClient\nfrom azure.identity import DefaultAzureCredential\n\n\n\n\n### Multiple-metric and dataset imports\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_curve, classification_report\nimport matplotlib.pyplot as plt\n\nimport mlflow\nfrom mlflow.entities import Metric\nfrom mlflow.tracking import MlflowClient\nfrom mlflow.models import infer_signature"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#initial-imports",
    "href": "posts/data_science/playing_with_mlflow.html#initial-imports",
    "title": "Playing with MLflow",
    "section": "",
    "text": "# Standard imports\nimport os\n\n# Third-party imports\nimport pandas as pd\nimport numpy as np\n\n# AML imports\nfrom azure.ai.ml import command, MLClient\nfrom azure.identity import DefaultAzureCredential\n\n\n\n\n### Multiple-metric and dataset imports\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_curve, classification_report\nimport matplotlib.pyplot as plt\n\nimport mlflow\nfrom mlflow.entities import Metric\nfrom mlflow.tracking import MlflowClient\nfrom mlflow.models import infer_signature"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#connecting",
    "href": "posts/data_science/playing_with_mlflow.html#connecting",
    "title": "Playing with MLflow",
    "section": "Connecting",
    "text": "Connecting\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#logging-details",
    "href": "posts/data_science/playing_with_mlflow.html#logging-details",
    "title": "Playing with MLflow",
    "section": "Logging details",
    "text": "Logging details\nFirst experiment: see why the MLflow job created by hello world notebook does not log code, etc. I assume this is because we need to use command and create a job through to the ml_client, as explained in the hello world notebook, under section running script as a job:\n\n%%writefile hello_world_with_logs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n\ndef start_logging (args):\n    # set name for logging\n    mlflow.set_experiment(\"Hello World with logging\")\n    mlflow.start_run()\n    mlflow.log_param (\"name to log\", args.name)\n    \ndef finish_logging ():\n    mlflow.end_run ()\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    args = parse_args ()\n    start_logging (args)\n    hello_world (args.name)\n    finish_logging ()\n\nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_with_logs.py\n\n\n\n# configure job\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_with_logs.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with logging and job\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nFound the config file in: /config.json\nUploading data_science (12.66 MBs): 100%|██████████| 12658976/12658976 [00:00&lt;00:00, 18557482.88it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\njolly_malanga_wgt7b8mb36\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\nIn the previous example there is one error: it seems that we cannot indicate an experiment name unless it is the same as the one indicated in the command function. Since we didn’t indicate any experiment name in that function, we try to do it now:\n\n\nFixing error\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_with_logs.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with logging and job\",\n    experiment_name=\"Hello World with logging\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nUploading data_science (12.66 MBs): 100%|██████████| 12664739/12664739 [00:00&lt;00:00, 18366160.15it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nHello World with logging\njoyful_brick_2zb5xmvktl\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\n\nResult\n\nA job is created with experiment name “Hello world with logging” and latest job name “Hello World with logging and job”, which is the display_name indicated in the command function (see screenshot below)\nBoth code and logs are stored as part of this job.\n\n\n\n-"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#logging-experiments",
    "href": "posts/data_science/playing_with_mlflow.html#logging-experiments",
    "title": "Playing with MLflow",
    "section": "Logging experiments",
    "text": "Logging experiments\nLinks:\nhttps://mlflow.org/docs/2.0.0/tracking.html#logging-functions\nhttps://mlflow.org/docs/2.0.0/tracking.html#managing-experiments-and-runs-with-the-tracking-service-api\n\n%%writefile hello_world_experiments.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    for idx, name in enumerate(names):\n        mlflow.create_experiment (str(idx))\n        mlflow.start_run()\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_experiments.py\n\n\n\n# Standard imports\nimport os\n\n# Third-party imports\nimport pandas as pd\n\n# AML imports\nfrom azure.ai.ml import command, MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_experiments.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with experiments\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nFound the config file in: /config.json\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nUploading data_science (12.75 MBs): 100%|██████████| 12749662/12749662 [00:00&lt;00:00, 15505064.12it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\nwitty_glove_syh5ltdkh6\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\n\nA job “Hello World with experiments” is created under the experiment name “data_science”. It seems this is the default name of the experiment if we don’t indicate in the command function (see screenshot)\n\n\n\nThe job has code and logs registered"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#start_run-receives-experiment",
    "href": "posts/data_science/playing_with_mlflow.html#start_run-receives-experiment",
    "title": "Playing with MLflow",
    "section": "start_run receives experiment",
    "text": "start_run receives experiment\n\n%%writefile hello_world_experiments.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    for idx, name in enumerate(names):\n        experiment = mlflow.create_experiment (str(idx))\n        mlflow.start_run(experiment)\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_experiments.py\n\n\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_experiments.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with experiments 2\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nUploading data_science (12.73 MBs): 100%|██████████| 12725904/12725904 [00:00&lt;00:00, 16250029.70it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\ngood_helmet_wgcgzlvs99\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\nThis experiment failed, since the call to mlflow.start_run (experiment) is incorrect. The correct call is mlflow.start_run(experiment_id=experiment_id)"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#start_run-receives-under-experiment_id-name",
    "href": "posts/data_science/playing_with_mlflow.html#start_run-receives-under-experiment_id-name",
    "title": "Playing with MLflow",
    "section": "start_run receives under experiment_id name",
    "text": "start_run receives under experiment_id name\n\n%%writefile hello_world_experiments_id.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    for idx, name in enumerate(names):\n        experiment_id = mlflow.create_experiment (str(idx))\n        mlflow.start_run(experiment_id=experiment_id)\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_experiments_id.py\n\n\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_experiments_id.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with experiment_id\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nUploading data_science (12.74 MBs): 100%|██████████| 12741018/12741018 [00:02&lt;00:00, 5305432.15it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\nlime_snail_kdddyl016h\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\nThe code is uploaded to an experiment called “data_science”. This experiment makes use of the first parameter value: name=\"John\". The remaining experiments (1, and 2), are created separately for parameter values \"Mary\" and \"Ana\", without code being uploaded to them."
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#using-separate-runs-instead",
    "href": "posts/data_science/playing_with_mlflow.html#using-separate-runs-instead",
    "title": "Playing with MLflow",
    "section": "using separate runs instead",
    "text": "using separate runs instead\n\n%%writefile hello_world_runs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    experiment_id = mlflow.create_experiment(\"experiment1\")\n    for idx, name in enumerate(names):\n        mlflow.start_run(run_name=str(idx), experiment_id=experiment_id)\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_runs.py\n\n\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_runs.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with runs\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nUploading data_science (12.75 MBs): 100%|██████████| 12749252/12749252 [00:00&lt;00:00, 18741643.65it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\nolive_shelf_r4fzsl1f0d\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\n\nTwo runs are created under a job with experiment name “experiment1” and latest_job name 1 and 2: \nThe metric values for these can be compared using graphics:\n\n\n\nThere is still a job created under experiment name data_science. This job contains result of using first parameter value, code and logs. But it cannot be compared."
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#separate-runs-experiment-in-command",
    "href": "posts/data_science/playing_with_mlflow.html#separate-runs-experiment-in-command",
    "title": "Playing with MLflow",
    "section": "Separate runs + experiment in command",
    "text": "Separate runs + experiment in command\n\n%%writefile hello_world_runs_command.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    for idx, name in enumerate(names):\n        mlflow.start_run(run_name=str(idx))\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_runs_command.py\n\n\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_runs_command.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    experiment_name=\"hw_runs_command\",\n    display_name=\"Hello World with runs + command\",\n)\n\n# submit job\nml_client.create_or_update(job)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nUploading data_science (17.09 MBs): 100%|██████████| 17092597/17092597 [00:00&lt;00:00, 23325862.31it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nhw_runs_command\njolly_bone_c07ncly80l\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult\n\nWe have the three runs under the same experiment, and we can compare their metrics:"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#logging-images",
    "href": "posts/data_science/playing_with_mlflow.html#logging-images",
    "title": "Playing with MLflow",
    "section": "Logging images",
    "text": "Logging images\n\n%%writefile hello_world_images.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\nimport matplotlib.pyplot as plt\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    names = [\"John\", \"Mary\", \"Ana\"]\n    for idx, name in enumerate(names):\n        mlflow.start_run(run_name=str(idx))\n        mlflow.log_param (\"name to log\", name)\n        mlflow.log_metric (\"length\", len(name))\n        \n        fig, ax = plt.subplots()\n        ax.plot([0+10*len(name), 1+10*len(name)], [2+10*len(name), 3+10*len(name)])\n        mlflow.log_figure(fig, f\"figure_{idx}.png\")\n        \n        mlflow.end_run ()\n        hello_world (name)\n    \nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_images.py\n\n\n\n# configure job\njob = command(\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_images.py\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    experiment_name=\"hw_images\",\n    display_name=\"Hello World with images\",\n)\n\njob.settings.default_compute = \"jaumecpu\"\n\n# submit job\nml_client.create_or_update(job)\n\nWarnings: [settings: Unknown field.]\nWarnings: [settings: Unknown field.]\nUploading data_science (16.39 MBs): 100%|██████████| 16392540/16392540 [00:01&lt;00:00, 14278614.03it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nhw_images\nshy_island_fh9jg0r6nf\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\nResult"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#using-interactive",
    "href": "posts/data_science/playing_with_mlflow.html#using-interactive",
    "title": "Playing with MLflow",
    "section": "Using interactive",
    "text": "Using interactive\n\n# Set the experiment\nmlflow.set_experiment(\"mlflow-interactive-4\")\n\nnames = [\"John\", \"Mary\", \"Ana\"]\nfor idx, name in enumerate(names):\n    mlflow.start_run(run_name=str(idx)+\"-bis-2\")\n    mlflow.log_param (\"name to log\", name)\n    mlflow.log_metric (\"length\", len(name))\n\n    fig, ax = plt.subplots()\n    ax.plot([0+10*len(name), 1+10*len(name)], [2+10*len(name), 3+10*len(name)])\n    mlflow.log_figure(fig, f\"figure_{idx}.png\")\n\n    mlflow.end_run ()\n\n2024/06/04 09:05:04 INFO mlflow.tracking.fluent: Experiment with name 'mlflow-interactive-4' does not exist. Creating a new experiment."
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#multiple-metrics",
    "href": "posts/data_science/playing_with_mlflow.html#multiple-metrics",
    "title": "Playing with MLflow",
    "section": "Multiple metrics",
    "text": "Multiple metrics\n\nmlflow.set_experiment(\"multiple-metrics\")\nclient = MlflowClient()\n\nnames = [\"John\", \"Mary\", \"Ana\"]\nfor idx, name in enumerate(names):\n    current_run = mlflow.start_run(run_name=str(idx)+\"-bis-2\")\n    mlflow.log_param (\"name to log\", name)\n    mlflow.log_metric (\"length\", len(name))\n    \n    list_to_log = np.array([1, 2, 3, 2, 1, 2, 3, 2, 1])+len(name)*1000\n\n    client.log_batch(\n        current_run.info.run_id, \n        metrics=[\n            Metric(key=\"sample_list\", value=val, timestamp=int(time.time() * 1000), step=0) \n            for val in list_to_log\n        ]\n    )\n\n    fig, ax = plt.subplots()\n    ax.plot(np.array([1,2,4,8,16,32,64,128]) + len(name)*1000)\n    mlflow.log_figure(fig, f\"figure_{idx}.png\")\n\n    mlflow.end_run ()"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#using-dataset",
    "href": "posts/data_science/playing_with_mlflow.html#using-dataset",
    "title": "Playing with MLflow",
    "section": "Using dataset",
    "text": "Using dataset\n\nauto-log, not using evaluate\n\n\nwithout set_experiment or run\n\n# enable autologging\nmlflow.autolog()\n\n# read data\ndataset_source_url = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\ndf = pd.read_csv(dataset_source_url, delimiter=\";\")\n\n# split data\ny = df[\"quality\"]\nX = df.drop(\"quality\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=17\n)\n\n# train model\nmodel = RandomForestClassifier ()\nmodel.fit (X_train, y_train)\n\n# evaluate\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nprint('Accuracy:', acc)\n\n2024/06/04 13:32:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2024/06/04 13:32:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '79f7182e-22da-49bc-9ffb-5d4d3ab19172', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n2024/06/04 13:32:14 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Cannot log the same dataset with different context', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '8bf21ee6ca6b0a22621d463962cdb6c7', 'request': 'bb3b9eee5cc179d2'}, 'Environment': 'eastus2', 'Location': 'eastus2', 'Time': '2024-06-04T13:32:14.3398324+00:00', 'ComponentName': 'mlflow', 'statusCode': 400, 'error_code': 'BAD_REQUEST'}\n\n\nAccuracy: 0.6611008039579468\n\n\n\n\nwith set_experiment or run\n\nmlflow.set_experiment(\"auto-log-diabetes\")\ncurrent_run = mlflow.start_run(run_name=\"single-run\")\n    \n# enable autologging\nmlflow.autolog()\n\n# read data\ndataset_source_url = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\ndf = pd.read_csv(dataset_source_url, delimiter=\";\")\n\n# split data\ny = df[\"quality\"]\nX = df.drop(\"quality\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=17\n)\n\n# train model\nmodel = RandomForestClassifier ()\nmodel.fit (X_train, y_train)\n\n# evaluate\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nprint('Accuracy:', acc)\n\nmlflow.end_run()\n\n2024/06/04 13:42:27 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n2024/06/04 13:42:34 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Cannot log the same dataset with different context', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '2ca9d0147eefa2c27982cd511b017688', 'request': '0c999aaf8b0221f2'}, 'Environment': 'eastus2', 'Location': 'eastus2', 'Time': '2024-06-04T13:42:34.8823005+00:00', 'ComponentName': 'mlflow', 'statusCode': 400, 'error_code': 'BAD_REQUEST'}\n\n\nAccuracy: 0.6635745207173779\n\n\n\n\nwith evaluate\n\nmlflow.set_experiment(\"auto-log-evaluate\")\ncurrent_run = mlflow.start_run(run_name=\"single-run\")\n    \n# enable autologging\nmlflow.autolog()\n\n# read data\ndataset_source_url = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\ndf = pd.read_csv(dataset_source_url, delimiter=\";\")\n\n# split data\ny = df[\"quality\"]\nX = df.drop(\"quality\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=17\n)\n\n\n# train model\nmodel = RandomForestClassifier ()\nmodel.fit (X_train, y_train)\n\n# evaluate\ny_hat = model.predict(X_test)\n\n# --------------------------------------\neval_data = X_test\neval_data[\"label\"] = y_test\n\n# Assign the decoded predictions to the Evaluation Dataset\neval_data[\"predictions\"] = y_hat\n\n# Create the PandasDataset for use in mlflow evaluate\npd_dataset = mlflow.data.from_pandas(\n    eval_data, predictions=\"predictions\", targets=\"label\"\n)\nresult = mlflow.evaluate(data=pd_dataset, predictions=None, model_type=\"classifier\")\n#result = mlflow.evaluate(model=model, predictions=None, model_type=\"classifier\")\n# -------------------------------------\n\n\n\nwith shap, extra metrics, and multiple runs\n\nmlflow.end_run()\ndef f1_at_70 (eval_df, _builtin_metrics):\n    precision, recall, thresholds = precision_recall_curve (eval_df[\"target\"], eval_df[\"prediction\"])\n    thresholds = np.append (thresholds, values=1.0)\n    threshold=thresholds[precision&gt;0.7]\n    metrics = classification_report (y_test, y_hat&gt;threshold, output_dict=True)\n    return metrics['1']['f1-score']\n\nf1_at_70_metric = mlflow.models.make_metric(\n    eval_fn=f1_at_70,\n    greater_is_better=True,\n)\n\nmlflow.set_experiment(\"shap-extra-many-runs-17\")\n\n# enable autologging\nmlflow.autolog()\n# read data\ndataset_source_url = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\ndf = pd.read_csv(dataset_source_url, delimiter=\";\")\n\n# split data\ny = df[\"quality\"]\nX = df.drop(\"quality\", axis=1)\n\nX = X[(y==6) | (y==5)]\ny = y[(y==6) | (y==5)]\ny[y==6]=1\ny[y==5]=0\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=17\n)\n\n# hp\nn_estimators_values = [25, 50, 100, 200]\n\nfor idx, n_estimators in enumerate (n_estimators_values):\n    current_run = mlflow.start_run(run_name=f\"run_{idx}\")\n\n    # train model\n    model = RandomForestClassifier (n_estimators=n_estimators)\n    model.fit (X_train, y_train)\n\n    # evaluate\n    #y_hat = model.predict_proba(X_test)[:, 1]\n\n    # --------------------------------------\n    eval_data = X_test.copy()\n    eval_data[\"label\"] = y_test\n\n    # Assign the decoded predictions to the Evaluation Dataset\n    #eval_data[\"predictions\"] = y_hat\n\n    # Create the PandasDataset for use in mlflow evaluate\n    pd_dataset = mlflow.data.from_pandas(\n        eval_data, \n        #predictions=\"predictions\", \n        targets=\"label\", \n        source=dataset_source_url, \n        name=\"wine-quality-white-bis\", \n    )\n    #result = mlflow.evaluate(data=pd_dataset, predictions=None, model_type=\"classifier\", extra_metrics=[f1_at_70_metric])\n    signature = infer_signature(X_test, model.predict(X_test))\n    model_info = mlflow.sklearn.log_model(sk_model=model, artifact_path=\"model\", signature=signature)\n    sklearn_pyfunc = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n    result = mlflow.evaluate(model=sklearn_pyfunc, data=pd_dataset, predictions=None, model_type=\"classifier\", extra_metrics=[f1_at_70_metric])\n    # -------------------------------------\n\n\n    mlflow.end_run()\n\n2024/06/04 17:22:15 INFO mlflow.tracking.fluent: Experiment with name 'shap-extra-many-runs-17' does not exist. Creating a new experiment.\n2024/06/04 17:22:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/data/dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv'. Exception: \n  return _dataset_source_registry.resolve(\n2024/06/04 17:22:21 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'Cannot log the same dataset with different context', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': '0ed9f77ef26119702d55b364f4936aba', 'request': '21f226dd00f8e20d'}, 'Environment': 'eastus2', 'Location': 'eastus2', 'Time': '2024-06-04T17:22:21.5642691+00:00', 'ComponentName': 'mlflow', 'statusCode': 400, 'error_code': 'BAD_REQUEST'}\n\n\nException: UserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/requirements.txt already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/python_env.yaml already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/model.pkl already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/conda.yaml already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/MLmodel already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/metadata/requirements.txt already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/metadata/python_env.yaml already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/metadata/conda.yaml already exists.\nUserError: Resource Conflict: ArtifactId ExperimentRun/dcid.4631baa7-0c38-4f37-ae4c-c02d11d7a8db/model/metadata/MLmodel already exists.\n\n\n\n mlflow.evaluate?\n\n\nSignature:\nmlflow.evaluate(\n    model=None,\n    data=None,\n    *,\n    model_type=None,\n    targets=None,\n    predictions=None,\n    dataset_path=None,\n    feature_names=None,\n    evaluators=None,\n    evaluator_config=None,\n    custom_metrics=None,\n    extra_metrics=None,\n    custom_artifacts=None,\n    validation_thresholds=None,\n    baseline_model=None,\n    env_manager='local',\n    model_config=None,\n    baseline_config=None,\n    inference_params=None,\n)\nDocstring:\nEvaluate the model performance on given data and selected metrics.\nThis function evaluates a PyFunc model or custom callable on the specified dataset using\nspecified ``evaluators``, and logs resulting metrics & artifacts to MLflow tracking server.\nUsers can also skip setting ``model`` and put the model outputs in ``data`` directly for\nevaluation. For detailed information, please read\n:ref:`the Model Evaluation documentation &lt;model-evaluation&gt;`.\nDefault Evaluator behavior:\n - The default evaluator, which can be invoked with ``evaluators=\"default\"`` or\n   ``evaluators=None``, supports model types listed below. For each pre-defined model type, the\n   default evaluator evaluates your model on a selected set of metrics and generate artifacts\n   like plots. Please find more details below.\n - For both the ``\"regressor\"`` and ``\"classifier\"`` model types, the default evaluator\n   generates model summary plots and feature importance plots using\n   `SHAP &lt;https://shap.readthedocs.io/en/latest/index.html&gt;`_.\n - For regressor models, the default evaluator additionally logs:\n    - **metrics**: example_count, mean_absolute_error, mean_squared_error,\n      root_mean_squared_error, sum_on_target, mean_on_target, r2_score, max_error,\n      mean_absolute_percentage_error.\n - For binary classifiers, the default evaluator additionally logs:\n    - **metrics**: true_negatives, false_positives, false_negatives, true_positives, recall,\n      precision, f1_score, accuracy_score, example_count, log_loss, roc_auc,\n      precision_recall_auc.\n    - **artifacts**: lift curve plot, precision-recall plot, ROC plot.\n - For multiclass classifiers, the default evaluator additionally logs:\n    - **metrics**: accuracy_score, example_count, f1_score_micro, f1_score_macro, log_loss\n    - **artifacts**: A CSV file for \"per_class_metrics\" (per-class metrics includes\n      true_negatives/false_positives/false_negatives/true_positives/recall/precision/roc_auc,\n      precision_recall_auc), precision-recall merged curves plot, ROC merged curves plot.\n - For question-answering models, the default evaluator logs:\n    - **metrics**: ``exact_match``, ``token_count``, `toxicity`_ (requires `evaluate`_,\n      `torch`_, `flesch_kincaid_grade_level`_ (requires `textstat`_) and `ari_grade_level`_.\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in tabular format.\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For text-summarization models, the default evaluator logs:\n    - **metrics**: ``token_count``, `ROUGE`_ (requires `evaluate`_, `nltk`_, and\n      `rouge_score`_ to be installed), `toxicity`_ (requires `evaluate`_, `torch`_,\n      `transformers`_), `ari_grade_level`_ (requires `textstat`_),\n      `flesch_kincaid_grade_level`_ (requires `textstat`_).\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in the tabular format.\n    .. _ROUGE:\n        https://huggingface.co/spaces/evaluate-metric/rouge\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _nltk:\n        https://pypi.org/project/nltk\n    .. _rouge_score:\n        https://pypi.org/project/rouge-score\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For text models, the default evaluator logs:\n    - **metrics**: ``token_count``, `toxicity`_ (requires `evaluate`_, `torch`_,\n      `transformers`_), `ari_grade_level`_ (requires `textstat`_),\n      `flesch_kincaid_grade_level`_ (requires `textstat`_).\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in tabular format.\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For retriever models, the default evaluator logs:\n    - **metrics**: :mod:`precision_at_k(k) &lt;mlflow.metrics.precision_at_k&gt;`,\n      :mod:`recall_at_k(k) &lt;mlflow.metrics.recall_at_k&gt;` and\n      :mod:`ndcg_at_k(k) &lt;mlflow.metrics.ndcg_at_k&gt;` - all have a default value of\n      ``retriever_k`` = 3.\n    - **artifacts**: A JSON file containing the inputs, outputs, targets, and per-row metrics\n      of the model in tabular format.\n - For sklearn models, the default evaluator additionally logs the model's evaluation criterion\n   (e.g. mean accuracy for a classifier) computed by `model.score` method.\n - The metrics/artifacts listed above are logged to the active MLflow run.\n   If no active run exists, a new MLflow run is created for logging these metrics and\n   artifacts. Note that no metrics/artifacts are logged for the ``baseline_model``.\n - Additionally, information about the specified dataset - hash, name (if specified), path\n   (if specified), and the UUID of the model that evaluated it - is logged to the\n   ``mlflow.datasets`` tag.\n - The available ``evaluator_config`` options for the default evaluator include:\n    - **log_model_explainability**: A boolean value specifying whether or not to log model\n      explainability insights, default value is True.\n    - **explainability_algorithm**: A string to specify the SHAP Explainer algorithm for model\n      explainability. Supported algorithm includes: 'exact', 'permutation', 'partition',\n      'kernel'.\n      If not set, ``shap.Explainer`` is used with the \"auto\" algorithm, which chooses the best\n      Explainer based on the model.\n    - **explainability_nsamples**: The number of sample rows to use for computing model\n      explainability insights. Default value is 2000.\n    - **explainability_kernel_link**: The kernel link function used by shap kernal explainer.\n      Available values are \"identity\" and \"logit\". Default value is \"identity\".\n    - **max_classes_for_multiclass_roc_pr**:\n      For multiclass classification tasks, the maximum number of classes for which to log\n      the per-class ROC curve and Precision-Recall curve. If the number of classes is\n      larger than the configured maximum, these curves are not logged.\n    - **metric_prefix**: An optional prefix to prepend to the name of each metric and artifact\n      produced during evaluation.\n    - **log_metrics_with_dataset_info**: A boolean value specifying whether or not to include\n      information about the evaluation dataset in the name of each metric logged to MLflow\n      Tracking during evaluation, default value is True.\n    - **pos_label**: If specified, the positive label to use when computing classification\n      metrics such as precision, recall, f1, etc. for binary classification models. For\n      multiclass classification and regression models, this parameter will be ignored.\n    - **average**: The averaging method to use when computing classification metrics such as\n      precision, recall, f1, etc. for multiclass classification models\n      (default: ``'weighted'``). For binary classification and regression models, this\n      parameter will be ignored.\n    - **sample_weights**: Weights for each sample to apply when computing model performance\n      metrics.\n    - **col_mapping**: A dictionary mapping column names in the input dataset or output\n      predictions to column names used when invoking the evaluation functions.\n    - **retriever_k**: A parameter used when ``model_type=\"retriever\"`` as the number of\n      top-ranked retrieved documents to use when computing the built-in metric\n      :mod:`precision_at_k(k) &lt;mlflow.metrics.precision_at_k&gt;`,\n      :mod:`recall_at_k(k) &lt;mlflow.metrics.recall_at_k&gt;` and\n      :mod:`ndcg_at_k(k) &lt;mlflow.metrics.ndcg_at_k&gt;`. Default value is 3. For all other\n      model types, this parameter will be ignored.\n - Limitations of evaluation dataset:\n    - For classification tasks, dataset labels are used to infer the total number of classes.\n    - For binary classification tasks, the negative label value must be 0 or -1 or False, and\n      the positive label value must be 1 or True.\n - Limitations of metrics/artifacts computation:\n    - For classification tasks, some metric and artifact computations require the model to\n      output class probabilities. Currently, for scikit-learn models, the default evaluator\n      calls the ``predict_proba`` method on the underlying model to obtain probabilities. For\n      other model types, the default evaluator does not compute metrics/artifacts that require\n      probability outputs.\n - Limitations of default evaluator logging model explainability insights:\n    - The ``shap.Explainer`` ``auto`` algorithm uses the ``Linear`` explainer for linear models\n      and the ``Tree`` explainer for tree models. Because SHAP's ``Linear`` and ``Tree``\n      explainers do not support multi-class classification, the default evaluator falls back to\n      using the ``Exact`` or ``Permutation`` explainers for multi-class classification tasks.\n    - Logging model explainability insights is not currently supported for PySpark models.\n    - The evaluation dataset label values must be numeric or boolean, all feature values\n      must be numeric, and each feature column must only contain scalar values.\n - Limitations when environment restoration is enabled:\n    - When environment restoration is enabled for the evaluated model (i.e. a non-local\n      ``env_manager`` is specified), the model is loaded as a client that invokes a MLflow\n      Model Scoring Server process in an independent Python environment with the model's\n      training time dependencies installed. As such, methods like ``predict_proba`` (for\n      probability outputs) or ``score`` (computes the evaluation criterian for sklearn models)\n      of the model become inaccessible and the default evaluator does not compute metrics or\n      artifacts that require those methods.\n    - Because the model is an MLflow Model Server process, SHAP explanations are slower to\n      compute. As such, model explainaibility is disabled when a non-local ``env_manager``\n      specified, unless the ``evaluator_config`` option **log_model_explainability** is\n      explicitly set to ``True``.\nArgs:\n    model: Optional. If specified, it should be one of the following:\n        - A pyfunc model instance\n        - A URI referring to a pyfunc model\n        - A URI referring to an MLflow Deployments endpoint e.g. ``\"endpoints:/my-chat\"``\n        - A callable function: This function should be able to take in model input and\n          return predictions. It should follow the signature of the\n          :py:func:`predict &lt;mlflow.pyfunc.PyFuncModel.predict&gt;` method. Here's an example\n          of a valid function:\n          ..code-block:: python\n              model = mlflow.pyfunc.load_model(model_uri)\n              def fn(model_input):\n                  return model.predict(model_input)\n        If omitted, it indicates a static dataset will be used for evaluation instead of a\n        model.  In this case, the ``data`` argument must be a Pandas DataFrame or an mlflow\n        PandasDataset that contains model outputs, and the ``predictions`` argument must be the\n        name of the column in ``data`` that contains model outputs.\n    data: One of the\n        following:\n        - A numpy array or list of evaluation features, excluding labels.\n        - A Pandas DataFrame containing evaluation features, labels, and optionally model\n            outputs. Model outputs are required to be provided when model is unspecified.\n            If ``feature_names`` argument not specified, all columns except for the label\n            column and model_output column are regarded as feature columns. Otherwise,\n            only column names present in ``feature_names`` are regarded as feature columns.\n        -  A Spark DataFrame containing evaluation features and labels. If\n            ``feature_names`` argument not specified, all columns except for the label\n            column are regarded as feature columns. Otherwise, only column names present in\n            ``feature_names`` are regarded as feature columns. Only the first 10000 rows in\n            the Spark DataFrame will be used as evaluation data.\n        - A :py:class:`mlflow.data.dataset.Dataset` instance containing evaluation\n            features, labels, and optionally model outputs. Model outputs are only supported\n            with a PandasDataset. Model outputs are required when model is unspecified, and\n            should be specified via the ``predictions`` prerty of the PandasDataset.\n    targets: If ``data`` is a numpy array or list, a numpy array or list of evaluation\n        labels. If ``data`` is a DataFrame, the string name of a column from ``data``\n        that contains evaluation labels. Required for classifier and regressor models,\n        but optional for question-answering, text-summarization, and text models. If\n        ``data`` is a :py:class:`mlflow.data.dataset.Dataset` that defines targets,\n        then ``targets`` is optional.\n    predictions: Optional. The name of the column that contains model outputs.\n        - When ``model`` is specified and outputs multiple columns, ``predictions`` can be used\n          to specify the name of the column that will be used to store model outputs for\n          evaluation.\n        - When ``model`` is not specified and ``data`` is a pandas dataframe,\n          ``predictions`` can be used to specify the name of the column in ``data`` that\n          contains model outputs.\n        .. code-block:: python\n            :caption: Example usage of predictions\n            # Evaluate a model that outputs multiple columns\n            data = pd.DataFrame({\"question\": [\"foo\"]})\n            def model(inputs):\n                return pd.DataFrame({\"answer\": [\"bar\"], \"source\": [\"baz\"]})\n            results = evaluate(model=model, data=data, predictions=\"answer\", ...)\n            # Evaluate a static dataset\n            data = pd.DataFrame({\"question\": [\"foo\"], \"answer\": [\"bar\"], \"source\": [\"baz\"]})\n            results = evaluate(data=data, predictions=\"answer\", ...)\n    model_type: (Optional) A string describing the model type. The default evaluator\n        supports the following model types:\n        - ``'classifier'``\n        - ``'regressor'``\n        - ``'question-answering'``\n        - ``'text-summarization'``\n        - ``'text'``\n        - ``'retriever'``\n        If no ``model_type`` is specified, then you must provide a a list of\n        metrics to compute via the ``extra_metrics`` param.\n        .. note::\n            ``'question-answering'``, ``'text-summarization'``, ``'text'``, and\n            ``'retriever'`` are experimental and may be changed or removed in a\n            future release.\n    inference_params: (Optional) A dictionary of inference parameters to be passed to the model\n        when making predictions, such as ``{\"max_tokens\": 100}``. This is only used when\n        the ``model`` is an MLflow Deployments endpoint URI e.g. ``\"endpoints:/my-chat\"``\n    dataset_path: (Optional) The path where the data is stored. Must not contain double\n        quotes (``“``). If specified, the path is logged to the ``mlflow.datasets``\n        tag for lineage tracking purposes.\n    feature_names: (Optional) A list. If the ``data`` argument is a numpy array or list,\n        ``feature_names`` is a list of the feature names for each feature. If\n        ``feature_names=None``, then the ``feature_names`` are generated using the\n        format ``feature_{feature_index}``. If the ``data`` argument is a Pandas\n        DataFrame or a Spark DataFrame, ``feature_names`` is a list of the names\n        of the feature columns in the DataFrame. If ``feature_names=None``, then\n        all columns except the label column and the predictions column are\n        regarded as feature columns.\n    evaluators: The name of the evaluator to use for model evaluation, or a list of\n        evaluator names. If unspecified, all evaluators capable of evaluating the\n        specified model on the specified dataset are used. The default evaluator\n        can be referred to by the name ``\"default\"``. To see all available\n        evaluators, call :py:func:`mlflow.models.list_evaluators`.\n    evaluator_config: A dictionary of additional configurations to supply to the evaluator.\n        If multiple evaluators are specified, each configuration should be\n        supplied as a nested dictionary whose key is the evaluator name.\n    extra_metrics:\n        (Optional) A list of :py:class:`EvaluationMetric &lt;mlflow.models.EvaluationMetric&gt;`\n        objects.  These metrics are computed in addition to the default metrics associated with\n        pre-defined `model_type`, and setting `model_type=None` will only compute the metrics\n        specified in `extra_metrics`. See the `mlflow.metrics` module for more information about\n        the builtin metrics and how to define extra metrics.\n        .. code-block:: python\n            :caption: Example usage of extra metrics\n            import mlflow\n            import numpy as np\n            def root_mean_squared_error(eval_df, _builtin_metrics):\n                return np.sqrt((np.abs(eval_df[\"prediction\"] - eval_df[\"target\"]) ** 2).mean)\n            rmse_metric = mlflow.models.make_metric(\n                eval_fn=root_mean_squared_error,\n                greater_is_better=False,\n            )\n            mlflow.evaluate(..., extra_metrics=[rmse_metric])\n    custom_artifacts:\n        (Optional) A list of custom artifact functions with the following signature:\n        .. code-block:: python\n            def custom_artifact(\n                eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],\n                builtin_metrics: Dict[str, float],\n                artifacts_dir: str,\n            ) -&gt; Dict[str, Any]:\n                \"\"\"\n                Args:\n                    eval_df:\n                        A Pandas or Spark DataFrame containing ``prediction`` and ``target``\n                        column.  The ``prediction`` column contains the predictions made by the\n                        model.  The ``target`` column contains the corresponding labels to the\n                        predictions made on that row.\n                    builtin_metrics:\n                        A dictionary containing the metrics calculated by the default evaluator.\n                        The keys are the names of the metrics and the values are the scalar\n                        values of the metrics. Refer to the DefaultEvaluator behavior section\n                        for what metrics will be returned based on the type of model (i.e.\n                        classifier or regressor).\n                    artifacts_dir:\n                        A temporary directory path that can be used by the custom artifacts\n                        function to temporarily store produced artifacts. The directory will be\n                        deleted after the artifacts are logged.\n                Returns:\n                    A dictionary that maps artifact names to artifact objects\n                    (e.g. a Matplotlib Figure) or to artifact paths within ``artifacts_dir``.\n                \"\"\"\n                ...\n        Object types that artifacts can be represented as:\n            - A string uri representing the file path to the artifact. MLflow will infer the\n              type of the artifact based on the file extension.\n            - A string representation of a JSON object. This will be saved as a .json artifact.\n            - Pandas DataFrame. This will be resolved as a CSV artifact.\n            - Numpy array. This will be saved as a .npy artifact.\n            - Matplotlib Figure. This will be saved as an image artifact. Note that\n              ``matplotlib.pyplot.savefig`` is called behind the scene with default\n              configurations.\n              To customize, either save the figure with the desired configurations and return\n              its file path or define customizations through environment variables in\n              ``matplotlib.rcParams``.\n            - Other objects will be attempted to be pickled with the default protocol.\n        .. code-block:: python\n            :caption: Example usage of custom artifacts\n            import mlflow\n            import matplotlib.pyplot as plt\n            def scatter_plot(eval_df, builtin_metrics, artifacts_dir):\n                plt.scatter(eval_df[\"prediction\"], eval_df[\"target\"])\n                plt.xlabel(\"Targets\")\n                plt.ylabel(\"Predictions\")\n                plt.title(\"Targets vs. Predictions\")\n                plt.savefig(os.path.join(artifacts_dir, \"example.png\"))\n                plt.close()\n                return {\"pred_target_scatter\": os.path.join(artifacts_dir, \"example.png\")}\n            def pred_sample(eval_df, _builtin_metrics, _artifacts_dir):\n                return {\"pred_sample\": pred_sample.head(10)}\n            mlflow.evaluate(..., custom_artifacts=[scatter_plot, pred_sample])\n    validation_thresholds: (Optional) A dictionary of metric name to\n        :py:class:`mlflow.models.MetricThreshold` used for model validation. Each metric name\n        must either be the name of a builtin metric or the name of a metric defined in the\n        ``extra_metrics`` parameter.\n        .. code-block:: python\n            :caption: Example of Model Validation\n            from mlflow.models import MetricThreshold\n            thresholds = {\n                \"accuracy_score\": MetricThreshold(\n                    # accuracy should be &gt;=0.8\n                    threshold=0.8,\n                    # accuracy should be at least 5 percent greater than baseline model accuracy\n                    min_absolute_change=0.05,\n                    # accuracy should be at least 0.05 greater than baseline model accuracy\n                    min_relative_change=0.05,\n                    greater_is_better=True,\n                ),\n            }\n            with mlflow.start_run():\n                mlflow.evaluate(\n                    model=your_candidate_model,\n                    data,\n                    targets,\n                    model_type,\n                    dataset_name,\n                    evaluators,\n                    validation_thresholds=thresholds,\n                    baseline_model=your_baseline_model,\n                )\n        See :ref:`the Model Validation documentation &lt;model-validation&gt;`\n        for more details.\n    baseline_model: (Optional) A string URI referring to an MLflow model with the pyfunc\n        flavor. If specified, the candidate ``model`` is compared to this\n        baseline for model validation purposes.\n    env_manager: Specify an environment manager to load the candidate ``model`` and\n        ``baseline_model`` in isolated Python environments and restore their\n        dependencies. Default value is ``local``, and the following values are\n        supported:\n        - ``virtualenv``: (Recommended) Use virtualenv to restore the python\n          environment that was used to train the model.\n        - ``conda``:  Use Conda to restore the software environment that was used\n          to train the model.\n        - ``local``: Use the current Python environment for model inference, which\n          may differ from the environment used to train the model and may lead to\n          errors or invalid predictions.\n    model_config: the model configuration to use for loading the model with pyfunc. Inspect\n        the model's pyfunc flavor to know which keys are supported for your\n        specific model. If not indicated, the default model configuration\n        from the model is used (if any).\n    baseline_config: the model configuration to use for loading the baseline\n        model. If not indicated, the default model configuration\n        from the baseline model is used (if any).\nReturns:\n    An :py:class:`mlflow.models.EvaluationResult` instance containing\n    metrics of candidate model and baseline model, and artifacts of candidate model.\nFile:      /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/models/evaluation/base.py\nType:      function\n\n\n\n\n%debug\n\n&gt; /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py(95)_check_targets()\n     93 \n     94     if len(y_type) &gt; 1:\n---&gt; 95         raise ValueError(\n     96             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n     97                 type_true, type_pred\n\n{'binary', 'continuous'}\n     59 def _check_targets(y_true, y_pred):\n     60     \"\"\"Check that y_true and y_pred belong to the same classification task.\n     61 \n     62     This converts multiclass or binary types to a common shape, and raises a\n     63     ValueError for a mix of multilabel and multiclass targets, a mix of\n     64     multilabel formats, for the presence of continuous-valued or multioutput\n     65     targets, or for targets of different lengths.\n     66 \n     67     Column vectors are squeezed to 1d, while multilabel formats are returned\n     68     as CSR sparse label indicators.\n     69 \n     70     Parameters\n     71     ----------\n     72     y_true : array-like\n     73 \n     74     y_pred : array-like\n     75 \n     76     Returns\n     77     -------\n     78     type_true : one of {'multilabel-indicator', 'multiclass', 'binary'}\n     79         The type of the true target data, as output by\n     80         ``utils.multiclass.type_of_target``.\n     81 \n     82     y_true : array or indicator matrix\n     83 \n     84     y_pred : array or indicator matrix\n     85     \"\"\"\n     86     check_consistent_length(y_true, y_pred)\n     87     type_true = type_of_target(y_true, input_name=\"y_true\")\n     88     type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n     89 \n     90     y_type = {type_true, type_pred}\n     91     if y_type == {\"binary\", \"multiclass\"}:\n     92         y_type = {\"multiclass\"}\n     93 \n     94     if len(y_type) &gt; 1:\n---&gt; 95         raise ValueError(\n     96             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n     97                 type_true, type_pred\n     98             )\n     99         )\n    100 \n    101     # We can't have more than one value on y_type =&gt; The set is no more needed\n    102     y_type = y_type.pop()\n    103 \n    104     # No metrics support \"multiclass-multioutput\" format\n    105     if y_type not in [\"binary\", \"multiclass\", \"multilabel-indicator\"]:\n    106         raise ValueError(\"{0} is not supported\".format(y_type))\n    107 \n    108     if y_type in [\"binary\", \"multiclass\"]:\n    109         y_true = column_or_1d(y_true)\n    110         y_pred = column_or_1d(y_pred)\n    111         if y_type == \"binary\":\n    112             try:\n    113                 unique_values = np.union1d(y_true, y_pred)\n    114             except TypeError as e:\n    115                 # We expect y_true and y_pred to be of the same data type.\n    116                 # If `y_true` was provided to the classifier as strings,\n    117                 # `y_pred` given by the classifier will also be encoded with\n    118                 # strings. So we raise a meaningful error\n    119                 raise TypeError(\n    120                     \"Labels in y_true and y_pred should be of the same type. \"\n    121                     f\"Got y_true={np.unique(y_true)} and \"\n    122                     f\"y_pred={np.unique(y_pred)}. Make sure that the \"\n    123                     \"predictions provided by the classifier coincides with \"\n    124                     \"the true labels.\"\n    125                 ) from e\n    126             if len(unique_values) &gt; 2:\n    127                 y_type = \"multiclass\"\n    128 \n    129     if y_type.startswith(\"multilabel\"):\n    130         y_true = csr_matrix(y_true)\n    131         y_pred = csr_matrix(y_pred)\n    132         y_type = \"multilabel-indicator\"\n    133 \n    134     return y_type, y_true, y_pred\n    135 \n\n{'binary', 'continuous'}\n*** SyntaxError: '[' was never closed\nFalse\n'binary'\narray([0.08, 0.84, 1.  , ..., 0.32, 0.88, 0.04])\narray([0.  , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 ,\n       0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84,\n       0.88, 0.92, 0.96, 1.  ])\n&gt; /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/metrics/_classification.py(317)confusion_matrix()\n    315     (0, 2, 1, 1)\n    316     \"\"\"\n--&gt; 317     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    318     if y_type not in (\"binary\", \"multiclass\"):\n    319         raise ValueError(\"%s is not supported\" % y_type)\n\n&gt; /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py(456)safe_patch_function()\n    454                     reroute_warnings=False,\n    455                 ):\n--&gt; 456                     return original(*args, **kwargs)\n    457 \n    458             # Whether or not the original / underlying function has been called during the\n\n&lt;function confusion_matrix at 0x7f0fd89da3b0&gt;\n    382     def safe_patch_function(*args, **kwargs):\n    383         \"\"\"\n    384         A safe wrapper around the specified `patch_function` implementation designed to\n    385         handle exceptions thrown during the execution of `patch_function`. This wrapper\n    386         distinguishes exceptions thrown from the underlying / original function\n    387         (`&lt;destination&gt;.&lt;function_name&gt;`) from exceptions thrown from other parts of\n    388         `patch_function`. This distinction is made by passing an augmented version of the\n    389         underlying / original function to `patch_function` that uses nonlocal state to track\n    390         whether or not it has been executed and whether or not it threw an exception.\n    391         Exceptions thrown from the underlying / original function are propagated to the caller,\n    392         while exceptions thrown from other parts of `patch_function` are caught and logged as\n    393         warnings.\n    394         \"\"\"\n    395         # Reroute warnings encountered during the patch function implementation to an MLflow event\n    396         # logger, and enforce silent mode if applicable (i.e. if the corresponding autologging\n    397         # integration was called with `silent=True`), hiding MLflow event logging statements and\n    398         # hiding all warnings in the autologging preamble and postamble (i.e. the code surrounding\n    399         # the user's original / underlying ML function). Non-MLflow warnings are enabled during the\n    400         # execution of the original / underlying ML function\n    401         #\n    402         # Note that we've opted *not* to apply this context manager as a decorator on\n    403         # `safe_patch_function` because the context-manager-as-decorator pattern uses\n    404         # `contextlib.ContextDecorator`, which creates generator expressions that cannot be pickled\n    405         # during model serialization by ML frameworks such as scikit-learn\n    406         is_silent_mode = get_autologging_config(autologging_integration, \"silent\", False)\n    407         with set_mlflow_events_and_warnings_behavior_globally(\n    408             # MLflow warnings emitted during autologging training sessions are likely not\n    409             # actionable and result from the autologging implementation invoking another MLflow\n    410             # API. Accordingly, we reroute these warnings to the MLflow event logger with level\n    411             # WARNING For reference, see recommended warning and event logging behaviors from\n    412             # https://docs.python.org/3/howto/logging.html#when-to-use-logging\n    413             reroute_warnings=True,\n    414             disable_event_logs=is_silent_mode,\n    415             disable_warnings=is_silent_mode,\n    416         ), set_non_mlflow_warnings_behavior_for_current_thread(\n    417             # non-MLflow Warnings emitted during the autologging preamble (before the original /\n    418             # underlying ML function is called) and postamble (after the original / underlying ML\n    419             # function is called) are likely not actionable and result from the autologging\n    420             # implementation invoking an API from a dependent library. Accordingly, we reroute\n    421             # these warnings to the MLflow event logger with level WARNING. For reference, see\n    422             # recommended warning and event logging behaviors from\n    423             # https://docs.python.org/3/howto/logging.html#when-to-use-logging\n    424             reroute_warnings=True,\n    425             disable_warnings=is_silent_mode,\n    426         ):\n    427             if is_testing():\n    428                 preexisting_run_for_testing = mlflow.active_run()\n    429 \n    430             # Whether or not to exclude autologged content from user-created fluent runs\n    431             # (i.e. runs created manually via `mlflow.start_run()`)\n    432             exclusive = get_autologging_config(autologging_integration, \"exclusive\", False)\n    433             user_created_fluent_run_is_active = (\n    434                 mlflow.active_run() and not _AutologgingSessionManager.active_session()\n    435             )\n    436             active_session_failed = (\n    437                 _AutologgingSessionManager.active_session() is not None\n    438                 and _AutologgingSessionManager.active_session().state == \"failed\"\n    439             )\n    440 \n    441             if (\n    442                 active_session_failed\n    443                 or autologging_is_disabled(autologging_integration)\n    444                 or (user_created_fluent_run_is_active and exclusive)\n    445                 or mlflow.utils.autologging_utils._AUTOLOGGING_GLOBALLY_DISABLED\n    446             ):\n    447                 # If the autologging integration associated with this patch is disabled,\n    448                 # or if the current autologging integration is in exclusive mode and a user-created\n    449                 # fluent run is active, call the original function and return. Restore the original\n    450                 # warning behavior during original function execution, since autologging is being\n    451                 # skipped\n    452                 with set_non_mlflow_warnings_behavior_for_current_thread(\n    453                     disable_warnings=False,\n    454                     reroute_warnings=False,\n    455                 ):\n--&gt; 456                     return original(*args, **kwargs)\n    457 \n    458             # Whether or not the original / underlying function has been called during the\n    459             # execution of patched code\n    460             original_has_been_called = False\n    461             # The value returned by the call to the original / underlying function during\n    462             # the execution of patched code\n    463             original_result = None\n    464             # Whether or not an exception was raised from within the original / underlying function\n    465             # during the execution of patched code\n    466             failed_during_original = False\n    467             # The active MLflow run (if any) associated with patch code execution\n    468             patch_function_run_for_testing = None\n    469             # The exception raised during executing patching function\n    470             patch_function_exception = None\n    471 \n    472             def try_log_autologging_event(log_fn, *args):\n    473                 try:\n    474                     log_fn(*args)\n    475                 except Exception as e:\n    476                     _logger.debug(\n    477                         \"Failed to log autologging event via '%s'. Exception: %s\",\n    478                         log_fn,\n    479                         e,\n    480                     )\n    481 \n    482             def call_original_fn_with_event_logging(original_fn, og_args, og_kwargs):\n    483                 try:\n    484                     try_log_autologging_event(\n    485                         AutologgingEventLogger.get_logger().log_original_function_start,\n    486                         session,\n    487                         destination,\n    488                         function_name,\n    489                         og_args,\n    490                         og_kwargs,\n    491                     )\n    492                     original_fn_result = original_fn(*og_args, **og_kwargs)\n    493 \n    494                     try_log_autologging_event(\n    495                         AutologgingEventLogger.get_logger().log_original_function_success,\n    496                         session,\n    497                         destination,\n    498                         function_name,\n    499                         og_args,\n    500                         og_kwargs,\n    501                     )\n    502                     return original_fn_result\n    503                 except Exception as original_fn_e:\n    504                     try_log_autologging_event(\n    505                         AutologgingEventLogger.get_logger().log_original_function_error,\n    506                         session,\n    507                         destination,\n    508                         function_name,\n    509                         og_args,\n    510                         og_kwargs,\n    511                         original_fn_e,\n    512                     )\n    513 \n    514                     nonlocal failed_during_original\n    515                     failed_during_original = True\n    516                     raise\n    517 \n    518             with _AutologgingSessionManager.start_session(autologging_integration) as session:\n    519                 try:\n    520 \n    521                     def call_original(*og_args, **og_kwargs):\n    522                         def _original_fn(*_og_args, **_og_kwargs):\n    523                             if is_testing():\n    524                                 _validate_args(\n    525                                     autologging_integration,\n    526                                     function_name,\n    527                                     args,\n    528                                     kwargs,\n    529                                     og_args,\n    530                                     og_kwargs,\n    531                                 )\n    532                                 # By the time `original` is called by the patch implementation, we\n    533                                 # assume that either: 1. the patch implementation has already\n    534                                 # created an MLflow run or 2. the patch code will not create an\n    535                                 # MLflow run during the current execution. Here, we capture a\n    536                                 # reference to the active run, which we will use later on to\n    537                                 # determine whether or not the patch implementation created\n    538                                 # a run and perform validation if necessary\n    539                                 nonlocal patch_function_run_for_testing\n    540                                 patch_function_run_for_testing = mlflow.active_run()\n    541 \n    542                             nonlocal original_has_been_called\n    543                             original_has_been_called = True\n    544 \n    545                             nonlocal original_result\n    546                             # Show all non-MLflow warnings as normal (i.e. not as event logs)\n    547                             # during original function execution, even if silent mode is enabled\n    548                             # (`silent=True`), since these warnings originate from the ML framework\n    549                             # or one of its dependencies and are likely relevant to the caller\n    550                             with set_non_mlflow_warnings_behavior_for_current_thread(\n    551                                 disable_warnings=False,\n    552                                 reroute_warnings=False,\n    553                             ):\n    554                                 original_result = original(*_og_args, **_og_kwargs)\n    555                                 return original_result\n    556 \n    557                         return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n    558 \n    559                     # Apply the name, docstring, and signature of `original` to `call_original`.\n    560                     # This is important because several autologging patch implementations inspect\n    561                     # the signature of the `original` argument during execution\n    562                     call_original = update_wrapper_extended(call_original, original)\n    563 \n    564                     try_log_autologging_event(\n    565                         AutologgingEventLogger.get_logger().log_patch_function_start,\n    566                         session,\n    567                         destination,\n    568                         function_name,\n    569                         args,\n    570                         kwargs,\n    571                     )\n    572 \n    573                     if patch_is_class:\n    574                         patch_function.call(call_original, *args, **kwargs)\n    575                     else:\n    576                         patch_function(call_original, *args, **kwargs)\n    577 \n    578                     session.state = \"succeeded\"\n    579 \n    580                     try_log_autologging_event(\n    581                         AutologgingEventLogger.get_logger().log_patch_function_success,\n    582                         session,\n    583                         destination,\n    584                         function_name,\n    585                         args,\n    586                         kwargs,\n    587                     )\n    588                 except Exception as e:\n    589                     session.state = \"failed\"\n    590                     patch_function_exception = e\n    591                     # Exceptions thrown during execution of the original function should be\n    592                     # propagated to the caller. Additionally, exceptions encountered during test\n    593                     # mode should be reraised to detect bugs in autologging implementations\n    594                     if failed_during_original or is_testing():\n    595                         raise\n    596 \n    597                 if is_testing() and not preexisting_run_for_testing:\n    598                     # If an MLflow run was created during the execution of patch code, verify that\n    599                     # it is no longer active and that it contains expected autologging tags\n    600                     assert (\n    601                         not mlflow.active_run()\n    602                     ), f\"Autologging integration {autologging_integration} leaked an active run\"\n    603                     if patch_function_run_for_testing:\n    604                         _validate_autologging_run(\n    605                             autologging_integration, patch_function_run_for_testing.info.run_id\n    606                         )\n    607                 try:\n    608                     if original_has_been_called:\n    609                         return original_result\n    610                     else:\n    611                         return call_original_fn_with_event_logging(original, args, kwargs)\n    612                 finally:\n    613                     # If original function succeeds, but `patch_function_exception` exists,\n    614                     # it represent patching code unexpected failure, so we call\n    615                     # `log_patch_function_error` in this case.\n    616                     # If original function failed, we don't call `log_patch_function_error`\n    617                     # even if `patch_function_exception` exists, because original function failure\n    618                     # means there's some error in user code (e.g. user provide wrong arguments)\n    619                     if patch_function_exception is not None and not failed_during_original:\n    620                         try_log_autologging_event(\n    621                             AutologgingEventLogger.get_logger().log_patch_function_error,\n    622                             session,\n    623                             destination,\n    624                             function_name,\n    625                             args,\n    626                             kwargs,\n    627                             patch_function_exception,\n    628                         )\n    629 \n    630                         _logger.warning(\n    631                             \"Encountered unexpected error during %s autologging: %s\",\n    632                             autologging_integration,\n    633                             patch_function_exception,\n    634                         )\n    635 \n\n&gt; /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/models/evaluation/default_evaluator.py(247)_get_binary_classifier_metrics()\n    245 ):\n    246     with _suppress_class_imbalance_errors(ValueError):\n--&gt; 247         tn, fp, fn, tp = sk_metrics.confusion_matrix(y_true, y_pred).ravel()\n    248         return {\n    249             \"true_negatives\": tn,\n\narray([0.08, 0.84, 1.  , ..., 0.32, 0.88, 0.04])\n&gt; /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/models/evaluation/default_evaluator.py(1521)_compute_builtin_metrics()\n   1519         if self.model_type == _ModelType.CLASSIFIER:\n   1520             if self.is_binomial:\n-&gt; 1521                 metrics = _get_binary_classifier_metrics(\n   1522                     y_true=self.y,\n   1523                     y_pred=self.y_pred,\n\n&lt;mlflow.models.evaluation.default_evaluator.DefaultEvaluator object at 0x7f0fcb072800&gt;\nTrue\n   1514     def _compute_builtin_metrics(self):\n   1515         \"\"\"\n   1516         Helper method for computing builtin metrics\n   1517         \"\"\"\n   1518         self._evaluate_sklearn_model_score_if_scorable()\n   1519         if self.model_type == _ModelType.CLASSIFIER:\n   1520             if self.is_binomial:\n-&gt; 1521                 metrics = _get_binary_classifier_metrics(\n   1522                     y_true=self.y,\n   1523                     y_pred=self.y_pred,\n   1524                     y_proba=self.y_probs,\n   1525                     labels=self.label_list,\n   1526                     pos_label=self.pos_label,\n   1527                     sample_weights=self.sample_weights,\n   1528                 )\n   1529                 if metrics:\n   1530                     self.metrics_values.update(_get_aggregate_metrics_values(metrics))\n   1531                     self._compute_roc_and_pr_curve()\n   1532             else:\n   1533                 average = self.evaluator_config.get(\"average\", \"weighted\")\n   1534                 metrics = _get_multiclass_classifier_metrics(\n   1535                     y_true=self.y,\n   1536                     y_pred=self.y_pred,\n   1537                     y_proba=self.y_probs,\n   1538                     labels=self.label_list,\n   1539                     average=average,\n   1540                     sample_weights=self.sample_weights,\n   1541                 )\n   1542                 if metrics:\n   1543                     self.metrics_values.update(_get_aggregate_metrics_values(metrics))\n   1544         elif self.model_type == _ModelType.REGRESSOR:\n   1545             self.metrics_values.update(\n   1546                 _get_aggregate_metrics_values(\n   1547                     _get_regressor_metrics(self.y, self.y_pred, self.sample_weights)\n   1548                 )\n   1549             )\n   1550 \n\n\n\nipdb&gt;  y_type\nipdb&gt;  ll\nipdb&gt;  y_type \nipdb&gt;  y_type in [\"binary\", \"multiclass\"\nipdb&gt;  y_type in [\"binary\", \"multiclass\"]\nipdb&gt;  type_true \nipdb&gt;  y_pred\nipdb&gt;  np.unique(y_pred)\nipdb&gt;  up\nipdb&gt;  up\nipdb&gt;  original\nipdb&gt;  ll\nipdb&gt;  up\nipdb&gt;  y_pred\nipdb&gt;  up\nipdb&gt;  self\nipdb&gt;  self.is_binomial\nipdb&gt;  ll\nipdb&gt;  q\n\n\n\ndef root_mean_squared_error(eval_df, _builtin_metrics):\n    precision, recall, thresholds = precision_recall_curve (eval_df[\"label\"], eval_df[\"predictions\"])\n    thresholds = np.append ([thresholds, 1.0])\n    return np.sqrt((np.abs( - ) ** 2).mean)\n\nrmse_metric = mlflow.models.make_metric(\n    eval_fn=root_mean_squared_error,\n    greater_is_better=False,\n)\n\nmlflow.evaluate(..., extra_metrics=[rmse_metric])\n\n\nimport mlflow\nmlflow.__version__\n\n'2.13.1'\n\n\n\nmlflow.evaluate?\n\n\nSignature:\nmlflow.evaluate(\n    model=None,\n    data=None,\n    *,\n    model_type=None,\n    targets=None,\n    predictions=None,\n    dataset_path=None,\n    feature_names=None,\n    evaluators=None,\n    evaluator_config=None,\n    custom_metrics=None,\n    extra_metrics=None,\n    custom_artifacts=None,\n    validation_thresholds=None,\n    baseline_model=None,\n    env_manager='local',\n    model_config=None,\n    baseline_config=None,\n    inference_params=None,\n)\nDocstring:\nEvaluate the model performance on given data and selected metrics.\nThis function evaluates a PyFunc model or custom callable on the specified dataset using\nspecified ``evaluators``, and logs resulting metrics & artifacts to MLflow tracking server.\nUsers can also skip setting ``model`` and put the model outputs in ``data`` directly for\nevaluation. For detailed information, please read\n:ref:`the Model Evaluation documentation &lt;model-evaluation&gt;`.\nDefault Evaluator behavior:\n - The default evaluator, which can be invoked with ``evaluators=\"default\"`` or\n   ``evaluators=None``, supports model types listed below. For each pre-defined model type, the\n   default evaluator evaluates your model on a selected set of metrics and generate artifacts\n   like plots. Please find more details below.\n - For both the ``\"regressor\"`` and ``\"classifier\"`` model types, the default evaluator\n   generates model summary plots and feature importance plots using\n   `SHAP &lt;https://shap.readthedocs.io/en/latest/index.html&gt;`_.\n - For regressor models, the default evaluator additionally logs:\n    - **metrics**: example_count, mean_absolute_error, mean_squared_error,\n      root_mean_squared_error, sum_on_target, mean_on_target, r2_score, max_error,\n      mean_absolute_percentage_error.\n - For binary classifiers, the default evaluator additionally logs:\n    - **metrics**: true_negatives, false_positives, false_negatives, true_positives, recall,\n      precision, f1_score, accuracy_score, example_count, log_loss, roc_auc,\n      precision_recall_auc.\n    - **artifacts**: lift curve plot, precision-recall plot, ROC plot.\n - For multiclass classifiers, the default evaluator additionally logs:\n    - **metrics**: accuracy_score, example_count, f1_score_micro, f1_score_macro, log_loss\n    - **artifacts**: A CSV file for \"per_class_metrics\" (per-class metrics includes\n      true_negatives/false_positives/false_negatives/true_positives/recall/precision/roc_auc,\n      precision_recall_auc), precision-recall merged curves plot, ROC merged curves plot.\n - For question-answering models, the default evaluator logs:\n    - **metrics**: ``exact_match``, ``token_count``, `toxicity`_ (requires `evaluate`_,\n      `torch`_, `flesch_kincaid_grade_level`_ (requires `textstat`_) and `ari_grade_level`_.\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in tabular format.\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For text-summarization models, the default evaluator logs:\n    - **metrics**: ``token_count``, `ROUGE`_ (requires `evaluate`_, `nltk`_, and\n      `rouge_score`_ to be installed), `toxicity`_ (requires `evaluate`_, `torch`_,\n      `transformers`_), `ari_grade_level`_ (requires `textstat`_),\n      `flesch_kincaid_grade_level`_ (requires `textstat`_).\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in the tabular format.\n    .. _ROUGE:\n        https://huggingface.co/spaces/evaluate-metric/rouge\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _nltk:\n        https://pypi.org/project/nltk\n    .. _rouge_score:\n        https://pypi.org/project/rouge-score\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For text models, the default evaluator logs:\n    - **metrics**: ``token_count``, `toxicity`_ (requires `evaluate`_, `torch`_,\n      `transformers`_), `ari_grade_level`_ (requires `textstat`_),\n      `flesch_kincaid_grade_level`_ (requires `textstat`_).\n    - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``\n      argument is supplied), and per-row metrics of the model in tabular format.\n    .. _evaluate:\n        https://pypi.org/project/evaluate\n    .. _toxicity:\n        https://huggingface.co/spaces/evaluate-measurement/toxicity\n    .. _torch:\n        https://pytorch.org/get-started/locally/\n    .. _transformers:\n        https://huggingface.co/docs/transformers/installation\n    .. _ari_grade_level:\n        https://en.wikipedia.org/wiki/Automated_readability_index\n    .. _flesch_kincaid_grade_level:\n        https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level\n    .. _textstat:\n        https://pypi.org/project/textstat\n - For retriever models, the default evaluator logs:\n    - **metrics**: :mod:`precision_at_k(k) &lt;mlflow.metrics.precision_at_k&gt;`,\n      :mod:`recall_at_k(k) &lt;mlflow.metrics.recall_at_k&gt;` and\n      :mod:`ndcg_at_k(k) &lt;mlflow.metrics.ndcg_at_k&gt;` - all have a default value of\n      ``retriever_k`` = 3.\n    - **artifacts**: A JSON file containing the inputs, outputs, targets, and per-row metrics\n      of the model in tabular format.\n - For sklearn models, the default evaluator additionally logs the model's evaluation criterion\n   (e.g. mean accuracy for a classifier) computed by `model.score` method.\n - The metrics/artifacts listed above are logged to the active MLflow run.\n   If no active run exists, a new MLflow run is created for logging these metrics and\n   artifacts. Note that no metrics/artifacts are logged for the ``baseline_model``.\n - Additionally, information about the specified dataset - hash, name (if specified), path\n   (if specified), and the UUID of the model that evaluated it - is logged to the\n   ``mlflow.datasets`` tag.\n - The available ``evaluator_config`` options for the default evaluator include:\n    - **log_model_explainability**: A boolean value specifying whether or not to log model\n      explainability insights, default value is True.\n    - **explainability_algorithm**: A string to specify the SHAP Explainer algorithm for model\n      explainability. Supported algorithm includes: 'exact', 'permutation', 'partition',\n      'kernel'.\n      If not set, ``shap.Explainer`` is used with the \"auto\" algorithm, which chooses the best\n      Explainer based on the model.\n    - **explainability_nsamples**: The number of sample rows to use for computing model\n      explainability insights. Default value is 2000.\n    - **explainability_kernel_link**: The kernel link function used by shap kernal explainer.\n      Available values are \"identity\" and \"logit\". Default value is \"identity\".\n    - **max_classes_for_multiclass_roc_pr**:\n      For multiclass classification tasks, the maximum number of classes for which to log\n      the per-class ROC curve and Precision-Recall curve. If the number of classes is\n      larger than the configured maximum, these curves are not logged.\n    - **metric_prefix**: An optional prefix to prepend to the name of each metric and artifact\n      produced during evaluation.\n    - **log_metrics_with_dataset_info**: A boolean value specifying whether or not to include\n      information about the evaluation dataset in the name of each metric logged to MLflow\n      Tracking during evaluation, default value is True.\n    - **pos_label**: If specified, the positive label to use when computing classification\n      metrics such as precision, recall, f1, etc. for binary classification models. For\n      multiclass classification and regression models, this parameter will be ignored.\n    - **average**: The averaging method to use when computing classification metrics such as\n      precision, recall, f1, etc. for multiclass classification models\n      (default: ``'weighted'``). For binary classification and regression models, this\n      parameter will be ignored.\n    - **sample_weights**: Weights for each sample to apply when computing model performance\n      metrics.\n    - **col_mapping**: A dictionary mapping column names in the input dataset or output\n      predictions to column names used when invoking the evaluation functions.\n    - **retriever_k**: A parameter used when ``model_type=\"retriever\"`` as the number of\n      top-ranked retrieved documents to use when computing the built-in metric\n      :mod:`precision_at_k(k) &lt;mlflow.metrics.precision_at_k&gt;`,\n      :mod:`recall_at_k(k) &lt;mlflow.metrics.recall_at_k&gt;` and\n      :mod:`ndcg_at_k(k) &lt;mlflow.metrics.ndcg_at_k&gt;`. Default value is 3. For all other\n      model types, this parameter will be ignored.\n - Limitations of evaluation dataset:\n    - For classification tasks, dataset labels are used to infer the total number of classes.\n    - For binary classification tasks, the negative label value must be 0 or -1 or False, and\n      the positive label value must be 1 or True.\n - Limitations of metrics/artifacts computation:\n    - For classification tasks, some metric and artifact computations require the model to\n      output class probabilities. Currently, for scikit-learn models, the default evaluator\n      calls the ``predict_proba`` method on the underlying model to obtain probabilities. For\n      other model types, the default evaluator does not compute metrics/artifacts that require\n      probability outputs.\n - Limitations of default evaluator logging model explainability insights:\n    - The ``shap.Explainer`` ``auto`` algorithm uses the ``Linear`` explainer for linear models\n      and the ``Tree`` explainer for tree models. Because SHAP's ``Linear`` and ``Tree``\n      explainers do not support multi-class classification, the default evaluator falls back to\n      using the ``Exact`` or ``Permutation`` explainers for multi-class classification tasks.\n    - Logging model explainability insights is not currently supported for PySpark models.\n    - The evaluation dataset label values must be numeric or boolean, all feature values\n      must be numeric, and each feature column must only contain scalar values.\n - Limitations when environment restoration is enabled:\n    - When environment restoration is enabled for the evaluated model (i.e. a non-local\n      ``env_manager`` is specified), the model is loaded as a client that invokes a MLflow\n      Model Scoring Server process in an independent Python environment with the model's\n      training time dependencies installed. As such, methods like ``predict_proba`` (for\n      probability outputs) or ``score`` (computes the evaluation criterian for sklearn models)\n      of the model become inaccessible and the default evaluator does not compute metrics or\n      artifacts that require those methods.\n    - Because the model is an MLflow Model Server process, SHAP explanations are slower to\n      compute. As such, model explainaibility is disabled when a non-local ``env_manager``\n      specified, unless the ``evaluator_config`` option **log_model_explainability** is\n      explicitly set to ``True``.\nArgs:\n    model: Optional. If specified, it should be one of the following:\n        - A pyfunc model instance\n        - A URI referring to a pyfunc model\n        - A URI referring to an MLflow Deployments endpoint e.g. ``\"endpoints:/my-chat\"``\n        - A callable function: This function should be able to take in model input and\n          return predictions. It should follow the signature of the\n          :py:func:`predict &lt;mlflow.pyfunc.PyFuncModel.predict&gt;` method. Here's an example\n          of a valid function:\n          ..code-block:: python\n              model = mlflow.pyfunc.load_model(model_uri)\n              def fn(model_input):\n                  return model.predict(model_input)\n        If omitted, it indicates a static dataset will be used for evaluation instead of a\n        model.  In this case, the ``data`` argument must be a Pandas DataFrame or an mlflow\n        PandasDataset that contains model outputs, and the ``predictions`` argument must be the\n        name of the column in ``data`` that contains model outputs.\n    data: One of the\n        following:\n        - A numpy array or list of evaluation features, excluding labels.\n        - A Pandas DataFrame containing evaluation features, labels, and optionally model\n            outputs. Model outputs are required to be provided when model is unspecified.\n            If ``feature_names`` argument not specified, all columns except for the label\n            column and model_output column are regarded as feature columns. Otherwise,\n            only column names present in ``feature_names`` are regarded as feature columns.\n        -  A Spark DataFrame containing evaluation features and labels. If\n            ``feature_names`` argument not specified, all columns except for the label\n            column are regarded as feature columns. Otherwise, only column names present in\n            ``feature_names`` are regarded as feature columns. Only the first 10000 rows in\n            the Spark DataFrame will be used as evaluation data.\n        - A :py:class:`mlflow.data.dataset.Dataset` instance containing evaluation\n            features, labels, and optionally model outputs. Model outputs are only supported\n            with a PandasDataset. Model outputs are required when model is unspecified, and\n            should be specified via the ``predictions`` prerty of the PandasDataset.\n    targets: If ``data`` is a numpy array or list, a numpy array or list of evaluation\n        labels. If ``data`` is a DataFrame, the string name of a column from ``data``\n        that contains evaluation labels. Required for classifier and regressor models,\n        but optional for question-answering, text-summarization, and text models. If\n        ``data`` is a :py:class:`mlflow.data.dataset.Dataset` that defines targets,\n        then ``targets`` is optional.\n    predictions: Optional. The name of the column that contains model outputs.\n        - When ``model`` is specified and outputs multiple columns, ``predictions`` can be used\n          to specify the name of the column that will be used to store model outputs for\n          evaluation.\n        - When ``model`` is not specified and ``data`` is a pandas dataframe,\n          ``predictions`` can be used to specify the name of the column in ``data`` that\n          contains model outputs.\n        .. code-block:: python\n            :caption: Example usage of predictions\n            # Evaluate a model that outputs multiple columns\n            data = pd.DataFrame({\"question\": [\"foo\"]})\n            def model(inputs):\n                return pd.DataFrame({\"answer\": [\"bar\"], \"source\": [\"baz\"]})\n            results = evaluate(model=model, data=data, predictions=\"answer\", ...)\n            # Evaluate a static dataset\n            data = pd.DataFrame({\"question\": [\"foo\"], \"answer\": [\"bar\"], \"source\": [\"baz\"]})\n            results = evaluate(data=data, predictions=\"answer\", ...)\n    model_type: (Optional) A string describing the model type. The default evaluator\n        supports the following model types:\n        - ``'classifier'``\n        - ``'regressor'``\n        - ``'question-answering'``\n        - ``'text-summarization'``\n        - ``'text'``\n        - ``'retriever'``\n        If no ``model_type`` is specified, then you must provide a a list of\n        metrics to compute via the ``extra_metrics`` param.\n        .. note::\n            ``'question-answering'``, ``'text-summarization'``, ``'text'``, and\n            ``'retriever'`` are experimental and may be changed or removed in a\n            future release.\n    inference_params: (Optional) A dictionary of inference parameters to be passed to the model\n        when making predictions, such as ``{\"max_tokens\": 100}``. This is only used when\n        the ``model`` is an MLflow Deployments endpoint URI e.g. ``\"endpoints:/my-chat\"``\n    dataset_path: (Optional) The path where the data is stored. Must not contain double\n        quotes (``“``). If specified, the path is logged to the ``mlflow.datasets``\n        tag for lineage tracking purposes.\n    feature_names: (Optional) A list. If the ``data`` argument is a numpy array or list,\n        ``feature_names`` is a list of the feature names for each feature. If\n        ``feature_names=None``, then the ``feature_names`` are generated using the\n        format ``feature_{feature_index}``. If the ``data`` argument is a Pandas\n        DataFrame or a Spark DataFrame, ``feature_names`` is a list of the names\n        of the feature columns in the DataFrame. If ``feature_names=None``, then\n        all columns except the label column and the predictions column are\n        regarded as feature columns.\n    evaluators: The name of the evaluator to use for model evaluation, or a list of\n        evaluator names. If unspecified, all evaluators capable of evaluating the\n        specified model on the specified dataset are used. The default evaluator\n        can be referred to by the name ``\"default\"``. To see all available\n        evaluators, call :py:func:`mlflow.models.list_evaluators`.\n    evaluator_config: A dictionary of additional configurations to supply to the evaluator.\n        If multiple evaluators are specified, each configuration should be\n        supplied as a nested dictionary whose key is the evaluator name.\n    extra_metrics:\n        (Optional) A list of :py:class:`EvaluationMetric &lt;mlflow.models.EvaluationMetric&gt;`\n        objects.  These metrics are computed in addition to the default metrics associated with\n        pre-defined `model_type`, and setting `model_type=None` will only compute the metrics\n        specified in `extra_metrics`. See the `mlflow.metrics` module for more information about\n        the builtin metrics and how to define extra metrics.\n        .. code-block:: python\n            :caption: Example usage of extra metrics\n            import mlflow\n            import numpy as np\n            def root_mean_squared_error(eval_df, _builtin_metrics):\n                return np.sqrt((np.abs(eval_df[\"prediction\"] - eval_df[\"target\"]) ** 2).mean)\n            rmse_metric = mlflow.models.make_metric(\n                eval_fn=root_mean_squared_error,\n                greater_is_better=False,\n            )\n            mlflow.evaluate(..., extra_metrics=[rmse_metric])\n    custom_artifacts:\n        (Optional) A list of custom artifact functions with the following signature:\n        .. code-block:: python\n            def custom_artifact(\n                eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],\n                builtin_metrics: Dict[str, float],\n                artifacts_dir: str,\n            ) -&gt; Dict[str, Any]:\n                \"\"\"\n                Args:\n                    eval_df:\n                        A Pandas or Spark DataFrame containing ``prediction`` and ``target``\n                        column.  The ``prediction`` column contains the predictions made by the\n                        model.  The ``target`` column contains the corresponding labels to the\n                        predictions made on that row.\n                    builtin_metrics:\n                        A dictionary containing the metrics calculated by the default evaluator.\n                        The keys are the names of the metrics and the values are the scalar\n                        values of the metrics. Refer to the DefaultEvaluator behavior section\n                        for what metrics will be returned based on the type of model (i.e.\n                        classifier or regressor).\n                    artifacts_dir:\n                        A temporary directory path that can be used by the custom artifacts\n                        function to temporarily store produced artifacts. The directory will be\n                        deleted after the artifacts are logged.\n                Returns:\n                    A dictionary that maps artifact names to artifact objects\n                    (e.g. a Matplotlib Figure) or to artifact paths within ``artifacts_dir``.\n                \"\"\"\n                ...\n        Object types that artifacts can be represented as:\n            - A string uri representing the file path to the artifact. MLflow will infer the\n              type of the artifact based on the file extension.\n            - A string representation of a JSON object. This will be saved as a .json artifact.\n            - Pandas DataFrame. This will be resolved as a CSV artifact.\n            - Numpy array. This will be saved as a .npy artifact.\n            - Matplotlib Figure. This will be saved as an image artifact. Note that\n              ``matplotlib.pyplot.savefig`` is called behind the scene with default\n              configurations.\n              To customize, either save the figure with the desired configurations and return\n              its file path or define customizations through environment variables in\n              ``matplotlib.rcParams``.\n            - Other objects will be attempted to be pickled with the default protocol.\n        .. code-block:: python\n            :caption: Example usage of custom artifacts\n            import mlflow\n            import matplotlib.pyplot as plt\n            def scatter_plot(eval_df, builtin_metrics, artifacts_dir):\n                plt.scatter(eval_df[\"prediction\"], eval_df[\"target\"])\n                plt.xlabel(\"Targets\")\n                plt.ylabel(\"Predictions\")\n                plt.title(\"Targets vs. Predictions\")\n                plt.savefig(os.path.join(artifacts_dir, \"example.png\"))\n                plt.close()\n                return {\"pred_target_scatter\": os.path.join(artifacts_dir, \"example.png\")}\n            def pred_sample(eval_df, _builtin_metrics, _artifacts_dir):\n                return {\"pred_sample\": pred_sample.head(10)}\n            mlflow.evaluate(..., custom_artifacts=[scatter_plot, pred_sample])\n    validation_thresholds: (Optional) A dictionary of metric name to\n        :py:class:`mlflow.models.MetricThreshold` used for model validation. Each metric name\n        must either be the name of a builtin metric or the name of a metric defined in the\n        ``extra_metrics`` parameter.\n        .. code-block:: python\n            :caption: Example of Model Validation\n            from mlflow.models import MetricThreshold\n            thresholds = {\n                \"accuracy_score\": MetricThreshold(\n                    # accuracy should be &gt;=0.8\n                    threshold=0.8,\n                    # accuracy should be at least 5 percent greater than baseline model accuracy\n                    min_absolute_change=0.05,\n                    # accuracy should be at least 0.05 greater than baseline model accuracy\n                    min_relative_change=0.05,\n                    greater_is_better=True,\n                ),\n            }\n            with mlflow.start_run():\n                mlflow.evaluate(\n                    model=your_candidate_model,\n                    data,\n                    targets,\n                    model_type,\n                    dataset_name,\n                    evaluators,\n                    validation_thresholds=thresholds,\n                    baseline_model=your_baseline_model,\n                )\n        See :ref:`the Model Validation documentation &lt;model-validation&gt;`\n        for more details.\n    baseline_model: (Optional) A string URI referring to an MLflow model with the pyfunc\n        flavor. If specified, the candidate ``model`` is compared to this\n        baseline for model validation purposes.\n    env_manager: Specify an environment manager to load the candidate ``model`` and\n        ``baseline_model`` in isolated Python environments and restore their\n        dependencies. Default value is ``local``, and the following values are\n        supported:\n        - ``virtualenv``: (Recommended) Use virtualenv to restore the python\n          environment that was used to train the model.\n        - ``conda``:  Use Conda to restore the software environment that was used\n          to train the model.\n        - ``local``: Use the current Python environment for model inference, which\n          may differ from the environment used to train the model and may lead to\n          errors or invalid predictions.\n    model_config: the model configuration to use for loading the model with pyfunc. Inspect\n        the model's pyfunc flavor to know which keys are supported for your\n        specific model. If not indicated, the default model configuration\n        from the model is used (if any).\n    baseline_config: the model configuration to use for loading the baseline\n        model. If not indicated, the default model configuration\n        from the baseline model is used (if any).\nReturns:\n    An :py:class:`mlflow.models.EvaluationResult` instance containing\n    metrics of candidate model and baseline model, and artifacts of candidate model.\nFile:      /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/models/evaluation/base.py\nType:      function\n\n\n\n\nmlflow.data.from_pandas?\n\n\nSignature:\nmlflow.data.from_pandas(\n    df: pandas.core.frame.DataFrame,\n    source: Union[str, mlflow.data.dataset_source.DatasetSource] = None,\n    targets: Optional[str] = None,\n    name: Optional[str] = None,\n    digest: Optional[str] = None,\n    predictions: Optional[str] = None,\n) -&gt; mlflow.data.pandas_dataset.PandasDataset\nDocstring:\nConstructs a :py:class:`PandasDataset &lt;mlflow.data.pandas_dataset.PandasDataset&gt;` instance from\na Pandas DataFrame, optional targets, optional predictions, and source.\nArgs:\n    df: A Pandas DataFrame.\n    source: The source from which the DataFrame was derived, e.g. a filesystem\n        path, an S3 URI, an HTTPS URL, a delta table name with version, or\n        spark table etc. ``source`` may be specified as a URI, a path-like string,\n        or an instance of\n        :py:class:`DatasetSource &lt;mlflow.data.dataset_source.DatasetSource&gt;`.\n        If unspecified, the source is assumed to be the code location\n        (e.g. notebook cell, script, etc.) where\n        :py:func:`from_pandas &lt;mlflow.data.from_pandas&gt;` is being called.\n    targets: An optional target column name for supervised training. This column\n        must be present in the dataframe (``df``).\n    name: The name of the dataset. If unspecified, a name is generated.\n    digest: The dataset digest (hash). If unspecified, a digest is computed\n        automatically.\n    predictions: An optional predictions column name for model evaluation. This column\n        must be present in the dataframe (``df``).\n.. code-block:: python\n    :test:\n    :caption: Example\n    import mlflow\n    import pandas as pd\n    x = pd.DataFrame(\n        [[\"tom\", 10, 1, 1], [\"nick\", 15, 0, 1], [\"juli\", 14, 1, 1]],\n        columns=[\"Name\", \"Age\", \"Label\", \"ModelOutput\"],\n    )\n    dataset = mlflow.data.from_pandas(x, targets=\"Label\", predictions=\"ModelOutput\")\nFile:      /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py\nType:      function\n\n\n\n\npd_dataset.digest\n\n'd4a94990'"
  },
  {
    "objectID": "posts/data_science/playing_with_mlflow.html#try",
    "href": "posts/data_science/playing_with_mlflow.html#try",
    "title": "Playing with MLflow",
    "section": "Try",
    "text": "Try\n\ncreate_experiment followed by set_experiment\n\nhttps://mlflow.org/docs/latest/tracking.html#tracking-runs\nhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?view=azureml-api-2&tabs=interactive#log-images\nhttps://www.databricks.com/notebooks/gallery/MLflowLoggingAPIPythonQuickstart.html"
  },
  {
    "objectID": "posts/data_science/simulation.html",
    "href": "posts/data_science/simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "conda env includes current module, with setup.py and settings.ini from nbdev\nThe pipeline is run from a python_scripts folder.\nThe conda env is in root folder.\nThe config in a configs folder.\nThe components are in mylib/aml folder.\nWe add a docker file that copies files such as setup.py, settings.ini, data, wheels, etc. (everything needed by the component scripts, which is basically everything copied to simulation folder, except for the json file used for config of how the pipeline is built (e.g., the one indicating the name of the environment, etc.)\n\nWe are going to try two methods: one based on python image, and another based on aml image.\n\n\n\n\n\n\nimport os\nimport shutil\n\nos.makedirs ('simulation/python_scripts', exist_ok=True)\nos.makedirs ('simulation/my_lib/aml', exist_ok=True)\nos.makedirs ('simulation/configs', exist_ok=True)\nos.makedirs ('simulation/data', exist_ok=True)\n\n# shutil.copy ('./hello_world.yml', 'simulation') =&gt; a different one will be created \nshutil.copy ('./pipeline_input.json', 'simulation/configs')\n\nshutil.copy ('preprocessing/preprocessing.py', 'simulation/my_lib/aml')\nshutil.copy ('training/training.py', 'simulation/my_lib/aml')\nshutil.copy ('inference/inference.py', 'simulation/my_lib/aml')\n\nshutil.copy ('data/dummy_input.csv', 'simulation/data')\nshutil.copy ('data/dummy_test.csv', 'simulation/data')\n\n\n\n\ncd ../../..\ngit clone https://github.com/fastai/nbdev.git\ncp nbdev/settings.ini home/posts/data_science/simulation\ncp nbdev/setup.py home/posts/data_science/simulation\ncd home/posts/data_science/simulation\n\n\n\nEdit the settings.ini file and replace the following entries as follows:\nlib_name = my_lib\nrepo = simulation\nrequirements = pandas\n               scikit-learn\n               numpy\ndev_requirements = joblib\n                   azure-ai-ml\nlib_path = my_lib\nThen remove the following entries:\npip_requirements\nconda_requirements\ndev_requirements\nconsole_scripts\n\n\n\n\n%%writefile simulation/hello_world.yml\nname: hello_world\ndependencies:\n    - python=3.10\n    - pip\n    - pip:\n        - -e .[dev]\n\nOverwriting simulation/hello_world.yml\n\n\n\n\n\nI just searched in the list of curated environments present in my workspace, using the keyword sklearn in the search text box. At the time of writing this tutorial, the environment found is sklearn-1.1:30. By clicking on it, and then on the Context tab, we can read its dockerfile, which indicates, in the first line, the base docker image used: FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1.\nI found documentation about the docker image to be used by googling “docker mcr.microsoft.com/azureml/openmpi4.1.0”, which provided the following URL: https://hub.docker.com/_/microsoft-azureml. In there, we can find additional links: - https://github.com/Azure/AzureML-Containers =&gt; contains docker files for each image - Note: SDK code contained in this link is v1.\nWe can also explore this docker image by running it in interactive mode (see a cheat sheet of docker commands in here and here):\ndocker pull mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\ndocker run -it --entrypoint bash mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\nIn this tutorial we can see how to test this docker image :\ndocker run --rm -d -v $PWD/$BASE_PATH:$MODEL_BASE_PATH -p 8501:8501 \\\n -e MODEL_BASE_PATH=$MODEL_BASE_PATH -e MODEL_NAME=$MODEL_NAME \\\n --name=\"tfserving-test\" docker.io/tensorflow/serving:latest\nsleep 10\n\n\nEither copy the dockerfile and replace the line:\nCOPY conda_dependencies.yaml .\nwith:\nRUN mkdir -p data\nCOPY &lt;MY-CONDA-ENV-YAML&gt; .\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nand change the name conda_dependencies.yaml with  everywhere else in the file…\nor name your conda env file conda_dependencies.yaml:\nmv simulation/hello_world.yml simulation/conda_dependencies.yaml\nand use the curated docker image as base image in your dockerfile:\nFROM mcr.microsoft.com/azureml/curated/sklearn-1.1:30\n\nRUN mkdir -p data\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nNote that we can dedicate a specific folder for all the files that need to be copied and used in the Dockerfile, including conda_dependencies.yaml.\n\n\n\nFrom the two possibilities mentioned above, we use the first one, which is more modular:\n\ncd ..\n\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/jaumecpu/code/Users/jau.m/home/posts/data_science\n\n\n\nmv simulation/hello_world.yml simulation/conda_dependencies.yaml\n\nmv: cannot stat 'simulation/hello_world.yml': No such file or directory\n\n\n\n%%writefile simulation/Dockerfile\nFROM mcr.microsoft.com/azureml/curated/sklearn-1.1:30\n\nRUN mkdir -p data\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\n\nOverwriting simulation/Dockerfile\n\n\n\n%%writefile simulation/Dockerfile\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\n\nWORKDIR /\n\nENV CONDA_PREFIX=/azureml-envs/sklearn-1.1\nENV CONDA_DEFAULT_ENV=$CONDA_PREFIX\nENV PATH=$CONDA_PREFIX/bin:$PATH\n\n# This is needed for mpi to locate libpython\nENV LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH\n\n# Create conda environment\nRUN mkdir -p data\nCOPY hello_world.yml .\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nRUN conda env create -p $CONDA_PREFIX -f conda_dependencies.yaml -q && \\\n    rm conda_dependencies.yaml && \\\n    conda run -p $CONDA_PREFIX pip cache purge && \\\n    conda clean -a -y\n\nOverwriting Dockerfile\n\n\n\n\n\n#docker pull mcr.microsoft.com/azureml/curated/sklearn-1.1:30\ndocker build -t hello_world .\ndocker run -v ~/cloudfiles/code/Users/jau.m/home/posts/data_science/simulation/:/host_dir -it --entrypoint bash hello_world\nLet’s try running the first job of the pipeline function: preprocessing_training_job.For this, we first look how the script needs to be run from command line, as indicated in the command call of the preprocessing component:\n\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n\nThen, in order to see what the inputs inputs.input_file, ìnputs.x and inputs.output_filename are, we look at how the preprocessing_training_job is created:\n\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n\nand, in order to fill in those values we look at the ones passed to the pipeline function:\n\n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n\nIf we just replace those, we get:\n\npython preprocessing.py --input config.preprocessing_training_input_file config.preprocessing_training_output_filename -x config.x\n\n\nThese values are given in the config file, so we visualize it:\n\n\n!cat configs/pipeline_input.json\n\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\",\n    \"docker_context_path\": \".\"\n}\n\n\nWith all this, we can put the pieces togeher. The names of the ouput folders are automatically generated by AML, and the folders automatically created. In our case, we will the name the ouput folder as preprocessing_training_ouput_folder, and create it before hand. We also have to copy the script my_lib/aml/preprocessing.py to current folder. Putting all together, we run the following in command line inside the docker container:\ncp host_dir/my_lib/aml/preprocessing.py .\nmkdir preprocessing_training_ouput_folder\npython preprocessing.py --input ./data/dummy_input.csv --output_folder preprocessing_training_ouput_folder --output_filename preprocessed_training_data.csv -x 10 \n\n\n\n\nIn order to use a custom docker image, we need to use a different way of creating the environment:\nenv = Environment(\n    build=BuildContext(path=docker_context_path),\n    name=name_env,\n    description=description_env,\n)\nThis change affects the function create_env in aml_utils.py:\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    if docker_context_path is None:\n        \"Creates environment in AML workspace\"\n        env = Environment (\n            image=image,\n            conda_file=conda_file,\n            name=name_env,\n            description=description_env,\n        )\n    else:\n        env = Environment(\n            build=BuildContext(path=docker_context_path),\n            name=name_env,\n            description=description_env,\n        )\n    ml_client.environments.create_or_update (env)\nThe change also affects functions that call create_env (connect_setup_and_run in aml_utils.py, and run_pipeline in hello_world_pipeline.py), since they need to pass the additional parameter docker_context_path. We also need to import BuildContext from azure.ai.ml.entities. With these changes, the complete aml_utils.py file is as follow:\n\n%%writefile aml_utils.py\n# Standard imports\nimport json\n\n# Third-party imports\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import MLClient\nfrom azure.ai.ml.entities import Environment, BuildContext\nfrom azure.identity import DefaultAzureCredential\n\ndef connect ():\n    \"\"\"Connects to Azure ML workspace and returns a handle to use it.\"\"\"\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    if docker_context_path is None:\n        \"Creates environment in AML workspace\"\n        env = Environment (\n            image=image,\n            conda_file=conda_file,\n            name=name_env,\n            description=description_env,\n        )\n    else:\n        env = Environment(\n            build=BuildContext(path=docker_context_path),\n            name=name_env,\n            description=description_env,\n        )\n    ml_client.environments.create_or_update (env)\n    \ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n        docker_context_path=docker_context_path,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    config = Bunch (**config)\n\n    return config\n\nOverwriting aml_utils.py\n\n\n\ncp aml_utils.py simulation/\n\nAML documentation\nTutorial\n\n\n\nAdd the following line to the previous config file: \"docker_context_path\": \".\"\n\n%%writefile configs/pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\",\n    \"docker_context_path\": \".\"\n}\n\nOverwriting configs/pipeline_input.json\n\n\n\nrm configs/untitled.txt\n\nrm: cannot remove 'configs/untitled.txt': No such file or directory\n\n\nNo need\n\n\n\n\n\nSame imports section:\n\n%%writefile simulation/hello_world_pipeline.py\n# Standard imports\nimport argparse\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n)\n\n# Utility functions\nfrom aml_utils import (\n    connect,\n    create_env,\n    connect_setup_and_run,\n    read_config,\n)\n\n\nOverwriting hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\n@dsl.pipeline(\n    description=\"Simulation hello-world\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n        \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"hello-world@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \n\nAppending to hello_world_pipeline.py\n\n\n\n\n\nNext we define a function that both creates and runs the pipeline implemented above. This function performs all the steps implemented so far: it reads a config file, instantiates a pipeline object by calling our three_components_pipeline function, and finally performs the pipeline set-up and runs it by calling connect_setup_and_run:\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n        docker_context_path=config.docker_context_path,\n    )\n    \n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"configs/pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"simulation\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n\ncd simulation\n\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/jaumecpu/code/Users/jau.m/home/posts/data_science/simulation\n\n\n\n%run hello_world_pipeline.py\n\nRunning hello-world pipeline with args Namespace(config_path='configs/pipeline_input.json', experiment_name='simulation')\nRunId: upbeat_leg_dmp9bcvs9y\nWeb View: https://ml.azure.com/runs/upbeat_leg_dmp9bcvs9y?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-22 16:10:08Z] Submitting 2 runs, first five are: b47b7c2a:96c70098-5988-4f87-82e5-533cf367757a,f0c6ed40:8447c9f9-a361-4615-961a-f9362407c3fe\n[2024-04-22 16:20:46Z] Completing processing run id 96c70098-5988-4f87-82e5-533cf367757a.\n[2024-04-22 16:20:46Z] Completing processing run id 8447c9f9-a361-4615-961a-f9362407c3fe.\n[2024-04-22 16:20:47Z] Submitting 1 runs, first five are: 0ef51f82:68e226d8-0c7a-4d40-ab80-df94e1eae12e\n[2024-04-22 16:21:09Z] Completing processing run id 68e226d8-0c7a-4d40-ab80-df94e1eae12e.\n[2024-04-22 16:21:10Z] Submitting 1 runs, first five are: 005c2297:9906cb00-9ecf-4b37-9a83-58942197aef9\n[2024-04-22 16:21:33Z] Completing processing run id 9906cb00-9ecf-4b37-9a83-58942197aef9.\n\nExecution Summary\n=================\nRunId: upbeat_leg_dmp9bcvs9y\nWeb View: https://ml.azure.com/runs/upbeat_leg_dmp9bcvs9y?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nFound the config file in: /config.json\nUploading simulation (0.04 MBs): 100%|██████████| 43370/43370 [00:01&lt;00:00, 38468.84it/s]"
  },
  {
    "objectID": "posts/data_science/simulation.html#simulation",
    "href": "posts/data_science/simulation.html#simulation",
    "title": "Simulation",
    "section": "",
    "text": "conda env includes current module, with setup.py and settings.ini from nbdev\nThe pipeline is run from a python_scripts folder.\nThe conda env is in root folder.\nThe config in a configs folder.\nThe components are in mylib/aml folder.\nWe add a docker file that copies files such as setup.py, settings.ini, data, wheels, etc. (everything needed by the component scripts, which is basically everything copied to simulation folder, except for the json file used for config of how the pipeline is built (e.g., the one indicating the name of the environment, etc.)\n\nWe are going to try two methods: one based on python image, and another based on aml image.\n\n\n\n\n\n\nimport os\nimport shutil\n\nos.makedirs ('simulation/python_scripts', exist_ok=True)\nos.makedirs ('simulation/my_lib/aml', exist_ok=True)\nos.makedirs ('simulation/configs', exist_ok=True)\nos.makedirs ('simulation/data', exist_ok=True)\n\n# shutil.copy ('./hello_world.yml', 'simulation') =&gt; a different one will be created \nshutil.copy ('./pipeline_input.json', 'simulation/configs')\n\nshutil.copy ('preprocessing/preprocessing.py', 'simulation/my_lib/aml')\nshutil.copy ('training/training.py', 'simulation/my_lib/aml')\nshutil.copy ('inference/inference.py', 'simulation/my_lib/aml')\n\nshutil.copy ('data/dummy_input.csv', 'simulation/data')\nshutil.copy ('data/dummy_test.csv', 'simulation/data')\n\n\n\n\ncd ../../..\ngit clone https://github.com/fastai/nbdev.git\ncp nbdev/settings.ini home/posts/data_science/simulation\ncp nbdev/setup.py home/posts/data_science/simulation\ncd home/posts/data_science/simulation\n\n\n\nEdit the settings.ini file and replace the following entries as follows:\nlib_name = my_lib\nrepo = simulation\nrequirements = pandas\n               scikit-learn\n               numpy\ndev_requirements = joblib\n                   azure-ai-ml\nlib_path = my_lib\nThen remove the following entries:\npip_requirements\nconda_requirements\ndev_requirements\nconsole_scripts\n\n\n\n\n%%writefile simulation/hello_world.yml\nname: hello_world\ndependencies:\n    - python=3.10\n    - pip\n    - pip:\n        - -e .[dev]\n\nOverwriting simulation/hello_world.yml\n\n\n\n\n\nI just searched in the list of curated environments present in my workspace, using the keyword sklearn in the search text box. At the time of writing this tutorial, the environment found is sklearn-1.1:30. By clicking on it, and then on the Context tab, we can read its dockerfile, which indicates, in the first line, the base docker image used: FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1.\nI found documentation about the docker image to be used by googling “docker mcr.microsoft.com/azureml/openmpi4.1.0”, which provided the following URL: https://hub.docker.com/_/microsoft-azureml. In there, we can find additional links: - https://github.com/Azure/AzureML-Containers =&gt; contains docker files for each image - Note: SDK code contained in this link is v1.\nWe can also explore this docker image by running it in interactive mode (see a cheat sheet of docker commands in here and here):\ndocker pull mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\ndocker run -it --entrypoint bash mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\nIn this tutorial we can see how to test this docker image :\ndocker run --rm -d -v $PWD/$BASE_PATH:$MODEL_BASE_PATH -p 8501:8501 \\\n -e MODEL_BASE_PATH=$MODEL_BASE_PATH -e MODEL_NAME=$MODEL_NAME \\\n --name=\"tfserving-test\" docker.io/tensorflow/serving:latest\nsleep 10\n\n\nEither copy the dockerfile and replace the line:\nCOPY conda_dependencies.yaml .\nwith:\nRUN mkdir -p data\nCOPY &lt;MY-CONDA-ENV-YAML&gt; .\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nand change the name conda_dependencies.yaml with  everywhere else in the file…\nor name your conda env file conda_dependencies.yaml:\nmv simulation/hello_world.yml simulation/conda_dependencies.yaml\nand use the curated docker image as base image in your dockerfile:\nFROM mcr.microsoft.com/azureml/curated/sklearn-1.1:30\n\nRUN mkdir -p data\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nNote that we can dedicate a specific folder for all the files that need to be copied and used in the Dockerfile, including conda_dependencies.yaml.\n\n\n\nFrom the two possibilities mentioned above, we use the first one, which is more modular:\n\ncd ..\n\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/jaumecpu/code/Users/jau.m/home/posts/data_science\n\n\n\nmv simulation/hello_world.yml simulation/conda_dependencies.yaml\n\nmv: cannot stat 'simulation/hello_world.yml': No such file or directory\n\n\n\n%%writefile simulation/Dockerfile\nFROM mcr.microsoft.com/azureml/curated/sklearn-1.1:30\n\nRUN mkdir -p data\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\n\nOverwriting simulation/Dockerfile\n\n\n\n%%writefile simulation/Dockerfile\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240415.v1\n\nWORKDIR /\n\nENV CONDA_PREFIX=/azureml-envs/sklearn-1.1\nENV CONDA_DEFAULT_ENV=$CONDA_PREFIX\nENV PATH=$CONDA_PREFIX/bin:$PATH\n\n# This is needed for mpi to locate libpython\nENV LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH\n\n# Create conda environment\nRUN mkdir -p data\nCOPY hello_world.yml .\nCOPY settings.ini .\nCOPY setup.py .\nCOPY data/dummy_input.csv data/\nCOPY data/dummy_test.csv data/\nCOPY data/dummy_test.csv data/\nRUN conda env create -p $CONDA_PREFIX -f conda_dependencies.yaml -q && \\\n    rm conda_dependencies.yaml && \\\n    conda run -p $CONDA_PREFIX pip cache purge && \\\n    conda clean -a -y\n\nOverwriting Dockerfile\n\n\n\n\n\n#docker pull mcr.microsoft.com/azureml/curated/sklearn-1.1:30\ndocker build -t hello_world .\ndocker run -v ~/cloudfiles/code/Users/jau.m/home/posts/data_science/simulation/:/host_dir -it --entrypoint bash hello_world\nLet’s try running the first job of the pipeline function: preprocessing_training_job.For this, we first look how the script needs to be run from command line, as indicated in the command call of the preprocessing component:\n\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n\nThen, in order to see what the inputs inputs.input_file, ìnputs.x and inputs.output_filename are, we look at how the preprocessing_training_job is created:\n\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n\nand, in order to fill in those values we look at the ones passed to the pipeline function:\n\n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n\nIf we just replace those, we get:\n\npython preprocessing.py --input config.preprocessing_training_input_file config.preprocessing_training_output_filename -x config.x\n\n\nThese values are given in the config file, so we visualize it:\n\n\n!cat configs/pipeline_input.json\n\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\",\n    \"docker_context_path\": \".\"\n}\n\n\nWith all this, we can put the pieces togeher. The names of the ouput folders are automatically generated by AML, and the folders automatically created. In our case, we will the name the ouput folder as preprocessing_training_ouput_folder, and create it before hand. We also have to copy the script my_lib/aml/preprocessing.py to current folder. Putting all together, we run the following in command line inside the docker container:\ncp host_dir/my_lib/aml/preprocessing.py .\nmkdir preprocessing_training_ouput_folder\npython preprocessing.py --input ./data/dummy_input.csv --output_folder preprocessing_training_ouput_folder --output_filename preprocessed_training_data.csv -x 10 \n\n\n\n\nIn order to use a custom docker image, we need to use a different way of creating the environment:\nenv = Environment(\n    build=BuildContext(path=docker_context_path),\n    name=name_env,\n    description=description_env,\n)\nThis change affects the function create_env in aml_utils.py:\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    if docker_context_path is None:\n        \"Creates environment in AML workspace\"\n        env = Environment (\n            image=image,\n            conda_file=conda_file,\n            name=name_env,\n            description=description_env,\n        )\n    else:\n        env = Environment(\n            build=BuildContext(path=docker_context_path),\n            name=name_env,\n            description=description_env,\n        )\n    ml_client.environments.create_or_update (env)\nThe change also affects functions that call create_env (connect_setup_and_run in aml_utils.py, and run_pipeline in hello_world_pipeline.py), since they need to pass the additional parameter docker_context_path. We also need to import BuildContext from azure.ai.ml.entities. With these changes, the complete aml_utils.py file is as follow:\n\n%%writefile aml_utils.py\n# Standard imports\nimport json\n\n# Third-party imports\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import MLClient\nfrom azure.ai.ml.entities import Environment, BuildContext\nfrom azure.identity import DefaultAzureCredential\n\ndef connect ():\n    \"\"\"Connects to Azure ML workspace and returns a handle to use it.\"\"\"\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    if docker_context_path is None:\n        \"Creates environment in AML workspace\"\n        env = Environment (\n            image=image,\n            conda_file=conda_file,\n            name=name_env,\n            description=description_env,\n        )\n    else:\n        env = Environment(\n            build=BuildContext(path=docker_context_path),\n            name=name_env,\n            description=description_env,\n        )\n    ml_client.environments.create_or_update (env)\n    \ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n    docker_context_path=None,\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n        docker_context_path=docker_context_path,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    config = Bunch (**config)\n\n    return config\n\nOverwriting aml_utils.py\n\n\n\ncp aml_utils.py simulation/\n\nAML documentation\nTutorial\n\n\n\nAdd the following line to the previous config file: \"docker_context_path\": \".\"\n\n%%writefile configs/pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\",\n    \"docker_context_path\": \".\"\n}\n\nOverwriting configs/pipeline_input.json\n\n\n\nrm configs/untitled.txt\n\nrm: cannot remove 'configs/untitled.txt': No such file or directory\n\n\nNo need\n\n\n\n\n\nSame imports section:\n\n%%writefile simulation/hello_world_pipeline.py\n# Standard imports\nimport argparse\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n)\n\n# Utility functions\nfrom aml_utils import (\n    connect,\n    create_env,\n    connect_setup_and_run,\n    read_config,\n)\n\n\nOverwriting hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\n@dsl.pipeline(\n    description=\"Simulation hello-world\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n        \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./my_lib/aml/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"hello-world@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \n\nAppending to hello_world_pipeline.py\n\n\n\n\n\nNext we define a function that both creates and runs the pipeline implemented above. This function performs all the steps implemented so far: it reads a config file, instantiates a pipeline object by calling our three_components_pipeline function, and finally performs the pipeline set-up and runs it by calling connect_setup_and_run:\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n        docker_context_path=config.docker_context_path,\n    )\n    \n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"configs/pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"simulation\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n%%writefile -a simulation/hello_world_pipeline.py\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nAppending to hello_world_pipeline.py\n\n\n\n\n\n\n\ncd simulation\n\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/jaumecpu/code/Users/jau.m/home/posts/data_science/simulation\n\n\n\n%run hello_world_pipeline.py\n\nRunning hello-world pipeline with args Namespace(config_path='configs/pipeline_input.json', experiment_name='simulation')\nRunId: upbeat_leg_dmp9bcvs9y\nWeb View: https://ml.azure.com/runs/upbeat_leg_dmp9bcvs9y?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-22 16:10:08Z] Submitting 2 runs, first five are: b47b7c2a:96c70098-5988-4f87-82e5-533cf367757a,f0c6ed40:8447c9f9-a361-4615-961a-f9362407c3fe\n[2024-04-22 16:20:46Z] Completing processing run id 96c70098-5988-4f87-82e5-533cf367757a.\n[2024-04-22 16:20:46Z] Completing processing run id 8447c9f9-a361-4615-961a-f9362407c3fe.\n[2024-04-22 16:20:47Z] Submitting 1 runs, first five are: 0ef51f82:68e226d8-0c7a-4d40-ab80-df94e1eae12e\n[2024-04-22 16:21:09Z] Completing processing run id 68e226d8-0c7a-4d40-ab80-df94e1eae12e.\n[2024-04-22 16:21:10Z] Submitting 1 runs, first five are: 005c2297:9906cb00-9ecf-4b37-9a83-58942197aef9\n[2024-04-22 16:21:33Z] Completing processing run id 9906cb00-9ecf-4b37-9a83-58942197aef9.\n\nExecution Summary\n=================\nRunId: upbeat_leg_dmp9bcvs9y\nWeb View: https://ml.azure.com/runs/upbeat_leg_dmp9bcvs9y?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nFound the config file in: /config.json\nUploading simulation (0.04 MBs): 100%|██████████| 43370/43370 [00:01&lt;00:00, 38468.84it/s]"
  },
  {
    "objectID": "posts/data_science/simulation.html#end",
    "href": "posts/data_science/simulation.html#end",
    "title": "Simulation",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "posts/education/learning_visually.html",
    "href": "posts/education/learning_visually.html",
    "title": "Learning visually",
    "section": "",
    "text": "I recently joined the amazing exercism community. Exercism is an online free coding platform that encourages learning programming languages through practice, free mentorship by volunteers, and exposure to similar solutions once our own solution has been submitted and passes the tests. Each exercise comes with associated learning material, which is a concise description of the concepts that are strictly required for attempting the exercise. However, the focus is always to encourage the students to learn through problem solving, while autonomously investigating the bits that are required. This follows closely recent research on education and neuroscience.\nI would like to share related thoughts on learning through practice, visual learning, and mathematics or related disciplines. The following are just short notes on this matter, that can serve both as a high-level roadmap to a potential long-term project, and contain some references that I would like to keep in mind and expand in the future.\nI found exercism to be a nicely designed platform that, being open source, could be extended to be applied to other domains beyond programming languages, and in particular to math problems. We could then use libraries to describe the problems visually, similar to what 3blue1brown does. By presenting math problems as both visual puzzles and in its original text form, we can make the problem more appealing, following the the ideas of Jo Boaler, e.g., in Mathematical mindsets, and visual mathematics. It would be nice if the student could manipulate the problem visually (i.e., manipulating and transforming the graphical elements with a mouse), and if the problem could be presented not only in 2D but also in 3D (using Virtual Reality, ideally), so that the student is able to also manipulate the objects in a sort-of “physical” world (be it through a game that emulates this world, or through gadgets like glasses and gloves, to have a better sensorial experience, although this would only be accessible by people able to buy those gadgets, unfortunately).\nMichael Nielsen has written very nice essays on these lines, under the title “Tools for Thought”. In particular, his essays Toward an exploratory medium for mathematics, Thought as a Technology, How can we develop transformative tools for thought? and Reinventing Explanation. Similar ideas are recently being developed by many scientists and educators and put in practice in journals such as Distill. I will be including those references in here as I find them, with a brief description, to serve as sources for the future."
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html",
    "href": "posts/education/resources_early_childhood_education.html",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "",
    "text": "The following provides a compact listing about resources and material I found interesting, on both parenting and early childhood education. This includes books, blogs, and podcasts. The intent is to make use of those resources, plus notes collectedfrom our parenting coach, as a source of material for subsequent posts on the topic of parenting and early childhood education. Some of the books are still in my to-read list, which I indicate by an un-checked box. Books in the “in-progress” list are colored in purple, and they are left unchecked if I read just a few chapters."
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#parenting",
    "href": "posts/education/resources_early_childhood_education.html#parenting",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Parenting",
    "text": "Parenting\n\nBooks\n\nThe Whole-Brain Child: 12 Revolutionary Strategies to Nurture Your Child’s Developing Mind by Daniel J. Siegel and Tina Payne Bryson\nBrain Rules for Baby (Updated and Expanded): How to Raise a Smart and Happy Baby Child from Zero to Five by John Medina\nHow Children Succeed: Grit, Curiosity, and the Hidden Power of Character by Paul Tough\nHow to Talk So Kids Will Listen & Listen So Kids Will Talk by Adele Faber and Elaine Mazlish\nNo-Drama Discipline. The Whole-Brain Way to Calm the Chaos and Nurture Your Child’s Developing Mind by Daniel J. Siegel and Tina Payne Bryson\nParenting from the Inside Out. How A Deeper Self-Understanding Can Help You Raise Children Who Thrive by Daniel J. Siegel and Mary Hartzell\nHow To Get Kids To Say Yes!: Using the Secret Four Color Languages to Get Kids to Listen by\n\n\n\nBlogs and websites\n\n50 OF THE BEST BOOKS FOR PARENTS\nPathways\nResources from Erikson Institute"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#early-childhood-education",
    "href": "posts/education/resources_early_childhood_education.html#early-childhood-education",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Early Childhood Education",
    "text": "Early Childhood Education\n\nBooks\n\nWhere’s the Math? Books, Games, and Routines to Spark Children’s Thinking\nTools of the Mind: The Vygotskian Approach to Early Childhood Education (2nd Edition) by elena Bodrova and Deorah J. Leong\nWho Am I in the Lives of Children? An Introduction to Early Childhood Education (10th Edition) by Stephanie Feeney and Eva Moravick\nMind in the Making: The Seven Essential Life Skills Every Child Needs by Ellen Galinsky\nThe Complete Resource Book for Preschoolers: Over 2000 Activities and Ideas (Complete Resource Series) by Pam Schiller and Kay Hastings\n\n\n\nBlogs and websites\n\nEarly Math Collaborative from Erikson Institute\nTHE 40 BEST BOOKS ON EARLY CHILDHOOD EDUCATION"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#general-education",
    "href": "posts/education/resources_early_childhood_education.html#general-education",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "General Education",
    "text": "General Education\n\nMath Education\n\nBooks\n\nHow I Wish I’d Taught Maths: Lessons learned from research, conversations with experts, and 12 years of mistakes: Reflections on research, conversations with experts, and 12 years of mistakes.\nMathematics for human flourishing\nMathematical mindsets\nChange Is the Only Constant: The Wisdom of Calculus in a Madcap World\nMath with bad drawings\n\n\n\nBlogs and websites\n\n3Blue1Brown"
  },
  {
    "objectID": "posts/education/resources_early_childhood_education.html#learning-to-learn",
    "href": "posts/education/resources_early_childhood_education.html#learning-to-learn",
    "title": "Resources on Parenting & Early Childhood Education",
    "section": "Learning to learn",
    "text": "Learning to learn\n\nBooks\n\nMake It Stick: The Science of Successful Learning by Henry L. Roediger III, Mark A. McDaniel, Peter C. Brown\n\n\n\nBlogs and websites\n\nTechniques for Efficiently Learning Programming Languages. Despite the title, this post provides many useful tips for learning to learn in general.\nRecommendations about how to learn mathematics in an enjoyable way"
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html",
    "href": "posts/health/tenacity_and_will_power.html",
    "title": "Tenacity and will power",
    "section": "",
    "text": "This post is just a series of short notes I wrote for myself, on general strategies to achieve tenacity / will power goals."
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html#introduction",
    "href": "posts/health/tenacity_and_will_power.html#introduction",
    "title": "Tenacity and will power",
    "section": "",
    "text": "This post is just a series of short notes I wrote for myself, on general strategies to achieve tenacity / will power goals."
  },
  {
    "objectID": "posts/health/tenacity_and_will_power.html#strategies",
    "href": "posts/health/tenacity_and_will_power.html#strategies",
    "title": "Tenacity and will power",
    "section": "Strategies",
    "text": "Strategies\nThese are the (evolving) strategies I would like to follow:\n\nClearly write goal objectives before trying. Dieting example: always write I will be eating that day,before eating. This is what I can eat today: menu with 2000 calories for example, 30% fat, 25% protein, 10% sugar.\n\nWrite down times: time when I start breakfast, and duration (end time). Time when I start lunch (if I do it), and duration (end time). Total eating window time (end lunch - beginning breakfast). It should always be lower than 8 hours. No snacks in between.\nWrite down all the coffees and teas, and their times.\nExtra: may be also the regular drinks (e.g., water), to see how this affects sleep.\nAt least something at coarse level, that has just a reasonable accuracy.\n\nDieting or other goals: Always write down what I have eaten (or whatever the goal was). That’s even more important than meeting objectives. I need to know, if I don’t meet them, why I haven’t and what could’ve done better or changed for meeting them. Write this down as well, every time.\n\nAbout writing down what I eat, it doesn’t need to be super-accurate. But at least something at coarse level, that has just a reasonable accuracy.\n\nSleep objectives. If I don’t meet them, what should I’ve done better, what subset of objectives (e.g., number of coffees) I didn’t meet and which strategies I could’ve followed to meet them. Always have empathy and kindness towards myself, not be harsh, but do not stop trying.\nBuy all the necessary wearables: sleep, glucose, lactose and maybe heart rate (because of its relantionship with will power).\nContinue reading, for instance papers about super-agers and how they get will power. Write down a blog summarizing my findings.\nIzan:\n\nwrite down notes from Anita and publish them.\nlook for strategies on savings, and publish them."
  },
  {
    "objectID": "posts/health/physical_health.html",
    "href": "posts/health/physical_health.html",
    "title": "Healthspan and lifespan",
    "section": "",
    "text": "Findings regarding best protocols on health."
  },
  {
    "objectID": "posts/health/physical_health.html#sleep",
    "href": "posts/health/physical_health.html#sleep",
    "title": "Healthspan and lifespan",
    "section": "Sleep",
    "text": "Sleep\n\nThe single most important thing seems to be sleeping well, close to eight hours per day.\nCoffee, while having its benefits, needs to be avoided from noon. Ideally, the latest coffee should be taken no later than twelve hours before going to sleep."
  },
  {
    "objectID": "posts/health/physical_health.html#nutrition",
    "href": "posts/health/physical_health.html#nutrition",
    "title": "Healthspan and lifespan",
    "section": "Nutrition",
    "text": "Nutrition\n\nFasting\n\nIntermitent fasting. Specifically, time-restricted fasting, although there are other appropriate forms of intermitent fasting.\nFasting up to one week, three times per year, with keto diet the week before and the week after.\n\nIf fasting is done for more than three days, we might have our sleep affected. To avoid that, we need to take some supplements. I need to find their name.\n\nFasting for up to 48 hours once per month.\n\n\n\nDiet: plant-based with fish\n\nSpecifically, salmon and other blue fishes rich in omega-3\nIt seems to be slightly better than a pure vegan diet, which in turn is better than a meat-based western diet."
  },
  {
    "objectID": "posts/health/physical_health.html#nutrition-to-keep-guts-microbiome-healthy.",
    "href": "posts/health/physical_health.html#nutrition-to-keep-guts-microbiome-healthy.",
    "title": "Healthspan and lifespan",
    "section": "Nutrition to keep gut’s microbiome healthy.",
    "text": "Nutrition to keep gut’s microbiome healthy."
  },
  {
    "objectID": "posts/health/physical_health.html#exercise",
    "href": "posts/health/physical_health.html#exercise",
    "title": "Healthspan and lifespan",
    "section": "Exercise",
    "text": "Exercise\n\nCardio\n\nCardio seems to be the most important exercise of all.\nIn order to avoid removing the benefits of doing cardio, we need to stay on stand-up position at least 50% of the day, rather than sitting. For office jobs, a standing desk is advisable.\nCardio can be done by running, using air-bike, or using stairs, among others.\nWe need to arrive to Zone 2, several days per week. A proxy for this is to achieve the maximum intensity while still being able to keep a conversation while doing the exercise.\nWe need to have a high-intensity exercise at least 10 minutes? (I need to check this) per week. This is exercise would be the next level to zone 2, i.e., not being able to have a conversation while doing it.\n\n\nAvoiding injuries while running\n\nWarmup before running: exercises.\nStrecth after running: exercises\nDo knee exercises\nStart running progressively: plan"
  },
  {
    "objectID": "posts/health/index.html",
    "href": "posts/health/index.html",
    "title": "Health",
    "section": "",
    "text": "Agency and gratitude\n\n\n\n\n\n\n\n\n\n\n\n\n\nHealthspan and lifespan\n\n\nPhysical health: resources and protocols\n\n\n\n\n\n\n\n\n\n\nTenacity and will power TIL\n\n\nLessons from Huberman podcast\n\n\n\n\n\n\n\n\n\n\nTenacity and will power\n\n\nPotential strategies\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/others/podcasts.html",
    "href": "posts/others/podcasts.html",
    "title": "Podcasts",
    "section": "",
    "text": "Note: this post is, at this moment, just a draft in progress.\nI have been a podcast and audio-book listener for the last few years. In this post, I would like to list and briefly describe the podcasts that I find interesting, and point to relevant sources."
  },
  {
    "objectID": "posts/others/podcasts.html#list-of-podcasts",
    "href": "posts/others/podcasts.html#list-of-podcasts",
    "title": "Podcasts",
    "section": "List of podcasts",
    "text": "List of podcasts\n\nGeneral\n\nLex Fridman Podcast: long-format (&gt;= 3h) interviews with interesting people of all types: literature, education, health, science, religion, politics… It started focusing on AI (the domain he is expert on), then expanded to science and software in general, then to everything. Very interesting guests IMO, most of them previously unknown by me.\nJoe Rogan Experience: Similar to Lex Fridman podcast. i found many interesting personalities in this podcast, and Joe has this capacity of making every conversation a fascinating one, and showing respect and interest towards points of view that are quite different from his own ones. However, there are few things that make me get away from it sometimes: he tends to bring many UFC fighters and comedians, which are the two things he is expert on. I like martial arts, but this high bias towards this type of guests is not ideal for me. He also tends to criticize previous guests when they are not there, even if he doesn’t do any criticism when the guest is there (at least not during the time I listen, sometimes I stop after one or two hours, and I should wait until the end to be sure about this).\n\n\n\nHealth\n\nHuberman Lab Podcast: mental and physical health, performance, and well-being in general. Dr. Andrew Huberman is a neuroscientist and professor at the Standford School of Medicine. This podcast combines interviews with guests, many of them well-known scientists and pioneers in their field, with discussions about where he covers specific topics that he and his team have been researching for the podcast.\nThe Peter Attia Drive Podcast: focused on latest research for increasing longevity, healthspan and lifespan. Dr. Peter Attia is the author of Outlive, and has a dedicated practice for studying and researching causes and solutions of age-related diseases, and how to stay healthy until the last years of our life.\nDr Chaterjee: mostly interviews with guests from the health sector, occasionally having well-known guests from other domains, usually with some relationship with health and well-being in general.\n\n\n\nEducation\n\nMr Barton Maths Podcast: education in mathematics (mostly secondary education), but extrapolable to education in general, as it talks about research in education, which in turn comes from fields such as neuroscience and psychology, and is applicable to many fields beyond mathematics.\n3blue1brown podcast: interviews, mostly with mathematicians. Even if you don’t like maths (which to be honest it is not something I’m really an expert on), i find the conversations very interesting, and amenable for non-mathematicians like myself.\n\n\n\nParenting\n\nRasing Good Humans: I listened to some of the episodes but still have to listen to more.\nParent-Driven Development: just listened to a couple of podcasts. Informal conversations with parents involved in technology and software in particular: how they teach their children, what strategies they use to keep a good work-life balance, etc.\n\n\n\nMisc.\n\nThe Rest is History: Great podcast about both recent and ancient history, with in-depth coverage of different curious and interesting events, personalities, and cultures.\nThe Rest is Money: I discovered this through the Rest is History. It is a different way to follow recent developments, here focused on the ones having impact on the economy.\nGlobal News Podcast from the BBC. It has two episodes per day, 30 min each."
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html",
    "href": "additional/data_science/aml/experiments/hello_component.html",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Create component from script.\nRegister component in AML.\nNext steps\n\n\n\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\n\nWe specify a job using the command decorator:\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Towards component Hello World\",\n)\n\n\nml_client.create_or_update(job)\n\nUploading data_science (18.84 MBs): 100%|██████████| 18841759/18841759 [00:00&lt;00:00, 21054056.71it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\ncalm_feather_z584zn3lrr\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\n\n\nThe component appears in Jobs tab, but doesn’t appear in Components tab.\nThe job appears under a experiment with the same name as the folder the notebook is in, “data_science”. The “latest job” column shows the last display name indicated, which at this momemnt is “Towards component Hello World”, but it will be a different name later as we run other components.\nIf you want to differentiate between jobs, you can add the following entry in the command function: experiment_name=\"my-new-experiment\"\n\n\n\n\n\nLet’s see what happens when we give the component a name.\n\njob = command(\n    name=\"with_name_no_component\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using name\",\n)\n\n\n# Now we register the component to the workspace\ndata_prep_component = ml_client.create_or_update(job)\n\nUploading data_science (12.65 MBs): 100%|██████████| 12646567/12646567 [00:00&lt;00:00, 16266221.53it/s]\n\n\nBad pipe message: %s [b'\\xb0\\x01\\xc6vv_c\\xd1 W!', b'\\x14r\\x15]\\xc2 e:\\xb2\\xd0*\\x1f\\xdb\\xf5\\x9b\\t@\\x89\\x07\\xe3m7\\xcf\\xfe\\xcd\\x94SD\\x84pdfv\\xbc8,\\xe5\\xbf\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127']\nBad pipe message: %s [b'.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\nBad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"6{\\x02\\x11\\xbdB\\xe6\\x1e\\xec\\x8fAF\\x88}\\x1a'\\x1d4 \\xe0\\x82'.\\xb5{\\x07\\x9f\\x0e\\r\\x0cs\\x06\\xa4n\\x80d\\xcb\\xe4\\x7f;\\xf8\\x1a\\xfe\\xa1-\\xa1\\xcb\\x8e\\xd8\\x04\\xab\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\", b'\\x08\\x0b\\x08\\x04\\x08\\x05\\x08']\nBad pipe message: %s [b'\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"\\xe20\\r\\xaaRC\\x9b\\xf0J\\xe1\\xb9&lt;\\x0b53\\xd4\\xd6\\x8c\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00&lt;\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\", b'\\x02\\x03', b'\\x02\\x01', b'\\x02\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b\"*G\\xf7\\xbeE\\x11\\xa5\\x84\\x11\\xf5\\xb7\\x84\\x83\\xc0z\\xa8\\xdbt\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00&lt;\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\"]\nBad pipe message: %s [b'\\x072`\\xb7O\\xca\\xae\\x82\\xf5r\\xb6\\x93\\xc1?d\\xd2p\\xfa\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\nBad pipe message: %s [b'?\\x8b\\xef\\xd0\\xef\\xb7\\x8fRP\\x90ES\\nd\\x88\\xc0\\x1f\\xfb\\x00\\x00']\nBad pipe message: %s [b'\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff']\nBad pipe message: %s [b'W\\xee\\x0e&\\xdc[\\xed\\x8dg\\xfbQ\\xa2\\xa2M\\xcc\\xefl\\xbc\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00', b'\\x04\\xc0\\x12\\xc0']\nBad pipe message: %s [b'\\x16\\x00\\x13\\x00\\x10\\x00\\r']\nBad pipe message: %s [b'k\\xb2\\xc1f\\xb5\\xdf\\xb4qJ\\x0e5B46\\x1a\\xf2\\x1c\\xb6\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12']\nBad pipe message: %s [b'\\x08g%\\xcd\\x1b\\xed\\x82$\\xf0\\x87\\xdd\\xff#\\x84\\x81\\xa0\\xf9c\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008']\nBad pipe message: %s [b\"\\x1b\\xa7\\x0f\\xac\\x9c\\x03o\\x13&lt;\\x8bx\\xa3\\xfb\\x16\\x9fN)\\x94\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\"]\nBad pipe message: %s [b'\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n\n\n\n\n\nThe component appears in Jobs tab, but doesn’t appear in Components tab.\n\n\n\n\n\nNow we don’t give it a name but create by passing job.component to ml_client.create_or_update instead of passing just job, as follows:\ndata_prep_component = ml_client.create_or_update(job.component)\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using .component but without name\",\n)\n\n\ndata_prep_component = ml_client.create_or_update(job.component)\n\n\n\n\nThe component doesn’t appear in Jobs tab, and doesn’t appear in Components tab.\n\n\n\n\n\n\njob = command(\n    name=\"with_name\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using .component\",\n)\n\n\n# Now we register the component to the workspace\ndata_prep_component = ml_client.create_or_update(job.component)\n\nUploading data_science (12.63 MBs): 100%|██████████| 12632631/12632631 [00:00&lt;00:00, 16275057.89it/s]\n\n\n\n\n\n\n\nThe component appears in Components tab but doesn’t appear in Jobs tab.\n\n\n\n\n\n\njob = command(\n    name=\"with_name_and_two_times_created\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Creating with and without .component\",\n)\n\n\ndata_prep_component = ml_client.create_or_update(job.component)\ndata_prep_component = ml_client.create_or_update(job)\n\nUploading data_science (12.65 MBs): 100%|██████████| 12646823/12646823 [00:00&lt;00:00, 17475106.66it/s]\n\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\n\n\n\nThe component appears in Components tab and in Jobs tab, but there doesn’t seem to be link between both.\n\n\n\n\n\n\nConnect / reuse created components"
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#set-up",
    "href": "additional/data_science/aml/experiments/hello_component.html#set-up",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "# AML imports\nfrom azure.ai.ml import (\n    command,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#specifying-and-submitting-job",
    "href": "additional/data_science/aml/experiments/hello_component.html#specifying-and-submitting-job",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "We specify a job using the command decorator:\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Towards component Hello World\",\n)\n\n\nml_client.create_or_update(job)\n\nUploading data_science (18.84 MBs): 100%|██████████| 18841759/18841759 [00:00&lt;00:00, 21054056.71it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\ndata_science\ncalm_feather_z584zn3lrr\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\n\n\n\nThe component appears in Jobs tab, but doesn’t appear in Components tab.\nThe job appears under a experiment with the same name as the folder the notebook is in, “data_science”. The “latest job” column shows the last display name indicated, which at this momemnt is “Towards component Hello World”, but it will be a different name later as we run other components.\nIf you want to differentiate between jobs, you can add the following entry in the command function: experiment_name=\"my-new-experiment\""
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#with-name",
    "href": "additional/data_science/aml/experiments/hello_component.html#with-name",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Let’s see what happens when we give the component a name.\n\njob = command(\n    name=\"with_name_no_component\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using name\",\n)\n\n\n# Now we register the component to the workspace\ndata_prep_component = ml_client.create_or_update(job)\n\nUploading data_science (12.65 MBs): 100%|██████████| 12646567/12646567 [00:00&lt;00:00, 16266221.53it/s]\n\n\nBad pipe message: %s [b'\\xb0\\x01\\xc6vv_c\\xd1 W!', b'\\x14r\\x15]\\xc2 e:\\xb2\\xd0*\\x1f\\xdb\\xf5\\x9b\\t@\\x89\\x07\\xe3m7\\xcf\\xfe\\xcd\\x94SD\\x84pdfv\\xbc8,\\xe5\\xbf\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127']\nBad pipe message: %s [b'.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\nBad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"6{\\x02\\x11\\xbdB\\xe6\\x1e\\xec\\x8fAF\\x88}\\x1a'\\x1d4 \\xe0\\x82'.\\xb5{\\x07\\x9f\\x0e\\r\\x0cs\\x06\\xa4n\\x80d\\xcb\\xe4\\x7f;\\xf8\\x1a\\xfe\\xa1-\\xa1\\xcb\\x8e\\xd8\\x04\\xab\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\", b'\\x08\\x0b\\x08\\x04\\x08\\x05\\x08']\nBad pipe message: %s [b'\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"\\xe20\\r\\xaaRC\\x9b\\xf0J\\xe1\\xb9&lt;\\x0b53\\xd4\\xd6\\x8c\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00&lt;\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\", b'\\x02\\x03', b'\\x02\\x01', b'\\x02\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b\"*G\\xf7\\xbeE\\x11\\xa5\\x84\\x11\\xf5\\xb7\\x84\\x83\\xc0z\\xa8\\xdbt\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00&lt;\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\"]\nBad pipe message: %s [b'\\x072`\\xb7O\\xca\\xae\\x82\\xf5r\\xb6\\x93\\xc1?d\\xd2p\\xfa\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\nBad pipe message: %s [b'?\\x8b\\xef\\xd0\\xef\\xb7\\x8fRP\\x90ES\\nd\\x88\\xc0\\x1f\\xfb\\x00\\x00']\nBad pipe message: %s [b'\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff']\nBad pipe message: %s [b'W\\xee\\x0e&\\xdc[\\xed\\x8dg\\xfbQ\\xa2\\xa2M\\xcc\\xefl\\xbc\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00', b'\\x04\\xc0\\x12\\xc0']\nBad pipe message: %s [b'\\x16\\x00\\x13\\x00\\x10\\x00\\r']\nBad pipe message: %s [b'k\\xb2\\xc1f\\xb5\\xdf\\xb4qJ\\x0e5B46\\x1a\\xf2\\x1c\\xb6\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12']\nBad pipe message: %s [b'\\x08g%\\xcd\\x1b\\xed\\x82$\\xf0\\x87\\xdd\\xff#\\x84\\x81\\xa0\\xf9c\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008']\nBad pipe message: %s [b\"\\x1b\\xa7\\x0f\\xac\\x9c\\x03o\\x13&lt;\\x8bx\\xa3\\xfb\\x16\\x9fN)\\x94\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\"]\nBad pipe message: %s [b'\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n\n\n\n\n\nThe component appears in Jobs tab, but doesn’t appear in Components tab."
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#with-.component",
    "href": "additional/data_science/aml/experiments/hello_component.html#with-.component",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Now we don’t give it a name but create by passing job.component to ml_client.create_or_update instead of passing just job, as follows:\ndata_prep_component = ml_client.create_or_update(job.component)\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using .component but without name\",\n)\n\n\ndata_prep_component = ml_client.create_or_update(job.component)\n\n\n\n\nThe component doesn’t appear in Jobs tab, and doesn’t appear in Components tab."
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#with-name-and-.component",
    "href": "additional/data_science/aml/experiments/hello_component.html#with-name-and-.component",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "job = command(\n    name=\"with_name\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Using .component\",\n)\n\n\n# Now we register the component to the workspace\ndata_prep_component = ml_client.create_or_update(job.component)\n\nUploading data_science (12.63 MBs): 100%|██████████| 12632631/12632631 [00:00&lt;00:00, 16275057.89it/s]\n\n\n\n\n\n\n\nThe component appears in Components tab but doesn’t appear in Jobs tab."
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#with-name-and-.component-submitting-two-times",
    "href": "additional/data_science/aml/experiments/hello_component.html#with-name-and-.component-submitting-two-times",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "job = command(\n    name=\"with_name_and_two_times_created\",\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Creating with and without .component\",\n)\n\n\ndata_prep_component = ml_client.create_or_update(job.component)\ndata_prep_component = ml_client.create_or_update(job)\n\nUploading data_science (12.65 MBs): 100%|██████████| 12646823/12646823 [00:00&lt;00:00, 17475106.66it/s]\n\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\n\n\n\nThe component appears in Components tab and in Jobs tab, but there doesn’t seem to be link between both."
  },
  {
    "objectID": "additional/data_science/aml/experiments/hello_component.html#next-steps",
    "href": "additional/data_science/aml/experiments/hello_component.html#next-steps",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Connect / reuse created components"
  },
  {
    "objectID": "additional/data_science/connect_locally.html",
    "href": "additional/data_science/connect_locally.html",
    "title": "Jaume Amores",
    "section": "",
    "text": "Based on https://github.com/Azure/AzureML-Containers/tree/master?tab=readme-ov-file#howtorun\nUsing cheat sheet from https://dockerlabs.collabnix.com/docker/cheatsheet/\n\ndocker pull mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04\ndocker run -it --entrypoint bash mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu22.04"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaume Amores",
    "section": "",
    "text": "Hello, and welcome to my home page! I currently work as a Principal Data Scientist in Johnson Controls. I have been working on Data Science for more than 20 years, in both academia and industry. I received a Ph.D. in Machine Learning and Computer vision in 2006, and have been in industry for more than 10 years, working both as individual contributor and technical lead in multi-disciplinary teams. I enjoy both the theoretical and practical aspects of Data Science, I like developing high quality software based on best practices, and have experience generating intellectual property.\nApart from my work, I am a dad of a little child and I am interested in early childhood education and health. I intend to write about those subjects in my blog posts, above."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Jaume Amores",
    "section": "",
    "text": "Hello, and welcome to my home page! I currently work as a Principal Data Scientist in Johnson Controls. I have been working on Data Science for more than 20 years, in both academia and industry. I received a Ph.D. in Machine Learning and Computer vision in 2006, and have been in industry for more than 10 years, working both as individual contributor and technical lead in multi-disciplinary teams. I enjoy both the theoretical and practical aspects of Data Science, I like developing high quality software based on best practices, and have experience generating intellectual property.\nApart from my work, I am a dad of a little child and I am interested in early childhood education and health. I intend to write about those subjects in my blog posts, above."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jaume Amores",
    "section": "Education",
    "text": "Education\n\nPh.D. in Machine Learning and Computer Vision | Universitat Autonoma de Barcelona | 2006\nM.Sc. in Machine Learning and Computer Vision | Universitat Autonoma de Barcelona | 2003\nB.Sc. in Computer Science | Universitat de Valencia | 2000"
  },
  {
    "objectID": "index.html#open-source",
    "href": "index.html#open-source",
    "title": "Jaume Amores",
    "section": "Open Source",
    "text": "Open Source\nAt the moment I have published one open source library written in python, based on the nbdev+quarto publishing framework. I intend to publish more projects in the future.\n\nnbmodular: link Convert data science notebooks with poor modularity to fully modular notebooks that are automatically exported as python modules."
  },
  {
    "objectID": "additional/data_science/aml/experiments/mlflow_register.html",
    "href": "additional/data_science/aml/experiments/mlflow_register.html",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Download notebook https://github.com/MicrosoftLearning/mslearn-azure-ml/blob/main/Labs/10/Log%20models%20with%20MLflow.ipynb (clone whole repo from https://github.com/MicrosoftLearning/mslearn-azure-ml.git)\nIn notebook, replace\n\ncompute=\"aml-cluster\",\nwith your compute instance’s name.\n\n\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\n\n\n\nBoth\nmlflow.sklearn.autolog()\nand\nmlflow.autolog()\nachieve the same\n\n\n\nWe can avoid logging the model and do it later, by doing:\nmlflow.autolog(log_models=False)\nand later doing:\n\n\nIf we want the signature to be inferred we run:\n\nfrom mlflow.models.signature import infer_signature\n\n# create the signature by inferring it from the datasets\nsignature = infer_signature(X_train, y_hat)\n\n# manually log the model\nmlflow.sklearn.log_model(model, \"model\", signature=signature)    \n\n\n\nIf we want to indicate it manually, we would do something like:\n# create the signature manually\ninput_schema = Schema([\n    ColSpec(\"integer\", \"Pregnancies\"),\n    ColSpec(\"integer\", \"PlasmaGlucose\"),\n    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n    ColSpec(\"integer\", \"TricepsThickness\"),\n    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n    ColSpec(\"integer\", \"SerumInsulin\"),\n    ColSpec(\"double\", \"BMI\"),\n    ColSpec(\"double\", \"DiabetesPedigree\"),\n    ColSpec(\"integer\", \"Age\"),\n])\n\noutput_schema = Schema([ColSpec(\"boolean\")])\n\n# Create the signature object\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# manually log the model\nmlflow.sklearn.log_model(model, \"model\", signature=signature)\n\n\n\n\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\njob_name = returned_job.name\n\nrun_model = Model(\n    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n    name=\"mlflow-diabetes\",\n    description=\"Model created from run.\",\n    type=AssetTypes.MLFLOW_MODEL,\n)\n# Uncomment after adding required details above\nml_client.models.create_or_update(run_model)\nIn the Studio, navigate to the Models page. In the model list, find the mlflow-diabetes model and select it to explore it further.\n\nIn the Details tab of the mlflow-diabetes model, you can review that it’s a MLFLOW type model and the job that trained the model.\nIn the Artifacts tab you can find the directory with the MLmodel file.\n\nIf you want to explore the model’s behavior further, you can optionally choose to deploy the model to a real-time endpoint.\n\n\n\n\nWe see png plots in the outputs+logs tab and in the images tab. These are logged automatically with autolog, during training.\nFor the moment, I don’t see the plots manually saved in the code, in the train-model-sklearn.py script (second one in the notebook)"
  },
  {
    "objectID": "additional/data_science/aml/experiments/mlflow_register.html#set-up",
    "href": "additional/data_science/aml/experiments/mlflow_register.html#set-up",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "# AML imports\nfrom azure.ai.ml import (\n    command,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "additional/data_science/aml/experiments/mlflow_register.html#summary",
    "href": "additional/data_science/aml/experiments/mlflow_register.html#summary",
    "title": "Registering component in Azure ML",
    "section": "",
    "text": "Both\nmlflow.sklearn.autolog()\nand\nmlflow.autolog()\nachieve the same\n\n\n\nWe can avoid logging the model and do it later, by doing:\nmlflow.autolog(log_models=False)\nand later doing:\n\n\nIf we want the signature to be inferred we run:\n\nfrom mlflow.models.signature import infer_signature\n\n# create the signature by inferring it from the datasets\nsignature = infer_signature(X_train, y_hat)\n\n# manually log the model\nmlflow.sklearn.log_model(model, \"model\", signature=signature)    \n\n\n\nIf we want to indicate it manually, we would do something like:\n# create the signature manually\ninput_schema = Schema([\n    ColSpec(\"integer\", \"Pregnancies\"),\n    ColSpec(\"integer\", \"PlasmaGlucose\"),\n    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n    ColSpec(\"integer\", \"TricepsThickness\"),\n    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n    ColSpec(\"integer\", \"SerumInsulin\"),\n    ColSpec(\"double\", \"BMI\"),\n    ColSpec(\"double\", \"DiabetesPedigree\"),\n    ColSpec(\"integer\", \"Age\"),\n])\n\noutput_schema = Schema([ColSpec(\"boolean\")])\n\n# Create the signature object\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# manually log the model\nmlflow.sklearn.log_model(model, \"model\", signature=signature)\n\n\n\n\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\njob_name = returned_job.name\n\nrun_model = Model(\n    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n    name=\"mlflow-diabetes\",\n    description=\"Model created from run.\",\n    type=AssetTypes.MLFLOW_MODEL,\n)\n# Uncomment after adding required details above\nml_client.models.create_or_update(run_model)\nIn the Studio, navigate to the Models page. In the model list, find the mlflow-diabetes model and select it to explore it further.\n\nIn the Details tab of the mlflow-diabetes model, you can review that it’s a MLFLOW type model and the job that trained the model.\nIn the Artifacts tab you can find the directory with the MLmodel file.\n\nIf you want to explore the model’s behavior further, you can optionally choose to deploy the model to a real-time endpoint.\n\n\n\n\nWe see png plots in the outputs+logs tab and in the images tab. These are logged automatically with autolog, during training.\nFor the moment, I don’t see the plots manually saved in the code, in the train-model-sklearn.py script (second one in the notebook)"
  },
  {
    "objectID": "additional/data_science/aml/free_subscription.html",
    "href": "additional/data_science/aml/free_subscription.html",
    "title": "Hello World in Azure ML Pipelines",
    "section": "",
    "text": "Go to : https://azure.microsoft.com/en-gb/free/\n\n\n\n\nGo home: https://portal.azure.com/?quickstart=true#home\nOn the top, in the text search box, type “azure machine learning”\n\n\n\nOn the left, click on the + button, and select create workspace\n\n\n\nNote: As part of creating the workspace, you need to create other resources, like the resource group and storage. I created a resource group with the name “helloworld”, and it populated the remaining fields for me. It is very important to avoid underscores, just letters and digits. The first time I did it, I used “hello_world” and after that I tried to change the name and it kept failing, even without underscore. It seems that after logging out and in again, and choosing an appropriate name without underscore, it succeeds.\n\n\nGo to workspace by clicking on the link that appears on the right, with name “Studio web URL”:\n\n\n\n\n\n\nIn my case, I just selected the cheapest recommended option, and named it “jaumecpu”."
  },
  {
    "objectID": "additional/data_science/aml/free_subscription.html#steps",
    "href": "additional/data_science/aml/free_subscription.html#steps",
    "title": "Hello World in Azure ML Pipelines",
    "section": "",
    "text": "Go to : https://azure.microsoft.com/en-gb/free/\n\n\n\n\nGo home: https://portal.azure.com/?quickstart=true#home\nOn the top, in the text search box, type “azure machine learning”\n\n\n\nOn the left, click on the + button, and select create workspace\n\n\n\nNote: As part of creating the workspace, you need to create other resources, like the resource group and storage. I created a resource group with the name “helloworld”, and it populated the remaining fields for me. It is very important to avoid underscores, just letters and digits. The first time I did it, I used “hello_world” and after that I tried to change the name and it kept failing, even without underscore. It seems that after logging out and in again, and choosing an appropriate name without underscore, it succeeds.\n\n\nGo to workspace by clicking on the link that appears on the right, with name “Studio web URL”:\n\n\n\n\n\n\nIn my case, I just selected the cheapest recommended option, and named it “jaumecpu”."
  },
  {
    "objectID": "posts/others/index.html",
    "href": "posts/others/index.html",
    "title": "Other topics",
    "section": "",
    "text": "Podcasts\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/health/agency_and_gratitude.html",
    "href": "posts/health/agency_and_gratitude.html",
    "title": "Agency and gratitude",
    "section": "",
    "text": "I would like to start contributing following the framework from Dr. Paul Conti. The basic idea is to do things that make me feel good and can help other people at the same time. This can be small things as:\n\nCommenting on interesting reads.\nContributing to open source: my personal project nbmodular, exercism, clojure data science community, and others.\nDo clojure pipeline ala dsblocks.\nReach out to people that are influencing me and ask them questions that may be of interest to others as well, e.g., in twitter, youtube, etc. Examples: David Sinclair, Andrew Huberman, and Peter Attia.\n\nHuberman: difficult task after tenacy task. Did they try to wait until drive/motivation/dopamine comes back to baseline (from the experimented valley)? Are the results as strong in that case? Idea basically is to separate the experiments for long time.\nSinclair: some of the suggested strategies require a lot of will power and tenacity. Do you know of mental strategies that can help us achieve those goals? Tricks such as drinking tea or coffee can be quite effective, but I wonder about strategies focused on dieting, which involve a large amount of tenacity.\nFast.ai: nbdev_export done, link to test tutorials, include examples / demos.\nFinish tenacity podcast and maybe re-listen Paul Conti podcasts book\nFor each X personal things, do one thing that may help (even just a bit) to the community. - Can be for my son - for others Try to find best strategy here, something that makes me feel good and works.\nPotential next project.\n\nLearn R language.\nApplied Statistics for Data Science: null hypothesis tests, etc.\nVisualization techniques and libraries: blogs, kaggle notebooks, other material.\n\nReveal.js / quarto notebooks.\n\nPapers discussed by Huberman, Attia and maybe Sinclair: analyze them from an statistics point of view and write a blog summarizing the findings. Have a list of blogs about this subject.\n\nPotential pitfalls, which ones are stronger from a statistics viewpoint.\nDo rating. Can even be a website with ratings / open review about this type of papers, automatic review that includes ChatGPT type of analysis, etc. With the AI piece we may be able to automatically find sources references and more context information (opinions, rebuttals, etc.) for these papers.\n\nFind kaggle projects, mostly focused on medicine, that can be good to participate in.\n\nAlso for Kaggle Days and social interaction.\n\nCommit myself to write a blog or something everytime I learn something, e.g., TIL like Simon Willison - see his github’s TIL"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html",
    "href": "posts/health/huberman_podcast_will_power.html",
    "title": "Tenacity and will power TIL",
    "section": "",
    "text": "This post is an in-progress Today-I-Learned (TIL) on the awesome Huberman podcast “How to Increase Tenacity & Will Power”"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html#introduction",
    "href": "posts/health/huberman_podcast_will_power.html#introduction",
    "title": "Tenacity and will power TIL",
    "section": "",
    "text": "This post is an in-progress Today-I-Learned (TIL) on the awesome Huberman podcast “How to Increase Tenacity & Will Power”"
  },
  {
    "objectID": "posts/health/huberman_podcast_will_power.html#short-notes-lessons-learned",
    "href": "posts/health/huberman_podcast_will_power.html#short-notes-lessons-learned",
    "title": "Tenacity and will power TIL",
    "section": "Short notes / lessons learned",
    "text": "Short notes / lessons learned\n\nExperts differ on whether Tenacity & Will Power are constant and limited in the individual. I interpret this as whether or not an individual is able to increase their maximum capacity of tenacity & will-power. If the answer is no, this means that each person can only have X amount of tenacity & will power, and nothing they do can increase this amount. That is not the same as saying that our tenacity & will power is constant and cannot change. It can increase throghout life through practice, but it cannot exceed a certain limit, which is fixed. It is this limit or upper bound what is fixed and cannot change.\nOn the previous topic, Dr. Huberman tends to lean towards the camp that, indeed, the maximum achievable Tenacity & Will Power is constant and cannot change.\nOne way of increasing Tenacity & Will Power is through exercise / practice. This means, in a nutshell, to do tasks that one doesn’t want to do, or, conversely don’t engage in activities or behaviours that one would like to engage in, and that are presumably unhealthy or not recommendable in some sense. Huberman informally refers to these tasks as micro-sucks, i.e., things that one doesn’t really feel like doing at some point, but that they are safe and, I interpret, not extremely challenging.\nBiological remarks:\n\nIncreasing testosterone seems to be related with increasing Tenacity & Will Power.\nThere is a specific region of the brain that is strongly associated with Tenacity & Will Power. The bigger this region grows, the more Tenacity & Will Power one has. So-called super-agers (or centenarians, as Dr. Attia calls them) tend to have such regions much bigger than the rest of people. And they tend to engage in activities that they would normally don’t feel like engaging in (at least at the beginning, e.g., things out of their comfort-zone and that they do not feel particularly inclined to do), and avoid unheatlhy or not-recommendable things that they normally desire. Another way of looking at this is that elderly people (in their 60s to 90s) that do not cease trying to improve, evolve, and explore unchartered and mildly not-attractive territories, show in some sense a strong desire of living longer while growing personally, and this usually translates into them living longer. It looks to me, to some extent, as a sort-of self-fulfilling wish."
  },
  {
    "objectID": "posts/education/index.html",
    "href": "posts/education/index.html",
    "title": "Education and Parenting",
    "section": "",
    "text": "Learning visually\n\n\nShort notes on learning by practice and visualization.\n\n\n\n\n\n\n\n\n\n\nParenting coach notes\n\n\n\n\n\n\n\n\n\n\n\n\n\nResources on Parenting & Early Childhood Education\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject-driven learning\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/education/parenting_coach.html",
    "href": "posts/education/parenting_coach.html",
    "title": "Parenting coach notes",
    "section": "",
    "text": "Note: this post is just a draft in progress. As of now, it consists of a collection of random notes.\nSome months ago we started to attend parenting coach sessions that would help us learn a suit of strategies for early-childhood parenting that we would like to apply to our son, who is three years old at the moment. This post summarizes some of these strategies and other lessons gathered from those sessions."
  },
  {
    "objectID": "posts/education/parenting_coach.html#following-a-routine",
    "href": "posts/education/parenting_coach.html#following-a-routine",
    "title": "Parenting coach notes",
    "section": "Following a routine",
    "text": "Following a routine\n“I see to it that my child does the following:”\n\n\n\nIn the morning\nIn the evening\n\n\n\n\nDress up\nWash hands\n\n\nGo to the car\nTidy up\n\n\n…\nHave dinner"
  },
  {
    "objectID": "posts/education/parenting_coach.html#general-guidelines",
    "href": "posts/education/parenting_coach.html#general-guidelines",
    "title": "Parenting coach notes",
    "section": "General guidelines",
    "text": "General guidelines\n\nPrevention is better than cure. For instance, if we see that the child might do something wrong, instead of waiting and checking if they actually end up doing it, we might avoid it altogether.\nAvoid non-positive attention-seeking mechanisms. For instance, when asking the child to dress-up, it is important to not ask it repeatedly, or otherwise they might just not do it as a way of obtaining a type of attention that we don’t want to encourage, in which case they might happily ignore our request and expect us to be paying this attention continuously. Instead, a better strategy is to say something like “While you dress up I will be getting ready myself. If you have any difficulties while dressing up, please let me know and I can help you, but I would like to see that you try to do it by yourself first”. It is very important that, even when things are a bit challenging, they are encouraged to try them a few times before seeking help."
  },
  {
    "objectID": "posts/education/parenting_coach.html#q-a",
    "href": "posts/education/parenting_coach.html#q-a",
    "title": "Parenting coach notes",
    "section": "Q & A",
    "text": "Q & A\nTo better reflect the parenting sessions, each one of the discussed topics is placed in a separate a sub-section, and within it we write a Q & A expressed as a dialogue between parents and coach. Parent questions or observations are indicated with P while coach responses with C.\n\nHitting\n\nP: My child is hitting me a lot lately. It seems as if he doesn’t control his emotions.\nC: When this happens, the first thing we need to ask is whether something changed at school or in other domain that might have affected him in some way.\nP: He’s not saying anything, nor his teachers. We are concerned that we wouldn’t notice if something happened at school. One reason for that concern is that all the staff has recently changed and the new staff is not communicating so much.\nC: If he had a behaviour issue, your teachers would certainly tell you. (Then I remember that one teacher told me about one event when our son pushed another kid). I wouldn’t worry about that.\nC: Regarding your initial question, you need to set your boundaries early in the day. Something like “I’m not going to allow you to hit me anymore”. Say it in an “I love you” manner. Use the last example when that happened. We tell him that this is ok because it happened yesterday (for example), so he feels safe when we talk about this. Then we can say something like “I don’t want that because it hurts me.”\n\nThen, if we see the child is going to hit us, we need to stop him/her before that happens (note for self: this falls under the “prevention is better than cure” general guideline, mentioned above). While we stop him, we can say something like - “Hang on, remember we spoke about this early today? I’m not going to allow you to hit me.”\nIf the child stops trying to hit, then we can the following type of dialogue (just an example situation) with our child:\n- What is it that you need?\n- I want to have yoghurt!\n- Hang on, I see. Let's talk about that without hitting. When was the last time you had one?\n- I had it this morning.\n- That's great, you can have it tomorrow morning.\nThis type of dialogue makes the child learn to rationalize cause and effect.\nThe previous dialogue can happen if the child stops to trying to hit. However, they don’t stop, it is better that we leave the room so that they don’t get the opportunity to do it. We say that we are going to leave because we don’t want to allow them to hit us. By doing so we are not allowing the negativity of the behaviour to last for long time.\n\n\nChild talking bad about school\nP: Our son always talks in a negative way about school.\nC: First of all, we have to be careful that there’s nothing concerning at school. Tell the teachers about his feeling and see what they say about this. After that, we also need to be careful to not be continuously asking our child whether or not he had a good day or, more specifically, if there was any issue at school that day. Especially, we need to avoid asking about in a way that provides an image of us being concerned. This might make our child feel uncomfortable, like investigated, and this doesn’t help them having an honest and open communication.\nInstead of that we could simply ask something general like “how was your day” and, after they respond, we can say something like “Let me tell you how was my day” so that they don’t feel the conversation is just about them or about investigating if there was any issue that day.\nRather than investigating on potential negative things, it’s better to talk about positive things. We can ask what activities he had or what games he played and then ask specific details about those (“What was this painting about?” “Do you remember what colors did you use?” or “What animals there were in that jig-saw?” This helps them practice and strengthen their memory, something especially important at early ages."
  },
  {
    "objectID": "posts/education/project_driven_learning.html",
    "href": "posts/education/project_driven_learning.html",
    "title": "Project-driven learning",
    "section": "",
    "text": "Note: this post is, at this moment, just a draft in progress.\nThe idea of writing this post came initially as a sort-of response / contribution to the excellent essay from Daniel Higginbotham entitled Techniques for Efficiently Learning Programming Languages. Despite the title of the essay, the ideas inside are very much generic for learning to learn basically anything. I will be adding a slighly new perspective which incorporates a “project-driven” approach to learning. This idea is not novel, and can be applied either in conjunction or as an alternative to the ideas expressed in post by D. Higginbotham, depending on what our final goals are. I will also use ideas such as Exploration vs Exploitation from the field of Reinforcement Learning, which I will be explaning for anyone not familiar in this field.\nThe gist of project-based learning is to focus our learning journey on those things that will prove to be important in our daily practice or life in general. It is motivated in part by the fact that, many times, when we learn a new field, e.g., in college, we study many concepts that we will never be using or needing in anyway, and end up completely forgotten. To be more concrete, let us take the field of mathematics as an example.\nGiven the vast amount of things that are actually interesting and relevant for our lives, this approach can be considered sub-optimal in many cases, making us waste a lot of time on topics that are not even connected to those parts that are relevant to us. Having said that, as I explore in this post, it all depends on what the final goal in our learning adventure. For this, I will be using a framework based on the Exploration vs Exploitation trade-off from Reinforcement Learning.\nThe gist of it is that, many times, when we start a learning"
  },
  {
    "objectID": "posts/data_science/index.html",
    "href": "posts/data_science/index.html",
    "title": "Data Science",
    "section": "",
    "text": "Simulation\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying with MLflow\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello World AML pipeline with component\n\n\nExploring AML through Hello World components.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data_science/hello_world.html",
    "href": "posts/data_science/hello_world.html",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "The purpose of this tutorial is to show how to incrementally build a pipeline from simple and debuggable “Hello World” components. In order to run this at home, you may find it useful to create a free Azure ML subscription as described in the how-to guide I have here\n\n\nIn this section, we will write our code in a notebook and make sure it works well. Then, we will convert it to a script and run it from the terminal. Finally, we will add some logs with MLFlow.\nAlthough not required, as a very first step we can create a environment and kernel following the tutorial in https://learn.microsoft.com/en-gb/azure/machine-learning/tutorial-cloud-workstation?view=azureml-api-2\nFollowing the previous tutorial, create a notebook and type the following hello world code:\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\nhello_world (\"Jaume\")\n\nHello Jaume and world\n\n\nFantastic, the code works ;-). Now, let’s convert it to a script that can be run from terminal. The tutorial above explains how to convert the notebook to a python file. In our case, we will first add an argument parser and then write it to file using the magic cell %%writefile\n\n%%writefile hello_world_core.py\nimport argparse\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", type=str, help=\"person to greet\")\n    args = parser.parse_args()\n    \n    return args\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    hello_world (args.name)\n\nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_core.py\n\n\nBad pipe message: %s [b'\\x80\\xb8\\xc2\\x0e\\x1b\\xcd4\\xe90\\x12O\\x89\\xff4\\x0b\\xbf;\\xab \\xb6*\\xd3\\xab\\x91\\xb6\\x87\\xe82s\\x1fIv\\xd3\\x172\\xa6\\x11\\xb2w\\xff\\xf2\\x02L\\xbf_\\xc1\\t\\x1dn\\xdc\\x0f\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02']\nBad pipe message: %s [b'4\\xf9%\\x9at\\xbe\\x08\\x03\\x06\\xf5.E\\xe9\\xd7\\xb3\\xa1Z\\x8d ']\nBad pipe message: %s [b'\\x0c5\\x85\\xf5Z']\nBad pipe message: %s [b'\\xe3\\x18^', b'\\x9cOo\\xfe*\\xa90\\xa3\\xf8\\xfa#\\x8d\\x0b\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r']\nBad pipe message: %s [b\"\\x85c}\\xe4\\x85\\xb5*i\\xf3vog\\x0b\\x16\\\\\\xdd\\x9e\\x0e\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x00\", b'1\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01']\nBad pipe message: %s [b\"\\xf3\\x03\\x81E\\x16\\x17\\x18\\x1e0(\\xa5\\x94\\x96\\x98\\x0cw\\xd6\\xe3\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00\", b'\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00']\nBad pipe message: %s [b'\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n\n\nNow, we can open up a terminal, as illustrated in the tutorial above, cd to the folder where the script is and run it:\ncd  Users/&lt;my_user&gt;/hello_world\npython hello_world_core.py --name Jaume\n\n\n\n%%writefile hello_world_with_logs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n\ndef start_logging (args):\n    # set name for logging\n    mlflow.set_experiment(\"Hello World with logging\")\n    mlflow.start_run()\n    mlflow.log_param (\"name to log\", args.name)\n    \ndef finish_logging ():\n    mlflow.end_run ()\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    args = parse_args ()\n    start_logging (args)\n    hello_world (args.name)\n    finish_logging ()\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_with_logs.py\n\n\nLet’s run it and see:\npython hello_world_with_logs.py --name Peter\nHere is the newly created job:\n\nAnd the name passed as argument:\n\nWe start by getting a connection to our Azure ML (AML for short) workspace. We use here a simple connection mechanism that doesn’t require writting your subscription, resource group and workspace details:\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\n\n\nWe now convert the previous script into a job that can be run from the UI.\n\n\n\n# Standard imports\nimport os\n\n# Third-party imports\nimport pandas as pd\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n\n\n\nFor the remaining part of this tutorial, we will be needing an ml_client handle. This will allow us to create and use resources from our workspace. The simplest way to get such handle is with the following code:\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\n\nWe specify a job using the command decorator:\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Simplest Hello World\",\n)\n\n\nNote: we indicate as environment “AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest”, which actually contains more libraries than we need, such as sklearn. Simpler environments to use can be found in the “Environments” section of the workspace.\n\n… and submit it using create_or_update from ml_client:\n\nml_client.create_or_update(job)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nUploading hello_world (8.59 MBs): 100%|██████████| 8591281/8591281 [00:00&lt;00:00, 40584539.30it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nhello_world\nclever_spade_sq4jwcg67r\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\nIn the link that appears, we can see the status of the job, which initially is “Queued”. We need to wait until it is completed (and refresh the page to see this). Once it is completed, we can look at the logs:\n\nIn the logs, we can see the messages printed in console:\n\n\n\n\nAbove, we indicated a default value for the input argument name. It would be good to be able to submit jobs with different values for that argument. One way to do that is:\n\nIn the job’s Overview tab, click on “Edit and submit”\n\n\n\nIn the “Training script” section, edit the “Inputs” by clicking on the pencil next to it:\n\n\n\nIn the “Input value” field, type the new value you want for the argument:\n\n\n\nHit Next several times and then Submit.\nIf we go to the jobs section of the workspace, and enter again our job (“helloworld”), we can see that a new job has been submitted:\n\n\nIn its Overview tab, under “See all properties”, we can inspect the json file:\n\n… and see that the new value (Peter) is used in its “parameters” dictionary:\n\nThe std_log.txt for this job shows the new message with Peter:\n\n\n\n\n\n\nhello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.58 MBs): 100%|██████████| 8578531/8578531 [00:00&lt;00:00, 21700197.27it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_input: str\n        Input to pipeline, here name of person to greed.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\n# Let's instantiate the pipeline with the parameters of our choice\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"David\",\n)\n\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_registered_components\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:08:19Z] Submitting 1 runs, first five are: 605cf9a7:d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6\n[2024-03-26 14:12:40Z] Completing processing run id d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6.\n\nExecution Summary\n=================\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World witn Input\",\n)\n\nhello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8589758/8589758 [00:00&lt;00:00, 24178345.78it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\nfrom azure.ai.ml import dsl\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_input: str\n        Input to pipeline, here name of person to greed.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Joseph\",\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_input\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:38:43Z] Submitting 1 runs, first five are: cd1599c4:ce24c41e-946d-48cd-99b2-70ebde3befb2\n[2024-03-26 14:44:58Z] Completing processing run id ce24c41e-946d-48cd-99b2-70ebde3befb2.\n\nExecution Summary\n=================\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nNotes about Input:\n\nWhen using Input(type=“uri_folder”) or Input(type=“uri_file”), the value passed cannot be a string, it must be an Input type, for example:\n\njob = command(\n    inputs=dict(\n        file_name=Input (type=\"uri_file\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(path=\"/path/to/file\"),\n)\n\nHowever, when using Input(type=“string”) or Input(type=“number”), the input must be a string or number, not Input\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Mary\",\n)\n\nIn the latter case, the input does not appear in the graph of the pipeline, in the UI.\n\n\n\n\n\n# Component definition and registration\njob = command(\n    inputs=dict(\n        name=Input (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"hello-world\",\n    display_name=\"Hello World with uri_file\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Input to pipeline, here path to file.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(type=\"uri_file\", path=\"./hello_world_core.py\"),\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8588206/8588206 [00:00&lt;00:00, 24482901.98it/s]\n\n\nUploading hello_world_core.py (&lt; 1 MB): 0.00B [00:00, ?B/s] (&lt; 1 MB): 100%|██████████| 514/514 [00:00&lt;00:00, 12.0kB/s]\n\n\n\n\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:06:11Z] Submitting 1 runs, first five are: a08118c5:2099b6ad-fb3a-4cac-9557-c8cf355b8b1b\n[2024-03-26 15:11:50Z] Completing processing run id 2099b6ad-fb3a-4cac-9557-c8cf355b8b1b.\n\nExecution Summary\n=================\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\nIf you click on the “Data” component and inside it click on “Explore”, you can see the contents of the file, since it is a text python file.\n\n\n\n\n\n# Component definition and registration\njob = command(\n    outputs=dict(\n        name=Output (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{outputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with uri_file as output\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component()\n\npipeline = hello_world_pipeline()\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file_as_output\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (9.48 MBs): 100%|██████████| 9483085/9483085 [00:00&lt;00:00, 22969826.09it/s]\n\n\n\n\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:36:23Z] Submitting 1 runs, first five are: 528b20ac:27e32a0a-71a0-4bc3-abec-eaeae70ff08e\n[2024-03-26 15:41:30Z] Completing processing run id 27e32a0a-71a0-4bc3-abec-eaeae70ff08e.\n\nExecution Summary\n=================\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\n\nIn order to have something more meaningful, we create a pipeline with two components. The first one “pre-processes” the input data frame by adding one (or a specified number) to it, storing the output as a csv file. The second component builds a “model” by calculating the mean and standard deviation, and saves it as pickle file.\n\n\nWhenever we have multiple components, a common practice in Azure ML is to have a dedicated subfolder for each one. The subfolder contains the source .py file implementing the component, and may contain a conda yaml file with dependencies that are specific for this component. In our case, we use a pre-built environment so that we don’t need to include any conda yaml file.\n\nos.makedirs (\"preprocessing\", exist_ok=True)\nos.makedirs (\"training\", exist_ok=True)\nos.makedirs (\"data\", exist_ok=True)\n\n\ndf = pd.DataFrame (\n    {\n        \"a\": [1,2,3],\n        \"b\": [4,5,6],\n    },\n)\n\ndf.to_csv (\"data/dummy_input.csv\")\n\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data frame\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data frame\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data,\n    x,\n    preprocessed_data,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (preprocessed_data)\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (args.input_data, args.x, args.preprocessed_data)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\n# Component definition and registration\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_file\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to preprocessed data\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    preprocessed_data: str,\n    model_path: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\"\"\"\n    df = pd.read_csv (preprocessed_data, index_col=0)\n    model = train_model (df)\n    joblib.dump (model, model_path)\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (args.preprocessed_data, args.model)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_file\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_file\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 1043/1043 [00:00&lt;00:00, 112778.01it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\n\nreload (preprocessing)\nreload (training)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_preprocess_output: str,\n    pipeline_job_model_output: str,\n):\n    \"\"\"\n    Tests two component pipeline with preprocessing and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *file*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *file*. Not present in the final pipeline.\n    \"\"\"\n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_x,\n        pipeline_job_preprocess_output,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_preprocess_output=\"./test_pipeline/preprocessed_data.csv\",\n    pipeline_job_model_output=\"./test_pipeline/model.pk\"\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\n\n\n\n\n\nNow we are ready to implement and submit our pipeline. The code will be very similar to the test_pipeline implemented above, except for the fact that we don’t need to indicate the outputs that connect one component to the next, since these are automatically populated by AML.\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef two_components_pipeline(\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n):\n    \"\"\"\n    Pipeline with two components: preprocessing, and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\n\ntwo_components_pipeline = two_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n)\n\ntwo_components_pipeline_job = ml_client.jobs.create_or_update(\n    two_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_two_components_pipeline\",\n)\n\n# Pipeline running\nml_client.jobs.stream(two_components_pipeline_job.name)\n\nRunId: quiet_root_nb0c997gsp\nWeb View: https://ml.azure.com/runs/quiet_root_nb0c997gsp?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-27 10:45:01Z] Submitting 1 runs, first five are: caf1c51e:87b5910c-0e8d-4ca0-a808-f52a94d52b56\n[2024-03-27 10:51:05Z] Completing processing run id 87b5910c-0e8d-4ca0-a808-f52a94d52b56.\n[2024-03-27 10:51:05Z] Submitting 1 runs, first five are: 3d73a420:6c033636-f3d8-4fe2-ba8d-26072210ba05\n[2024-03-27 10:56:25Z] Completing processing run id 6c033636-f3d8-4fe2-ba8d-26072210ba05.\n\nExecution Summary\n=================\nRunId: quiet_root_nb0c997gsp\nWeb View: https://ml.azure.com/runs/quiet_root_nb0c997gsp?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nWe can see the created pipeline in the Pipelines section of our workspace:\n\n\n\n\n\nWe can see that:\n\nThe path to the preprocessed data has been automatically set to azureml/49824a8b-967f-4410-84a7-bc18b328a1b6/preprocessed_data, where the file name preprocessed_data is the name of the output given in the component definition:\n\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_file\"),\n    )\n\nSince this file name doesn’t have an extension, we cannot preview (see arrow 2). However, we can see its contents if we view the file in the datastore, as indicated below:\n\n\nUnfortunately, the content of the file appears in text format, rather than as a table.\n\nWe can also see the content of the outputs by inspecting the logs of the training component:\n\n\n\n\n\n\n\nLet’s try now using outputs of type “uri_folder”. We need to do two changes for this purpose:\n\nIn the component modules, preprocessing/preprocessing.py and training/training.py, the output arguments args.preprocessed_data and args.model will contain a path to a folder where the file is stored. Therefore, when saving the file, we need to append its name to the input path:\n\n#In preprocessing module:\ndf.to_csv (preprocessed_data + \"/preprocessed_data.csv\")\nand\n# In training module:\ndf = pd.read_csv (preprocessed_data + \"/preprocessed_data.csv\", index_col=0)\n\n# later in same module:\njoblib.dump (model, model_path + \"/model.pk\")\n\nIn the definition of the pipeline, we replace the type of the outputs to be “uri_folder”, and the input to the training component to be “uri_folder” as well.\n\n    # In preprocessing component\n    ...    \n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    ...\n        \n    # In training component\n    ...\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_folder\"),\n    ),\n    ...\nHere we have the final implementation of our components:\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data *file*\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data *folder* containing the preprocessed data.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data,\n    x,\n    preprocessed_data,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (preprocessed_data + \"/preprocessed_data.csv\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (args.input_data, args.x, args.preprocessed_data)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to preprocessed data\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    preprocessed_data: str,\n    model_path: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\"\"\"\n    df = pd.read_csv (preprocessed_data + \"/preprocessed_data.csv\", index_col=0)\n    model = train_model (df)\n    joblib.dump (model, model_path + \"/model.pk\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (args.preprocessed_data, args.model)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 1084/1084 [00:00&lt;00:00, 39997.06it/s]\n\n\n\n\n\n\n\nAgain, before submitting the pipeline job, we first test a manually built pipeline. Note that the new pipeline uses paths to folders, and not paths to files, for the outputs:\n\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\n\nreload (preprocessing)\nreload (training)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_preprocess_output: str,\n    pipeline_job_model_output: str,\n):\n    \"\"\"\n    Tests two component pipeline with preprocessing and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *folder*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *folder*. Not present in the final pipeline.\n    \"\"\"\n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_x,\n        pipeline_job_preprocess_output,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_preprocess_output=\"./test_pipeline\",\n    pipeline_job_model_output=\"./test_pipeline\"\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\n\n\n… and the implementation of our pipeline:\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef two_components_pipeline(\n    pipeline_job_data_input,\n    pipeline_job_x,\n):\n    \"\"\"\n    Pipeline with two components: preprocessing, and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\ntwo_components_pipeline = two_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n)\n\ntwo_components_pipeline_job = ml_client.jobs.create_or_update(\n    two_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_two_components_pipeline_with_uri_folder\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(two_components_pipeline_job.name)\n\nRunId: calm_zebra_t3gb5cjnrk\nWeb View: https://ml.azure.com/runs/calm_zebra_t3gb5cjnrk?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-28 08:45:53Z] Completing processing run id 1ff53a74-943f-4f94-8efd-4b55b345449f.\n[2024-03-28 08:45:54Z] Submitting 1 runs, first five are: e26d0be6:8e0f40eb-e2c3-4feb-a0d0-9882de1daebc\n\nExecution Summary\n=================\nRunId: calm_zebra_t3gb5cjnrk\nWeb View: https://ml.azure.com/runs/calm_zebra_t3gb5cjnrk?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nNow, when we go to the “Explore” tab, in the output data of the preprocessed component, we can see the contents of the output preprocessed data in tabular format. We can also see that the extension of the output, which is csv file:\n\n\n\n\n\nWe add now a third component, which takes as input test data, preprocesses it, and uses the model to perform “inference”. For this pipeline, we can reuse the training component from the last section, but we need to slighty modify the preprocessing component to use an additional argument: the name of the output file. This is needed because there will be two outputs: one when preprocessing the training data, and the other when preprocessing the test data.\n\n\n\nos.makedirs (\"inference\", exist_ok=True)\ntest_data = pd.DataFrame (\n    {\n        \"a\": [11., 12.1, 13.1],\n        \"b\": [14.1, 15.1, 16.1],\n    }\n)\ntest_data.to_csv (\"data/dummy_test.csv\")\n\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data *file*\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data *folder* containing the preprocessed data.\")\n    parser.add_argument(\"--preprocessed_file_name\", type=str, help=\"name of preprocessed file name.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data: str,\n    preprocessed_data: str,\n    preprocessed_file_name: str,\n    x: int,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (f\"{preprocessed_data}/{preprocessed_file_name}\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (\n        input_data=args.input_data, \n        preprocessed_data=args.preprocessed_data,\n        preprocessed_file_name=args.preprocessed_file_name,\n        x=args.x, \n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        preprocessed_file_name=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}} --preprocessed_file_name ${{inputs.preprocessed_file_name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\nUploading preprocessing (0.0 MBs): 100%|██████████| 1343/1343 [00:00&lt;00:00, 46879.53it/s]\n\n\n\n\nThe preprocessing component doesn’t change from the last pipeline, see “Using uri_folder” section.\n\n\n\n\n%%writefile inference/inference.py\nimport argparse\nimport joblib\nimport pandas as pd\nfrom typing import Tuple\nimport numpy as np\n\ndef inference (\n    model: Tuple[np.ndarray, np.ndarray], \n    df: pd.DataFrame,\n):\n    \"\"\"\n    Runs dummy inference on new data `df`\n    \"\"\"\n    (mu, std) = model\n    z_df = (df - mu) / std\n    print (\"Inference result:\")\n    print (z_df)\n    return z_df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--test_data\", type=str, help=\"path to test data *folder*\")\n    parser.add_argument(\"--test_data_file_name\", type=str, help=\"name of test data file name.\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model *folder*\")\n    parser.add_argument(\"--inference_output\", type=str, help=\"path to inference result *folder*\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_inference (\n    test_data: str,\n    test_data_file_name: str,\n    model_path: str,\n    inference_data: str,\n):\n    \"\"\"\n    Reads test data and model, performs inference, and writes to output inference file.\n    \n    Parameters\n    ----------\n    test_data: str\n        Path to test (preprocessed) data *folder*\n    test_data_file_name: str\n        Name of test data file.\n    model_path: str\n        Path to built model *folder*\n    inference_data: str\n        Path to inference result *folder*\n    \"\"\"\n    df = pd.read_csv (f\"{test_data}/{test_data_file_name}\", index_col=0)\n    model = joblib.load (model_path + \"/model.pk\")\n    z_df = inference (model, df)\n    z_df.to_csv (inference_data + \"/inference_result.csv\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_inference (\n        test_data=args.test_data, \n        test_data_file_name=args.test_data_file_name,\n        model_path=args.model, \n        inference_data=args.inference_output,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting inference/inference.py\n\n\n\ninference_command = command(\n    inputs=dict(\n        test_data=Input (type=\"uri_folder\"),\n        test_data_file_name=Input (type=\"string\"),\n        model=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        inference_output=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n            \"--test_data ${{inputs.test_data}} \"\n            \"--test_data_file_name ${{inputs.test_data_file_name}} \"\n            \"--model ${{inputs.model}} \"\n            \"--inference_output ${{outputs.inference_output}}\",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\nUploading inference (0.0 MBs): 100%|██████████| 1912/1912 [00:00&lt;00:00, 63810.98it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\nfrom inference import inference\n\nreload (preprocessing)\nreload (training)\nreload (inference)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_test_input: str,\n    pipeline_preprocessed_file_name: str,\n    pipeline_test_file_name: str,\n    \n    # The following parameters are not present in the final pipeline:\n    pipeline_job_preprocess_output: str,\n    pipeline_job_test_output: str,\n    pipeline_job_model_output: str,\n    pipeline_job_inference_output: str,\n):\n    \"\"\"\n    Tests third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_preprocessed_file_name: str\n        Name of (preprocessed) input data file.\n    pipeline_test_file_name: str\n        Name of (preprocessed) test data file.\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *folder*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_test_output: str\n        Path to preprocessed test data *folder*, to be used for inferencing.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *folder*. Not present in the final pipeline.\n    pipeline_job_inference_output: str\n        Path to inference result *folder*. Not present in the final pipeline.\n    \"\"\"\n    \n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_preprocess_output,\n        pipeline_preprocessed_file_name,\n        pipeline_job_x,\n    )\n    preprocessing.read_and_preprocess (\n        pipeline_job_test_input,\n        pipeline_job_test_output,\n        pipeline_test_file_name,\n        pipeline_job_x,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n    inference.read_and_inference (\n        test_data=pipeline_job_test_output,\n        test_data_file_name=pipeline_test_file_name,\n        model_path=pipeline_job_model_output,\n        inference_data=pipeline_job_inference_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_test_input=\"./data/dummy_test.csv\",\n    pipeline_preprocessed_file_name=\"preprocessed_data.csv\",\n    pipeline_test_file_name=\"preprocessed_test.csv\",\n    \n    # The following parameters are not present in the final pipeline:\n    pipeline_job_preprocess_output=\"./test_pipeline\",\n    pipeline_job_test_output=\"./test_pipeline\",\n    pipeline_job_model_output=\"./test_pipeline\",\n    pipeline_job_inference_output=\"./test_pipeline\",\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n       a     b\n0  11.0  14.1\n1  12.1  15.1\n2  13.1  16.1\nAdding 10 to df\nOutput\n       a     b\n0  21.0  24.1\n1  22.1  25.1\n2  23.1  26.1\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\nInference result:\n      a     b\n0   9.0   9.1\n1  10.1  10.1\n2  11.1  11.1\n\n\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_test_input: str,\n    pipeline_preprocessed_file_name: str,\n    pipeline_test_file_name: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_preprocessed_file_name: str\n        Name of (preprocessed) input data file.\n    pipeline_test_file_name: str\n        Name of (preprocessed) test data file.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n        preprocessed_file_name=pipeline_preprocessed_file_name,\n    )\n    \n    preprocessing_test_job = preprocessing_component(\n        input_data=pipeline_job_test_input,\n        x=pipeline_job_x,\n        preprocessed_file_name=pipeline_test_file_name,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\n    \n    # using train_func like a python call with its own inputs\n    inference_job = inference_component(\n        test_data=preprocessing_test_job.outputs.preprocessed_data,\n        test_data_file_name=pipeline_test_file_name,\n        model=training_job.outputs.model,  # note: using outputs from previous step\n    )\n    \nthree_components_pipeline = three_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n    pipeline_job_test_input=Input(type=\"uri_file\", path=\"./data/dummy_test.csv\"),\n    pipeline_preprocessed_file_name=\"preprocessed_data.csv\",\n    pipeline_test_file_name=\"preprocessed_test_data.csv\",\n)\n\nthree_components_pipeline_job = ml_client.jobs.create_or_update(\n    three_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_three_components_pipeline_with_uri_folder\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(three_components_pipeline_job.name)\n\nRunId: calm_rice_3cmmmtc5mf\nWeb View: https://ml.azure.com/runs/calm_rice_3cmmmtc5mf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-28 10:15:12Z] Submitting 2 runs, first five are: 47ca85c2:a5595dea-3117-47e9-a99d-186b0c346884,4b1f0180:09aecbcc-aa2c-4cad-b134-eb4837724f58\n[2024-03-28 10:20:13Z] Completing processing run id 09aecbcc-aa2c-4cad-b134-eb4837724f58.\n[2024-03-28 10:20:13Z] Submitting 1 runs, first five are: fece868d:164d1e2a-a5d7-4081-9a68-a07033a3feee\n[2024-03-28 10:20:45Z] Completing processing run id 164d1e2a-a5d7-4081-9a68-a07033a3feee.\n[2024-03-28 10:22:15Z] Completing processing run id a5595dea-3117-47e9-a99d-186b0c346884.\n[2024-03-28 10:22:16Z] Submitting 1 runs, first five are: a9d60b27:6a18ae74-2a3c-4e16-a6cb-a58649235bfe\n[2024-03-28 10:22:52Z] Completing processing run id 6a18ae74-2a3c-4e16-a6cb-a58649235bfe.\n\nExecution Summary\n=================\nRunId: calm_rice_3cmmmtc5mf\nWeb View: https://ml.azure.com/runs/calm_rice_3cmmmtc5mf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nHere we can see the resulting pipeline:\n\n\n\n\n\n\n\nFrom the development of the different pipelines we can extract a few observations that help us create a better refactored pipeline and, at the same time, compile a small set of “design” rules that may help us in future pipelines. In my case, I find it clearer and with less boilerplate to use the following rules:\n\nUse “uri_folder” type for intermediate outputs, and add another parameter next to it containing the output file, something like:\n\ndef pipeline(\n    ...\n    input_folder: str,\n    input_filename: str,\n    ...\n)\n\nUse “_folder” as a prefix for parameters of type uri_folder, “_file” for those of type uri_file, and “_filename” for those indicating names of file names.\nUse the suffix input for those things that are inputs and ouputfor those that are outputs.\nI’m not clear about this one. Many people usually pass a dataframe called df or a numpy array called X, which is passed from one step of the pipeline to the next, without appending words to the name that talk about the content of the dataframe or the array (e.g., use “X” instead of “preprocessed_X” or “inference_result_X”). I tend to find it easier to do a similar thing here for the inputs of intermediate components, when defining the command for those components. Therefore, for the inputs, I would use input_folder rather than preprocessed_training_data_input_folder for indicating the input to the model component. This means that if we replace later the model component with one that works directly on raw (non-preprocessed) data (e.g., because the preprocessing is implicitly done as part of the model), we don’t need to replace the part of the script that parses the arguments to indicate that now the input folder is just training_data_input_folder.\nFor the outputs, it might be useful to add a short prefix to talk about the type of output, so that the pipeline’s diagram shows what is the ouput of each component is. Again, I’m not clear about this one.\nThe exception to the previous rules is when we have more than one input or output folder. In this case, we clearly need to add more words to their names.\nIt is easier to avoid adding pipeline_job_... for each parameter of the pipeline.\n\n\n\n\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (\n    df: pd.DataFrame, \n    x: int\n):\n    \"\"\"Adds `x` to input data frame `df`.\n\n    Parameters\n    ----------\n    df: DataFrame\n        Input data frame \n    x: int\n        Integer to add to df.\n\n    Returns\n    -------\n    DataFrame.\n        Preprocessed data.\n    \"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_file\", type=str, help=\"path to input data file\")\n    parser.add_argument(\"--output_folder\", type=str, help=\"path to output data folder containing the preprocessed data.\")\n    parser.add_argument(\"--output_filename\", type=str, help=\"name of file containing the output, preprocessed, data.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add to input data for preprocessing it.\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_file: str,\n    output_folder: str,\n    output_filename: str,\n    x: int,\n):\n    \"\"\"Reads input data, preprocesses it, and writes result as csv file in disk.\n\n    Parameters\n    ----------\n    input_file: str\n        Path to input data file.\n    output_folder: str\n        Path to output data folder containing the preprocessed data.\n    output_filename: str\n        Name of file containing the output, preprocessed, data.\n    x: int\n        Number to add to input data for preprocessing it.\n    \"\"\"\n    df = pd.read_csv (input_file, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (f\"{output_folder}/{output_filename}\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (\n        input_file=args.input_file, \n        output_folder=args.output_folder,\n        output_filename=args.output_filename,\n        x=args.x, \n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_file=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py \"\n        \"--input_file ${{inputs.input_file}} \"\n        \"-x ${{inputs.x}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\nUploading preprocessing (0.0 MBs): 100%|██████████| 1985/1985 [00:00&lt;00:00, 64070.90it/s]\n\n\n\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\n    \n    Parameters\n    ----------\n    df: DataFrame\n        Input data frame\n    \n    Returns\n    -------\n    np.ndarray\n        Average across rows, one per column.\n    np.ndarray\n        Standard deviation across rows, one per column.\n    \"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    \n    parser.add_argument(\n        \"--input_folder\", \n        type=str, \n        help=\"path to preprocessed training data folder, \"\n             \"containing training set file.\"\n    )\n    parser.add_argument(\n        \"--input_filename\", \n        type=str, \n        help=\"name of file containing preprocessed, training data.\"\n    )\n    parser.add_argument(\n        \"--output_folder\", \n        type=str, \n        help=\"path to output *folder* containing the trained model.\"\n    )\n    parser.add_argument(\n        \"--output_filename\", \n        type=str, \n        help=\"name of file containing the trained model.\"\n    )\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    input_folder: str,\n    input_filename: str,\n    output_folder: str,\n    output_filename: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\n    \n    Parameters\n    ----------\n    input_folder: str\n        Path to preprocessed training data folder containing training set file.\n    input_filename: str\n        Name of file containing preprocessed, training data.\n    output_folder: str\n        Path to output folder containing the trained model.\n    output_filename: str\n        Name of file containing the trained model.\n    \"\"\"\n    \n    df = pd.read_csv (f\"{input_folder}/{input_filename}\", index_col=0)\n    model = train_model (df)\n    joblib.dump (model, f\"{output_folder}/{output_filename}\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (\n        args.input_folder, \n        args.input_filename,\n        args.output_folder,\n        args.output_filename,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        input_folder=Input (type=\"uri_folder\"),\n        input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py \"\n        \"--input_folder ${{inputs.input_folder}} \"\n        \"--input_filename ${{inputs.input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 2309/2309 [00:00&lt;00:00, 50917.16it/s]\n\n\n\n\n\n\n\n\n%%writefile inference/inference.py\nimport argparse\nfrom typing import Tuple\nimport joblib\nimport pandas as pd\nfrom sklearn.metrics import DistanceMetric\nimport numpy as np\n\ndef inference (\n    model: Tuple[np.ndarray, np.ndarray], \n    df: pd.DataFrame,\n):\n    \"\"\"Runs dummy inference on new data `df`.\n\n    Parameters\n    ----------\n    model: Tople (np.ndarray, np.ndarray)\n        Average across rows (one per column), and \n        standard deviation across rows (one per column).\n    df: DataFrame\n        Test data frame on which to perform inference.\n    \n    Returns\n    -------\n    DataFrame\n        One column dataframe giving an approximation of the Mahalanobis distance \n        between each row vector and the mean vector, assuming that the covariance \n        matrix is diagonal. The negative of the scores obtained can be considered \n        as a sort of prediction probability for each row of belonging to the Gaussian \n        class estimated from the training data. In this sense this function provides\n        inference about how \"normal\" the test samples are. \n    \"\"\"\n    (mu, std) = model\n    dist = DistanceMetric.get_metric('mahalanobis', V=np.diag(std**2))\n    ndims = df.shape[1]\n    mah_dist = dist.pairwise (mu.reshape(1, ndims), df)\n    mah_dist = pd.DataFrame (mah_dist.ravel(), columns=[\"distance\"])\n    print (\"Inference result:\")\n    print (mah_dist)\n    return mah_dist\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--preprocessed_input_folder\", \n        type=str, \n        help=\"path to input, preprocessed, test data folder, \"\n             \"containing file on which to perform inference.\"\n    )\n    parser.add_argument(\n        \"--preprocessed_input_filename\", \n        type=str, \n        help=\"name of file containing the input, preprocessed, test data.\"\n    )\n    parser.add_argument(\n        \"--model_input_folder\", \n        type=str, \n        help=\"path to model folder.\"\n    )\n    parser.add_argument(\n        \"--model_input_filename\", \n        type=str, \n        help=\"name of model file.\"\n    )\n    parser.add_argument(\n        \"--output_folder\", \n        type=str, \n        help=\"path to output data *folder* with inference results.\"\n    )\n    parser.add_argument(\n        \"--output_filename\", \n        type=str, \n        help=\"name of file containing the output data with inference results.\"\n    )\n    \n    args = parser.parse_args()\n\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_inference (\n    preprocessed_input_folder: str,\n    preprocessed_input_filename: str,\n    model_input_folder: str,\n    model_input_filename: str,\n    output_folder: str,    \n    output_filename: str,\n):\n    \"\"\"\n    Reads test data and model, performs inference, and writes to output inference file.\n    \n    Parameters\n    ----------\n    preprocessed_input_folder: str\n        Path to test (preprocessed) data folder.\n    preprocessed_input_filename: str\n        Name of test data file.\n    model_input_folder: str\n        Path to built model folder.\n    model_input_filename: str\n        Path to inference result folder.\n    output_folder: str\n        Path to output data folder with inference results.\n    output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    df = pd.read_csv (f\"{preprocessed_input_folder}/{preprocessed_input_filename}\", index_col=0)\n    model = joblib.load (f\"{model_input_folder}/{model_input_filename}\")\n    z_df = inference (model, df)\n    z_df.to_csv (f\"{output_folder}/{output_filename}\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_inference (\n        preprocessed_input_folder=args.preprocessed_input_folder,\n        preprocessed_input_filename=args.preprocessed_input_filename,\n        model_input_folder=args.model_input_folder,\n        model_input_filename=args.model_input_filename,\n        output_folder=args.output_folder,\n        output_filename=args.output_filename,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting inference/inference.py\n\n\n\ninference_command = command(\n    inputs=dict(\n        preprocessed_input_folder=Input (type=\"uri_folder\"),\n        preprocessed_input_filename=Input (type=\"string\"),\n        model_input_folder=Input (type=\"uri_folder\"),\n        model_input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n        \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n        \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n        \"--model_input_folder ${{inputs.model_input_folder}} \"\n        \"--model_input_filename ${{inputs.model_input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}} \",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\nUploading inference (0.0 MBs): 100%|██████████| 4046/4046 [00:00&lt;00:00, 151355.71it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\nfrom inference import inference\n\nreload (preprocessing)\nreload (training)\nreload (inference)\n\ndef test_pipeline (\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_folder: str, # Not present in final pipeline\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_folder: str, # Not present in final pipeline\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    # input_folder: this is preprocessing_training_output_folder\n    # input_filename: this is preprocessing_training_output_filename\n    training_output_folder: str, # Not present in final pipeline\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    # preprocessed_input_folder: this is preprocessing_test_output_folder\n    # preprocessed_input_filename: this is preprocessing_test_output_filename\n    # model_input_folder: this is training_output_folder\n    # model_input_filename: this is training_output_filename\n    inference_output_folder: str, # Not present in final pipeline\n    inference_output_filename: str,\n):\n    \"\"\"\n    Tests third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_folder: str\n        Path to folder containing the preprocessed, training data file.\n        Not present in final pipeline.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_folder: str\n        Path to folder containing the preprocessed, test data file.\n        Not present in final pipeline.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_folder: str\n        Path to output folder containing the trained model.\n        Not present in final pipeline.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_folder: str\n        Path to output data folder with inference results.\n        Not present in final pipeline.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    \n    preprocessing.read_and_preprocess (\n        input_file=preprocessing_training_input_file,\n        output_folder=preprocessing_training_output_folder, # Not present in final component\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing.read_and_preprocess (\n        input_file=preprocessing_test_input_file,\n        output_folder=preprocessing_test_output_folder,\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training.read_and_train (\n        input_folder=preprocessing_training_output_folder,\n        input_filename=preprocessing_training_output_filename,\n        output_folder=training_output_folder,\n        output_filename=training_output_filename,\n    )\n    inference.read_and_inference (\n        preprocessed_input_folder=preprocessing_test_output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_output_folder,\n        model_input_filename=training_output_filename,\n        output_folder=inference_output_folder,\n        output_filename=inference_output_filename,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    # first preprocessing component\n    preprocessing_training_input_file=\"./data/dummy_input.csv\",\n    preprocessing_training_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    preprocessing_training_output_filename=\"preprocessed_data.csv\",\n    x=10,\n    \n    # second preprocessing component\n    preprocessing_test_input_file=\"./data/dummy_test.csv\",\n    preprocessing_test_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    preprocessing_test_output_filename=\"preprocessed_test.csv\",\n    \n    # Training component parameters:\n    training_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    training_output_filename=\"model.pk\",\n    \n    # Inference component parameters:\n    inference_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    inference_output_filename=\"inference_result.csv\",\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n       a     b\n0  11.0  14.1\n1  12.1  15.1\n2  13.1  16.1\nAdding 10 to df\nOutput\n       a     b\n0  21.0  24.1\n1  22.1  25.1\n2  23.1  26.1\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\nInference result:\n    distance\n0  12.798828\n1  14.283557\n2  15.697771\n\n\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \nthree_components_pipeline = three_components_pipeline(\n    # first preprocessing component\n    preprocessing_training_input_file=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    preprocessing_training_output_filename=\"preprocessed_training_data.csv\",\n    x=10,\n    \n    # second preprocessing component\n    preprocessing_test_input_file=Input(type=\"uri_file\", path=\"./data/dummy_test.csv\"),\n    preprocessing_test_output_filename=\"preprocessed_test_data.csv\",\n    \n    # Training component parameters:\n    training_output_filename=\"model.pk\",\n    \n    # Inference component parameters:\n    inference_output_filename=\"inference_results.csv\",\n)\n\nthree_components_pipeline_job = ml_client.jobs.create_or_update(\n    three_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_three_components_refactored\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(three_components_pipeline_job.name)\n\nRunId: blue_sugar_ns1v5dpj4c\nWeb View: https://ml.azure.com/runs/blue_sugar_ns1v5dpj4c?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-29 09:00:10Z] Completing processing run id 2319106a-3802-4727-8e58-c347521ab38f.\n[2024-03-29 09:00:10Z] Completing processing run id caf9c677-ff96-4cd8-ac83-0439f16bc635.\n[2024-03-29 09:00:11Z] Completing processing run id 3c7a3956-de79-4e6c-90d1-e012ed8ccaa8.\n[2024-03-29 09:00:12Z] Submitting 1 runs, first five are: eeca7330:4a267c73-32ee-451d-9d53-b144842236ee\n[2024-03-29 09:00:52Z] Completing processing run id 4a267c73-32ee-451d-9d53-b144842236ee.\n\nExecution Summary\n=================\nRunId: blue_sugar_ns1v5dpj4c\nWeb View: https://ml.azure.com/runs/blue_sugar_ns1v5dpj4c?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nHere we can see the resulting pipeline:\n\n\n\n\n\nLet’s see how to put all the code needed for creating a pipeline into a script.\n\n\n\n%%writefile pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \n    \"training_output_filename\": \"model.pk\",\n    \n    \"inference_output_filename\": \"inference_results.csv\",\n\n    \"experiment_name\": \"e2e_three_components_in_script\"\n}\n\nWriting pipeline_input.json\n\n\n\n\n\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\n# -------------------------------------------------------------------------------------\n# Interface for each component\n# -------------------------------------------------------------------------------------\n# Preprocessing\npreprocessing_command = command(\n    inputs=dict(\n        input_file=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py \"\n        \"--input_file ${{inputs.input_file}} \"\n        \"-x ${{inputs.x}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n# Training\ntraining_command = command(\n    inputs=dict(\n        input_folder=Input (type=\"uri_folder\"),\n        input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py \"\n        \"--input_folder ${{inputs.input_folder}} \"\n        \"--input_filename ${{inputs.input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\ntraining_component = ml_client.create_or_update(training_command.component)\n\n# Inference\ninference_command = command(\n    inputs=dict(\n        preprocessed_input_folder=Input (type=\"uri_folder\"),\n        preprocessed_input_filename=Input (type=\"string\"),\n        model_input_folder=Input (type=\"uri_folder\"),\n        model_input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n        \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n        \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n        \"--model_input_folder ${{inputs.model_input_folder}} \"\n        \"--model_input_filename ${{inputs.model_input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}} \",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\n# -------------------------------------------------------------------------------------\n# Pipeline definition\n# -------------------------------------------------------------------------------------\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object. This is a \n    # sub-class of dict which allows to get access to fields \n    # as object attributes (a bit more convenient IMO) in addition \n    # to also allowing the dict syntax.\n    config = Bunch (**config)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    three_components_pipeline_job = ml_client.jobs.create_or_update(\n        three_components_pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(three_components_pipeline_job.name)\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py\n\n\nBad pipe message: %s [b'1~\\xd1B\\xe9k\\xf8\\x8beF\\x0bi8_~\\n\\xa2F \\xfec\\x82\\xc3\\xb3^P&\\xb5A\\xd2\\xbb\\xa6\\xb1\\xc5\\xef\\x04\\xb7C\\xa9\\xeb\\xb2U\\xed\\x81\\x80M\\x05\\xf7\\x85H\\xc8\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\nBad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"\\xcd\\xe4\\xaew\\x91`\\x94\\xc6fO\\xea\\x92 \\xc7b\\xb15G\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00&lt;\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\", b'\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b'\\x0b\"a7\\xfa\\xa1#\\xf3\\x88\\xcc%\\xae\\xb45\\xbc\\xdbY\\xb8\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0\\'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00&lt;\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00']\nBad pipe message: %s [b'\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e']\nBad pipe message: %s [b'7\\x992kK\\xc1\\xdbF\\x8b\\xb1\\xe1l\\x19\\xbfA&lt;\\x1fc\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02']\nBad pipe message: %s [b'\\xcf\\xf4\\xe1\\xe6\\xec\\xa7$\\x0f\\x95\\xd8\\xe3X\\xfcm\\x93\\xc2\\x06?\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00', b'\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12']\nBad pipe message: %s [b'Nv\\xa8\\xf4\\x13\\xe0t\\x12q\\xe1\\xb8\\xa4\\xe0(\\xaflvv']\nBad pipe message: %s [b'\\xd5\\xc3({`3.\\xe2\\xad\\xa8.6\\x01\\xe9\\xb4\\x06\\xba\\xb1\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x15\\x03\\x00']\nBad pipe message: %s [b\"\\xa7\\xe2\\x12\\x89\\xeaUh\\xb9\\x1a\\xc3\\x92\\x85\\x1f\\xd4\\xf7\\xaf\\xb4\\xcd\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\", b'\\x03\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\nBad pipe message: %s [b'\\xc7\\x95X[|\\x00\\xb9,o\\xa7\\x95\\xdd\\xee\\xd3A\\xd2g\\x06\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00', b\":\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x96\\x00\"]\nBad pipe message: %s [b'\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00']\nBad pipe message: %s [b'\\x10\\xc0']\nBad pipe message: %s [b'\\x15\\xc0\\x0b\\xc0\\x01']\n\n\nWe can now run the script from command line:\nFirst we open up a terminal and activate a conda environment that uses the python SDK version 2. Let’s see what environments we currently have:\nconda env list\nAs of now, this provides the following list:\n# conda environments:\n#\nbase                     /anaconda\nazureml_py310_sdkv2      /anaconda/envs/azureml_py310_sdkv2\nazureml_py38          *  /anaconda/envs/azureml_py38\nazureml_py38_PT_TF       /anaconda/envs/azureml_py38_PT_TF\njupyter_env              /anaconda/envs/jupyter_env\nFrom that list, the conda environment using SDK v2 is azureml_py310_sdkv2 (use another if that changes when you read this)\nWe activate it and run our script:\nconda activate azureml_py310_sdkv2\npython hello_world_pipeline.py\n\n\n\nLet’s introduce two optional changes:\n\nInstead of defining the preprocessing_command, training_command and inference_command out of the pipeline function, we will define them inside.\nWe will avoid creating the components beforehand, by not calling ml_client.create_or_update (my_component_command.component), as it was done for example here:\n\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\ndef connect ():\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n# -------------------------------------------------------------------------------------\n# Pipeline definition\n# -------------------------------------------------------------------------------------\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    \n    print (\n        \"Running hello-world pipeline with args\", \n        preprocessing_training_input_file,\n        preprocessing_training_output_filename,\n        x,\n        preprocessing_test_input_file,\n        preprocessing_test_output_filename,\n        training_output_filename,\n        inference_output_filename,\n        sep=\"\\n\",\n    )\n    \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./training/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./inference/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object.\n    # This allows to get access to fields as object attributes\n    # Which I find more convenient.\n    config = Bunch (**config)\n\n    # Connect to AML client\n    ml_client = connect ()\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    three_components_pipeline_job = ml_client.jobs.create_or_update(\n        three_components_pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(three_components_pipeline_job.name)\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py\n\n\n\n\n\n\nSo far we have been using a serverless compute, where Azure automatically creates the compute instances needed for running the pipeline, scaling and deleting them as required. More information can be found here. In this section we opt to use a specific compute instance. This has some advantages: while the serveless mode can shut down our compute when idle, and needs to start it again when new loads arrive, with a compute instance we can ensure that the instance is always running and the functions loaded, which may be important in time critical situations. More information can be found here.\nIn addition to this change, we will also us make the code a bit more modular and reusable. We do so by: - Indicating custom environments that can be adapted to different requirements. - Defining different functions that: - Connect to the AML workspace. - Create the environment. - Create the pipeline. - Set up and run the created pipeline.\nWe will separate the functions into two different files: an aml_utils.py module where we include functions that can be reused across different pipelines, and a hello_world.py script where we have code specific for our “Hello World” pipeline.\nLet us start with the aml_utils.py file. We will be writing the consecutive functions one after the other, appending them together with the magic command %%writefile -a aml_utils.py, which appends when we pass the flag -a.\n\n\n\n\nWe start with the imports:\n\n%%writefile aml_utils.py\n# Standard imports\nimport json\n\n# Third-party imports\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import MLClient\nfrom azure.ai.ml.entities import Environment\nfrom azure.identity import DefaultAzureCredential\n\n\nOverwriting aml_utils.py\n\n\n\n\n\nWe encapsulate the code for connecting to AML in a separate function, which we append to the previous code:\n\n%%writefile -a aml_utils.py\ndef connect ():\n    \"\"\"Connects to Azure ML workspace and returns a handle to use it.\"\"\"\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n\nAppending to aml_utils.py\n\n\n\n\n\nUntil now, we have been using environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\" when defining our component interfaces with the command function. This is one of the environments alreadyt available in the Azure ML studio, and it allows us to use scikit-learn as well as azure ml libraries on a ubuntu20.0.04 OS. Let us create a custom environment instead:\n\n%%writefile hello_world.yml\nname: hello-world\ndependencies:\n- python=3.10\n- pip\n- pandas\n- numpy\n- pip:\n  - scikit-learn\n  - joblib\n  - azure-ai-ml\n\nOverwriting hello_world.yml\n\n\nAvailable docker images can be found here. With this, we can define our envioroment as follows:\n\n%%writefile -a aml_utils.py\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"Creates environment in AML workspace\"\n    env = Environment (\n        image=image,\n        conda_file=conda_file,\n        name=name_env,\n        description=description_env,\n    )\n    ml_client.environments.create_or_update (env)\n\n    \n\nAppending to aml_utils.py\n\n\nAfter this, we can replace the name of our environment in the command functions that we will use belowfor defining the interface of each component, for instance as follows:\npreprocessing_component = command(\n    ...\n    environment=\"hello-world@latest\",\n    ...\n)\n\n\n\nThe compute instance can be indicated with just one line of code, which will be included in the function described in next subsection, called connect_setup_and_run:\n# change this with the name of your compute instance in AML\npipeline.settings.default_compute = \"my-compute-instance\" \nWe will also need to remove the argument compute=\"serverless\" from the pipeline decorator, as we will see below when we define our pipeline function.\n\n\n\nWe now define a connect_setup_and_run where we put all the necessary code for setting up and running any pipeline previously created. The function also connects to the AML workspace by calling connect above:\n\n%%writefile -a aml_utils.py\ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\n\nAppending to aml_utils.py\n\n\n\n\n\nFinally, we will write a helper function that reads the configuration from a json file and converts the resulting dictionary into a Bunch object. The Bunch class inherits from the standard dict class, and allows to get access to each dictionary field as if it was an object attribute. It also allows to get access to the dict fields in the standard way. For instance, both:\nx = my_bunch.my_field\nmy_bunch.my_field = x+1\nand\nx = my_bunch[\"my_field\"]\nmy_bunch[\"my_field\"] = x + 1\nare equivalent.\nHere is the resulting read_config function:\n\n%%writefile -a aml_utils.py\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    config = Bunch (**config)\n\n    return config\n\nAppending to aml_utils.py\n\n\n\n\n\n\nIn this section, we use a config file that is the same as the one in the previous section (“Putting everything into a script”), but adding the following parameters:\n    \"compute_name\": \"jaumecpu\",\n    \"image\" = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\"=\"./hello_world.yml\",\n    \"description_env\"=\"Hello World\"   \nThe added parameters indicate the compute instance and environment details. The final config file is as follows:\n\n%%writefile pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\"\n}\n\nOverwriting pipeline_input.json\n\n\n\n\n\nLet us know write the functions that are specific for our current pipeline. We do so in the script that we will be running from command line, hello_world_pipeline.py.\n\n\nLet us start again with the imports section:\n\n%%writefile hello_world_pipeline.py\n# Standard imports\nimport argparse\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n)\n\n# Utility functions\nfrom aml_utils import (\n    connect,\n    create_env,\n    connect_setup_and_run,\n    read_config,\n)\n\n\n\n\n\nWe write next our pipeline function, which indicates the components to be used and how they are connected throug inputs and outputs. The only change with respect to previous pipeline functions is that we indicate as environment the one we just created, “hello-world”, when we describe each component through the command function. The rest doesn’t change.\n\n%%writefile -a hello_world_pipeline.py\n@dsl.pipeline(\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n        \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./training/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./inference/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"hello-world@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \n\n\n\n\nNext we define a function that both creates and runs the pipeline implemented above. This function performs all the steps implemented so far: it reads a config file, instantiates a pipeline object by calling our three_components_pipeline function, and finally performs the pipeline set-up and runs it by calling connect_setup_and_run:\n\n%%writefile -a hello_world_pipeline.py\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n\n        # name env:\n        name_env=config.name_env,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n    )\n    \n\nOverwriting hello_world_pipeline.py\n\n\n\n\n\nNext, we define a function for parsing the command line arguments:\n\n%%writefile -a hello_world_pipeline.py\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n\n\n\n\nAnd finally, we write our main function which simply calls the argument parser and calls run_pipeline with the parsed arguments:\n\n%%writefile -a hello_world_pipeline.py\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nThis is how the pipeline can be run from ipython, and similarly from the command line:\n\n%run hello_world_pipeline.py\n\nFound the config file in: /config.json\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\nRunning hello-world pipeline with args Namespace(config_path='pipeline_input.json', experiment_name='hello-world-experiment')\nRunId: good_brain_fqtwt959vf\nWeb View: https://ml.azure.com/runs/good_brain_fqtwt959vf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-10 09:06:04Z] Submitting 2 runs, first five are: 56673d93:0ab3c91a-266e-42d1-964b-af6cd9a5a8a9,9dc0f6c7:2a6af947-815b-4014-951e-0a66d370a79b\n[2024-04-10 09:07:08Z] Completing processing run id 0ab3c91a-266e-42d1-964b-af6cd9a5a8a9.\n[2024-04-10 09:07:08Z] Completing processing run id 2a6af947-815b-4014-951e-0a66d370a79b.\n[2024-04-10 09:07:08Z] Submitting 1 runs, first five are: 20670901:7fc64bfc-bee0-4238-be3d-fbd26f2304b6\n[2024-04-10 09:07:30Z] Completing processing run id 7fc64bfc-bee0-4238-be3d-fbd26f2304b6.\n[2024-04-10 09:07:30Z] Submitting 1 runs, first five are: 11635808:7d181008-9749-4ba0-8af0-ee22a9a90a1f\n[2024-04-10 09:07:52Z] Completing processing run id 7d181008-9749-4ba0-8af0-ee22a9a90a1f.\n\nExecution Summary\n=================\nRunId: good_brain_fqtwt959vf\nWeb View: https://ml.azure.com/runs/good_brain_fqtwt959vf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\n\n\nWe add the following to our config file:\n    \"name_env\"=\"hello-world\",\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.ai.ml.entities import Environment\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\ndef connect ():\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n# -------------------------------------------------------------------------------------\n# environment\n# -------------------------------------------------------------------------------------\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"Creates environment in AML workspace\"\n    env = Environment (\n        image=image,\n        conda_file=conda_file,\n        name=name_env,\n        description=description_env,\n    )\n    ml_client.environments.create_or_update (env)\n\n# -------------------------------------------------------------------------------------\n# connect and setup\n# -------------------------------------------------------------------------------------\ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object.\n    # This allows to get access to fields as object attributes\n    # Which I find more convenient.\n    config = Bunch (**config)\n\n    return config\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n    \n    # Pipeline definition\n    @dsl.pipeline(\n        description=\"E2E hello world pipeline with input\",\n    )\n    def three_components_pipeline(\n        # Preprocessing component parameters, first component:\n        preprocessing_training_input_file: str,\n        preprocessing_training_output_filename: str,\n        x: int,\n\n        # Preprocessing component parameters, second component:\n        preprocessing_test_input_file: str,\n        preprocessing_test_output_filename: str,\n\n        # Training component parameters:\n        training_output_filename: str, \n\n        # Inference component parameters:\n        inference_output_filename: str,\n    ):\n        \"\"\"\n        Third pipeline: preprocessing, training and inference.\n\n        Parameters\n        ----------\n        preprocessing_training_input_file: str\n            Path to file containing training data to be preprocessed.\n        preprocessing_training_output_filename: str\n            Name of file containing the preprocessed, training data.\n        x: int\n            Number to add to input data for preprocessing it.\n        preprocessing_test_input_file: str\n            Path to file containing test data to be preprocessed.\n        preprocessing_test_output_filename: str\n            Name of file containing the preprocessed, test data.\n        training_output_filename: str\n            Name of file containing the trained model.\n        inference_output_filename: str\n            Name of file containing the output data with inference results.\n        name_env: str\n            Name of environment to use.\n        \"\"\"\n\n        print (f\"using {config.name_env}@latest\")\n        \n        # -------------------------------------------------------------------------------------\n        # Preprocessing\n        # -------------------------------------------------------------------------------------\n        # Interface\n        preprocessing_component = command(\n            inputs=dict(\n                input_file=Input (type=\"uri_file\"),\n                x=Input (type=\"number\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n            command=\"python preprocessing.py \"\n                \"--input_file ${{inputs.input_file}} \"\n                \"-x ${{inputs.x}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}}\",\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"Pre-processing\",\n        )\n\n        # Instantiation\n        preprocessing_training_job = preprocessing_component(\n            input_file=preprocessing_training_input_file,\n            #output_folder: automatically determined\n            output_filename=preprocessing_training_output_filename,\n            x=x,\n        )\n        preprocessing_test_job = preprocessing_component(\n            input_file=preprocessing_test_input_file,\n            #output_folder: automatically determined\n            output_filename=preprocessing_test_output_filename,\n            x=x,\n        )\n\n        # -------------------------------------------------------------------------------------\n        # Training component\n        # -------------------------------------------------------------------------------------\n        # Interface\n        training_component = command(\n            inputs=dict(\n                input_folder=Input (type=\"uri_folder\"),\n                input_filename=Input (type=\"string\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./training/\",  # location of source code: in this case, the root folder\n            command=\"python training.py \"\n                \"--input_folder ${{inputs.input_folder}} \"\n                \"--input_filename ${{inputs.input_filename}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}}\",\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"Training\",\n        )\n\n        # Instantiation\n        training_job = training_component(\n            input_folder=preprocessing_training_job.outputs.output_folder,\n            input_filename=preprocessing_training_output_filename,\n            #output_folder: automatically determined\n            output_filename=training_output_filename,\n        )\n\n        # -------------------------------------------------------------------------------------\n        # Inference\n        # -------------------------------------------------------------------------------------\n        # Interface\n        inference_component = command(\n            inputs=dict(\n                preprocessed_input_folder=Input (type=\"uri_folder\"),\n                preprocessed_input_filename=Input (type=\"string\"),\n                model_input_folder=Input (type=\"uri_folder\"),\n                model_input_filename=Input (type=\"string\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./inference/\",  # location of source code: in this case, the root folder\n            command=\"python inference.py \" \n                \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n                \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n                \"--model_input_folder ${{inputs.model_input_folder}} \"\n                \"--model_input_filename ${{inputs.model_input_filename}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}} \",\n\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"inference\",\n        )\n\n        # Instantiation\n        inference_job = inference_component(\n            preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n            preprocessed_input_filename=preprocessing_test_output_filename,\n            model_input_folder=training_job.outputs.output_folder,\n            model_input_filename=training_output_filename,\n            #output_folder: automatically determined\n            output_filename=inference_output_filename,\n        )\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n    )\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py\n\n\n\n%run hello_world_pipeline.py\n\nFound the config file in: /config.json\n\n\nRunning hello-world pipeline with args Namespace(config_path='pipeline_input.json', experiment_name='hello-world-experiment')\nusing hello-world@latest\nRunId: lucid_napkin_t6nkwzqqfx\nWeb View: https://ml.azure.com/runs/lucid_napkin_t6nkwzqqfx?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-10 09:42:21Z] Submitting 2 runs, first five are: a13baad8:2e78988c-ec3d-42c7-ad94-54617bee7252,e9a47e09:b17a6162-ff6c-48a3-af00-becc887c58d8\n[2024-04-10 09:42:43Z] Completing processing run id 2e78988c-ec3d-42c7-ad94-54617bee7252.\n[2024-04-10 09:42:54Z] Completing processing run id b17a6162-ff6c-48a3-af00-becc887c58d8.\n[2024-04-10 09:42:55Z] Submitting 1 runs, first five are: 9e02ee11:40379116-e551-49fa-b02b-8af7678e75e4\n[2024-04-10 09:43:16Z] Completing processing run id 40379116-e551-49fa-b02b-8af7678e75e4.\n[2024-04-10 09:43:17Z] Submitting 1 runs, first five are: 01e4367a:e69290f9-ce7c-4946-a3b9-db4b0ab5ad0a\n[2024-04-10 09:43:38Z] Completing processing run id e69290f9-ce7c-4946-a3b9-db4b0ab5ad0a.\n\nExecution Summary\n=================\nRunId: lucid_napkin_t6nkwzqqfx\nWeb View: https://ml.azure.com/runs/lucid_napkin_t6nkwzqqfx?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\ndef mydec (f):\n    def mywrap (*args, **kwargs):\n        print (\"hello\")\n        f()\n        print (\"bye\")\n    return mywrap\n\ndef outerf ():\n    x = 3\n    @mydec\n    def myf ():\n        print (f\"myf: {x}\")\n    myf()\n\n\nouterf()\n\nhello\nmyf: 3\nbye\n\n\n\n'${{parent.inputs.name_env}}'\n\n\nfrom hello_world_pipeline import connect, create_env, read_config\n\n\nml_client = connect ()\n\nFound the config file in: /config.json\n\n\n\nconfig = read_config (\"./pipeline_input.json\")\n\n\ncreate_env (\n    ml_client, \n    config.image,\n    config.conda_file,\n    config.name_env,\n    config.description_env,\n)\n\nFound the config file in: /config.json\n\n\n\nx=ml_client.environments.get (config.name_env, version=\"1\")\n\n\nx.name\n\n'hello-world'\n\n\n\nconfig.name_env\n\n'hello-world'\n\n\n\nx.version\n\n'1'\n\n\n\n\n\n\n\nCreate more structure on config input file: one dictionary per pipeline component.\n\n\n\n\n\nCreate components using @command_component decorator, see https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python?view=azureml-api-2#create-components-for-building-pipeline"
  },
  {
    "objectID": "posts/data_science/hello_world.html#starting-development-with-a-notebook",
    "href": "posts/data_science/hello_world.html#starting-development-with-a-notebook",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "In this section, we will write our code in a notebook and make sure it works well. Then, we will convert it to a script and run it from the terminal. Finally, we will add some logs with MLFlow.\nAlthough not required, as a very first step we can create a environment and kernel following the tutorial in https://learn.microsoft.com/en-gb/azure/machine-learning/tutorial-cloud-workstation?view=azureml-api-2\nFollowing the previous tutorial, create a notebook and type the following hello world code:\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\nhello_world (\"Jaume\")\n\nHello Jaume and world\n\n\nFantastic, the code works ;-). Now, let’s convert it to a script that can be run from terminal. The tutorial above explains how to convert the notebook to a python file. In our case, we will first add an argument parser and then write it to file using the magic cell %%writefile\n\n%%writefile hello_world_core.py\nimport argparse\n\ndef hello_world (name):\n    \"\"\"Greets the indicated person and the world in general.\"\"\"\n    \n    print (f\"Hello {name} and world\")\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", type=str, help=\"person to greet\")\n    args = parser.parse_args()\n    \n    return args\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    hello_world (args.name)\n\nif __name__ == \"__main__\":\n    main()\n\nWriting hello_world_core.py\n\n\nBad pipe message: %s [b'\\x80\\xb8\\xc2\\x0e\\x1b\\xcd4\\xe90\\x12O\\x89\\xff4\\x0b\\xbf;\\xab \\xb6*\\xd3\\xab\\x91\\xb6\\x87\\xe82s\\x1fIv\\xd3\\x172\\xa6\\x11\\xb2w\\xff\\xf2\\x02L\\xbf_\\xc1\\t\\x1dn\\xdc\\x0f\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02']\nBad pipe message: %s [b'4\\xf9%\\x9at\\xbe\\x08\\x03\\x06\\xf5.E\\xe9\\xd7\\xb3\\xa1Z\\x8d ']\nBad pipe message: %s [b'\\x0c5\\x85\\xf5Z']\nBad pipe message: %s [b'\\xe3\\x18^', b'\\x9cOo\\xfe*\\xa90\\xa3\\xf8\\xfa#\\x8d\\x0b\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r']\nBad pipe message: %s [b\"\\x85c}\\xe4\\x85\\xb5*i\\xf3vog\\x0b\\x16\\\\\\xdd\\x9e\\x0e\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x00\", b'1\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01']\nBad pipe message: %s [b\"\\xf3\\x03\\x81E\\x16\\x17\\x18\\x1e0(\\xa5\\x94\\x96\\x98\\x0cw\\xd6\\xe3\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00\", b'\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00']\nBad pipe message: %s [b'\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n\n\nNow, we can open up a terminal, as illustrated in the tutorial above, cd to the folder where the script is and run it:\ncd  Users/&lt;my_user&gt;/hello_world\npython hello_world_core.py --name Jaume\n\n\n\n%%writefile hello_world_with_logs.py\nimport mlflow\nfrom hello_world_core import hello_world, parse_args\n\ndef start_logging (args):\n    # set name for logging\n    mlflow.set_experiment(\"Hello World with logging\")\n    mlflow.start_run()\n    mlflow.log_param (\"name to log\", args.name)\n    \ndef finish_logging ():\n    mlflow.end_run ()\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    args = parse_args ()\n    start_logging (args)\n    hello_world (args.name)\n    finish_logging ()\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting hello_world_with_logs.py\n\n\nLet’s run it and see:\npython hello_world_with_logs.py --name Peter\nHere is the newly created job:\n\nAnd the name passed as argument:\n\nWe start by getting a connection to our Azure ML (AML for short) workspace. We use here a simple connection mechanism that doesn’t require writting your subscription, resource group and workspace details:\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json"
  },
  {
    "objectID": "posts/data_science/hello_world.html#running-script-as-a-job",
    "href": "posts/data_science/hello_world.html#running-script-as-a-job",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "We now convert the previous script into a job that can be run from the UI.\n\n\n\n# Standard imports\nimport os\n\n# Third-party imports\nimport pandas as pd\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n\n\n\nFor the remaining part of this tutorial, we will be needing an ml_client handle. This will allow us to create and use resources from our workspace. The simplest way to get such handle is with the following code:\n\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\nFound the config file in: /config.json\n\n\n\n\n\nWe specify a job using the command decorator:\n\njob = command(\n    inputs=dict(\n        name=\"Jaume\", # default value of our parameter\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Simplest Hello World\",\n)\n\n\nNote: we indicate as environment “AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest”, which actually contains more libraries than we need, such as sklearn. Simpler environments to use can be found in the “Environments” section of the workspace.\n\n… and submit it using create_or_update from ml_client:\n\nml_client.create_or_update(job)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nUploading hello_world (8.59 MBs): 100%|██████████| 8591281/8591281 [00:00&lt;00:00, 40584539.30it/s]\n\n\n\n\n\n\n\nExperiment\nName\nType\nStatus\nDetails Page\n\n\nhello_world\nclever_spade_sq4jwcg67r\ncommand\nStarting\nLink to Azure Machine Learning studio\n\n\n\n\n\nIn the link that appears, we can see the status of the job, which initially is “Queued”. We need to wait until it is completed (and refresh the page to see this). Once it is completed, we can look at the logs:\n\nIn the logs, we can see the messages printed in console:\n\n\n\n\nAbove, we indicated a default value for the input argument name. It would be good to be able to submit jobs with different values for that argument. One way to do that is:\n\nIn the job’s Overview tab, click on “Edit and submit”\n\n\n\nIn the “Training script” section, edit the “Inputs” by clicking on the pencil next to it:\n\n\n\nIn the “Input value” field, type the new value you want for the argument:\n\n\n\nHit Next several times and then Submit.\nIf we go to the jobs section of the workspace, and enter again our job (“helloworld”), we can see that a new job has been submitted:\n\n\nIn its Overview tab, under “See all properties”, we can inspect the json file:\n\n… and see that the new value (Peter) is used in its “parameters” dictionary:\n\nThe std_log.txt for this job shows the new message with Peter:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#creating-single-component-pipeline",
    "href": "posts/data_science/hello_world.html#creating-single-component-pipeline",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "hello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.58 MBs): 100%|██████████| 8578531/8578531 [00:00&lt;00:00, 21700197.27it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_input: str\n        Input to pipeline, here name of person to greed.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\n# Let's instantiate the pipeline with the parameters of our choice\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"David\",\n)\n\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_registered_components\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:08:19Z] Submitting 1 runs, first five are: 605cf9a7:d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6\n[2024-03-26 14:12:40Z] Completing processing run id d9904e2d-3ecb-4ddc-a04d-e2fed4facfe6.\n\nExecution Summary\n=================\nRunId: shy_cabbage_xb9vv4fswl\nWeb View: https://ml.azure.com/runs/shy_cabbage_xb9vv4fswl?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World witn Input\",\n)\n\nhello_world_component = ml_client.create_or_update(job.component)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8589758/8589758 [00:00&lt;00:00, 24178345.78it/s]\n\n\n\n\n\n# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\nfrom azure.ai.ml import dsl\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_input: str\n        Input to pipeline, here name of person to greed.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Joseph\",\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_input\",\n)\nml_client.jobs.stream(pipeline_job.name)\n\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 14:38:43Z] Submitting 1 runs, first five are: cd1599c4:ce24c41e-946d-48cd-99b2-70ebde3befb2\n[2024-03-26 14:44:58Z] Completing processing run id ce24c41e-946d-48cd-99b2-70ebde3befb2.\n\nExecution Summary\n=================\nRunId: olive_plastic_gvnjy01b5s\nWeb View: https://ml.azure.com/runs/olive_plastic_gvnjy01b5s?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nNotes about Input:\n\nWhen using Input(type=“uri_folder”) or Input(type=“uri_file”), the value passed cannot be a string, it must be an Input type, for example:\n\njob = command(\n    inputs=dict(\n        file_name=Input (type=\"uri_file\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(path=\"/path/to/file\"),\n)\n\nHowever, when using Input(type=“string”) or Input(type=“number”), the input must be a string or number, not Input\n\njob = command(\n    inputs=dict(\n        name=Input (type=\"string\"),\n    ),\n    ...\n)\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=\"Mary\",\n)\n\nIn the latter case, the input does not appear in the graph of the pipeline, in the UI.\n\n\n\n\n\n# Component definition and registration\njob = command(\n    inputs=dict(\n        name=Input (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{inputs.name}}\",\n    environment=\"hello-world\",\n    display_name=\"Hello World with uri_file\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n    pipeline_job_input: str,\n):\n    \"\"\"\n    Hello World pipeline\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Input to pipeline, here path to file.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component(\n        name=pipeline_job_input,\n    )\n\npipeline = hello_world_pipeline(\n    pipeline_job_input=Input(type=\"uri_file\", path=\"./hello_world_core.py\"),\n)\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (8.59 MBs): 100%|██████████| 8588206/8588206 [00:00&lt;00:00, 24482901.98it/s]\n\n\nUploading hello_world_core.py (&lt; 1 MB): 0.00B [00:00, ?B/s] (&lt; 1 MB): 100%|██████████| 514/514 [00:00&lt;00:00, 12.0kB/s]\n\n\n\n\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:06:11Z] Submitting 1 runs, first five are: a08118c5:2099b6ad-fb3a-4cac-9557-c8cf355b8b1b\n[2024-03-26 15:11:50Z] Completing processing run id 2099b6ad-fb3a-4cac-9557-c8cf355b8b1b.\n\nExecution Summary\n=================\nRunId: great_tail_pw48pry0lj\nWeb View: https://ml.azure.com/runs/great_tail_pw48pry0lj?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\nIf you click on the “Data” component and inside it click on “Explore”, you can see the contents of the file, since it is a text python file.\n\n\n\n\n\n# Component definition and registration\njob = command(\n    outputs=dict(\n        name=Output (type=\"uri_file\"),\n    ),\n    code=f\"./\",  # location of source code: in this case, the root folder\n    command=\"python hello_world_core.py --name ${{outputs.name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Hello World with uri_file as output\",\n)\nhello_world_component = ml_client.create_or_update(job.component)\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef hello_world_pipeline(\n):\n    # using data_prep_function like a python call with its own inputs\n    hello_world_job = hello_world_component()\n\npipeline = hello_world_pipeline()\n\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline,\n    # Project's name\n    experiment_name=\"e2e_hello_world_with_uri_file_as_output\",\n)\n\n# Pipeline running\nml_client.jobs.stream(pipeline_job.name)\n\nUploading hello_world (9.48 MBs): 100%|██████████| 9483085/9483085 [00:00&lt;00:00, 22969826.09it/s]\n\n\n\n\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-26 15:36:23Z] Submitting 1 runs, first five are: 528b20ac:27e32a0a-71a0-4bc3-abec-eaeae70ff08e\n[2024-03-26 15:41:30Z] Completing processing run id 27e32a0a-71a0-4bc3-abec-eaeae70ff08e.\n\nExecution Summary\n=================\nRunId: teal_soccer_m9bkcgz2gq\nWeb View: https://ml.azure.com/runs/teal_soccer_m9bkcgz2gq?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld"
  },
  {
    "objectID": "posts/data_science/hello_world.html#pipeline-with-two-components",
    "href": "posts/data_science/hello_world.html#pipeline-with-two-components",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "In order to have something more meaningful, we create a pipeline with two components. The first one “pre-processes” the input data frame by adding one (or a specified number) to it, storing the output as a csv file. The second component builds a “model” by calculating the mean and standard deviation, and saves it as pickle file.\n\n\nWhenever we have multiple components, a common practice in Azure ML is to have a dedicated subfolder for each one. The subfolder contains the source .py file implementing the component, and may contain a conda yaml file with dependencies that are specific for this component. In our case, we use a pre-built environment so that we don’t need to include any conda yaml file.\n\nos.makedirs (\"preprocessing\", exist_ok=True)\nos.makedirs (\"training\", exist_ok=True)\nos.makedirs (\"data\", exist_ok=True)\n\n\ndf = pd.DataFrame (\n    {\n        \"a\": [1,2,3],\n        \"b\": [4,5,6],\n    },\n)\n\ndf.to_csv (\"data/dummy_input.csv\")\n\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data frame\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data frame\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data,\n    x,\n    preprocessed_data,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (preprocessed_data)\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (args.input_data, args.x, args.preprocessed_data)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\n# Component definition and registration\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_file\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to preprocessed data\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    preprocessed_data: str,\n    model_path: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\"\"\"\n    df = pd.read_csv (preprocessed_data, index_col=0)\n    model = train_model (df)\n    joblib.dump (model, model_path)\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (args.preprocessed_data, args.model)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_file\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_file\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 1043/1043 [00:00&lt;00:00, 112778.01it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\n\nreload (preprocessing)\nreload (training)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_preprocess_output: str,\n    pipeline_job_model_output: str,\n):\n    \"\"\"\n    Tests two component pipeline with preprocessing and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *file*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *file*. Not present in the final pipeline.\n    \"\"\"\n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_x,\n        pipeline_job_preprocess_output,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_preprocess_output=\"./test_pipeline/preprocessed_data.csv\",\n    pipeline_job_model_output=\"./test_pipeline/model.pk\"\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\n\n\n\n\n\nNow we are ready to implement and submit our pipeline. The code will be very similar to the test_pipeline implemented above, except for the fact that we don’t need to indicate the outputs that connect one component to the next, since these are automatically populated by AML.\n\n# Pipeline definition and registration\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef two_components_pipeline(\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n):\n    \"\"\"\n    Pipeline with two components: preprocessing, and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\n\ntwo_components_pipeline = two_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n)\n\ntwo_components_pipeline_job = ml_client.jobs.create_or_update(\n    two_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_two_components_pipeline\",\n)\n\n# Pipeline running\nml_client.jobs.stream(two_components_pipeline_job.name)\n\nRunId: quiet_root_nb0c997gsp\nWeb View: https://ml.azure.com/runs/quiet_root_nb0c997gsp?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-27 10:45:01Z] Submitting 1 runs, first five are: caf1c51e:87b5910c-0e8d-4ca0-a808-f52a94d52b56\n[2024-03-27 10:51:05Z] Completing processing run id 87b5910c-0e8d-4ca0-a808-f52a94d52b56.\n[2024-03-27 10:51:05Z] Submitting 1 runs, first five are: 3d73a420:6c033636-f3d8-4fe2-ba8d-26072210ba05\n[2024-03-27 10:56:25Z] Completing processing run id 6c033636-f3d8-4fe2-ba8d-26072210ba05.\n\nExecution Summary\n=================\nRunId: quiet_root_nb0c997gsp\nWeb View: https://ml.azure.com/runs/quiet_root_nb0c997gsp?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nWe can see the created pipeline in the Pipelines section of our workspace:\n\n\n\n\n\nWe can see that:\n\nThe path to the preprocessed data has been automatically set to azureml/49824a8b-967f-4410-84a7-bc18b328a1b6/preprocessed_data, where the file name preprocessed_data is the name of the output given in the component definition:\n\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_file\"),\n    )\n\nSince this file name doesn’t have an extension, we cannot preview (see arrow 2). However, we can see its contents if we view the file in the datastore, as indicated below:\n\n\nUnfortunately, the content of the file appears in text format, rather than as a table.\n\nWe can also see the content of the outputs by inspecting the logs of the training component:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#using-uri_folder",
    "href": "posts/data_science/hello_world.html#using-uri_folder",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "Let’s try now using outputs of type “uri_folder”. We need to do two changes for this purpose:\n\nIn the component modules, preprocessing/preprocessing.py and training/training.py, the output arguments args.preprocessed_data and args.model will contain a path to a folder where the file is stored. Therefore, when saving the file, we need to append its name to the input path:\n\n#In preprocessing module:\ndf.to_csv (preprocessed_data + \"/preprocessed_data.csv\")\nand\n# In training module:\ndf = pd.read_csv (preprocessed_data + \"/preprocessed_data.csv\", index_col=0)\n\n# later in same module:\njoblib.dump (model, model_path + \"/model.pk\")\n\nIn the definition of the pipeline, we replace the type of the outputs to be “uri_folder”, and the input to the training component to be “uri_folder” as well.\n\n    # In preprocessing component\n    ...    \n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    ...\n        \n    # In training component\n    ...\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_folder\"),\n    ),\n    ...\nHere we have the final implementation of our components:\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data *file*\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data *folder* containing the preprocessed data.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data,\n    x,\n    preprocessed_data,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (preprocessed_data + \"/preprocessed_data.csv\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (args.input_data, args.x, args.preprocessed_data)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to preprocessed data\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    preprocessed_data: str,\n    model_path: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\"\"\"\n    df = pd.read_csv (preprocessed_data + \"/preprocessed_data.csv\", index_col=0)\n    model = train_model (df)\n    joblib.dump (model, model_path + \"/model.pk\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (args.preprocessed_data, args.model)\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        preprocessed_data=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        model=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py --preprocessed_data ${{inputs.preprocessed_data}} --model ${{outputs.model}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 1084/1084 [00:00&lt;00:00, 39997.06it/s]\n\n\n\n\n\n\n\nAgain, before submitting the pipeline job, we first test a manually built pipeline. Note that the new pipeline uses paths to folders, and not paths to files, for the outputs:\n\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\n\nreload (preprocessing)\nreload (training)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_preprocess_output: str,\n    pipeline_job_model_output: str,\n):\n    \"\"\"\n    Tests two component pipeline with preprocessing and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *folder*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *folder*. Not present in the final pipeline.\n    \"\"\"\n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_x,\n        pipeline_job_preprocess_output,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_preprocess_output=\"./test_pipeline\",\n    pipeline_job_model_output=\"./test_pipeline\"\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\n\n\n… and the implementation of our pipeline:\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef two_components_pipeline(\n    pipeline_job_data_input,\n    pipeline_job_x,\n):\n    \"\"\"\n    Pipeline with two components: preprocessing, and training.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\ntwo_components_pipeline = two_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n)\n\ntwo_components_pipeline_job = ml_client.jobs.create_or_update(\n    two_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_two_components_pipeline_with_uri_folder\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(two_components_pipeline_job.name)\n\nRunId: calm_zebra_t3gb5cjnrk\nWeb View: https://ml.azure.com/runs/calm_zebra_t3gb5cjnrk?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-28 08:45:53Z] Completing processing run id 1ff53a74-943f-4f94-8efd-4b55b345449f.\n[2024-03-28 08:45:54Z] Submitting 1 runs, first five are: e26d0be6:8e0f40eb-e2c3-4feb-a0d0-9882de1daebc\n\nExecution Summary\n=================\nRunId: calm_zebra_t3gb5cjnrk\nWeb View: https://ml.azure.com/runs/calm_zebra_t3gb5cjnrk?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nNow, when we go to the “Explore” tab, in the output data of the preprocessed component, we can see the contents of the output preprocessed data in tabular format. We can also see that the extension of the output, which is csv file:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#pipeline-with-three-components",
    "href": "posts/data_science/hello_world.html#pipeline-with-three-components",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "We add now a third component, which takes as input test data, preprocesses it, and uses the model to perform “inference”. For this pipeline, we can reuse the training component from the last section, but we need to slighty modify the preprocessing component to use an additional argument: the name of the output file. This is needed because there will be two outputs: one when preprocessing the training data, and the other when preprocessing the test data.\n\n\n\nos.makedirs (\"inference\", exist_ok=True)\ntest_data = pd.DataFrame (\n    {\n        \"a\": [11., 12.1, 13.1],\n        \"b\": [14.1, 15.1, 16.1],\n    }\n)\ntest_data.to_csv (\"data/dummy_test.csv\")\n\n\n\n\n\n%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (df, x):\n    \"\"\"Adds `x` to input data frame `df`.\"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data\", type=str, help=\"path to input data *file*\")\n    parser.add_argument(\"--preprocessed_data\", type=str, help=\"path to output data *folder* containing the preprocessed data.\")\n    parser.add_argument(\"--preprocessed_file_name\", type=str, help=\"name of preprocessed file name.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_data: str,\n    preprocessed_data: str,\n    preprocessed_file_name: str,\n    x: int,\n):\n    df = pd.read_csv (input_data, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (f\"{preprocessed_data}/{preprocessed_file_name}\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (\n        input_data=args.input_data, \n        preprocessed_data=args.preprocessed_data,\n        preprocessed_file_name=args.preprocessed_file_name,\n        x=args.x, \n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_data=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        preprocessed_file_name=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        preprocessed_data=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py --input_data ${{inputs.input_data}} -x ${{inputs.x}} --preprocessed_data ${{outputs.preprocessed_data}} --preprocessed_file_name ${{inputs.preprocessed_file_name}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\nUploading preprocessing (0.0 MBs): 100%|██████████| 1343/1343 [00:00&lt;00:00, 46879.53it/s]\n\n\n\n\nThe preprocessing component doesn’t change from the last pipeline, see “Using uri_folder” section.\n\n\n\n\n%%writefile inference/inference.py\nimport argparse\nimport joblib\nimport pandas as pd\nfrom typing import Tuple\nimport numpy as np\n\ndef inference (\n    model: Tuple[np.ndarray, np.ndarray], \n    df: pd.DataFrame,\n):\n    \"\"\"\n    Runs dummy inference on new data `df`\n    \"\"\"\n    (mu, std) = model\n    z_df = (df - mu) / std\n    print (\"Inference result:\")\n    print (z_df)\n    return z_df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--test_data\", type=str, help=\"path to test data *folder*\")\n    parser.add_argument(\"--test_data_file_name\", type=str, help=\"name of test data file name.\")\n    parser.add_argument(\"--model\", type=str, help=\"path to built model *folder*\")\n    parser.add_argument(\"--inference_output\", type=str, help=\"path to inference result *folder*\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_inference (\n    test_data: str,\n    test_data_file_name: str,\n    model_path: str,\n    inference_data: str,\n):\n    \"\"\"\n    Reads test data and model, performs inference, and writes to output inference file.\n    \n    Parameters\n    ----------\n    test_data: str\n        Path to test (preprocessed) data *folder*\n    test_data_file_name: str\n        Name of test data file.\n    model_path: str\n        Path to built model *folder*\n    inference_data: str\n        Path to inference result *folder*\n    \"\"\"\n    df = pd.read_csv (f\"{test_data}/{test_data_file_name}\", index_col=0)\n    model = joblib.load (model_path + \"/model.pk\")\n    z_df = inference (model, df)\n    z_df.to_csv (inference_data + \"/inference_result.csv\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_inference (\n        test_data=args.test_data, \n        test_data_file_name=args.test_data_file_name,\n        model_path=args.model, \n        inference_data=args.inference_output,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting inference/inference.py\n\n\n\ninference_command = command(\n    inputs=dict(\n        test_data=Input (type=\"uri_folder\"),\n        test_data_file_name=Input (type=\"string\"),\n        model=Input (type=\"uri_folder\"),\n    ),\n    outputs=dict(\n        inference_output=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n            \"--test_data ${{inputs.test_data}} \"\n            \"--test_data_file_name ${{inputs.test_data_file_name}} \"\n            \"--model ${{inputs.model}} \"\n            \"--inference_output ${{outputs.inference_output}}\",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\nUploading inference (0.0 MBs): 100%|██████████| 1912/1912 [00:00&lt;00:00, 63810.98it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\nfrom inference import inference\n\nreload (preprocessing)\nreload (training)\nreload (inference)\n\ndef test_pipeline (\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_test_input: str,\n    pipeline_preprocessed_file_name: str,\n    pipeline_test_file_name: str,\n    \n    # The following parameters are not present in the final pipeline:\n    pipeline_job_preprocess_output: str,\n    pipeline_job_test_output: str,\n    pipeline_job_model_output: str,\n    pipeline_job_inference_output: str,\n):\n    \"\"\"\n    Tests third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_preprocessed_file_name: str\n        Name of (preprocessed) input data file.\n    pipeline_test_file_name: str\n        Name of (preprocessed) test data file.\n    pipeline_job_preprocess_output: str\n        Path to preprocessed data *folder*, to be used as training.\n        Not present in the final pipeline.\n    pipeline_job_test_output: str\n        Path to preprocessed test data *folder*, to be used for inferencing.\n        Not present in the final pipeline.\n    pipeline_job_model_output: str\n        Path to model *folder*. Not present in the final pipeline.\n    pipeline_job_inference_output: str\n        Path to inference result *folder*. Not present in the final pipeline.\n    \"\"\"\n    \n    preprocessing.read_and_preprocess (\n        pipeline_job_data_input,\n        pipeline_job_preprocess_output,\n        pipeline_preprocessed_file_name,\n        pipeline_job_x,\n    )\n    preprocessing.read_and_preprocess (\n        pipeline_job_test_input,\n        pipeline_job_test_output,\n        pipeline_test_file_name,\n        pipeline_job_x,\n    )\n    training.read_and_train (\n        pipeline_job_preprocess_output,\n        pipeline_job_model_output,\n    )\n    inference.read_and_inference (\n        test_data=pipeline_job_test_output,\n        test_data_file_name=pipeline_test_file_name,\n        model_path=pipeline_job_model_output,\n        inference_data=pipeline_job_inference_output,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    pipeline_job_data_input=\"./data/dummy_input.csv\",\n    pipeline_job_x=10,\n    pipeline_job_test_input=\"./data/dummy_test.csv\",\n    pipeline_preprocessed_file_name=\"preprocessed_data.csv\",\n    pipeline_test_file_name=\"preprocessed_test.csv\",\n    \n    # The following parameters are not present in the final pipeline:\n    pipeline_job_preprocess_output=\"./test_pipeline\",\n    pipeline_job_test_output=\"./test_pipeline\",\n    pipeline_job_model_output=\"./test_pipeline\",\n    pipeline_job_inference_output=\"./test_pipeline\",\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n       a     b\n0  11.0  14.1\n1  12.1  15.1\n2  13.1  16.1\nAdding 10 to df\nOutput\n       a     b\n0  21.0  24.1\n1  22.1  25.1\n2  23.1  26.1\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\nInference result:\n      a     b\n0   9.0   9.1\n1  10.1  10.1\n2  11.1  11.1\n\n\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    pipeline_job_data_input: str,\n    pipeline_job_x: int,\n    pipeline_job_test_input: str,\n    pipeline_preprocessed_file_name: str,\n    pipeline_test_file_name: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    pipeline_job_data_input: str\n        Path to input data *file*\n    pipeline_job_x: int\n        Integer to add to input data to convert it to \"preprocessed\" data.\n    pipeline_job_test_input: str\n        Path to (preprocessed) test input *file*\n    pipeline_preprocessed_file_name: str\n        Name of (preprocessed) input data file.\n    pipeline_test_file_name: str\n        Name of (preprocessed) test data file.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_job = preprocessing_component(\n        input_data=pipeline_job_data_input,\n        x=pipeline_job_x,\n        preprocessed_file_name=pipeline_preprocessed_file_name,\n    )\n    \n    preprocessing_test_job = preprocessing_component(\n        input_data=pipeline_job_test_input,\n        x=pipeline_job_x,\n        preprocessed_file_name=pipeline_test_file_name,\n    )\n\n    # using train_func like a python call with its own inputs\n    training_job = training_component(\n        preprocessed_data=preprocessing_job.outputs.preprocessed_data,  # note: using outputs from previous step\n    )\n    \n    # using train_func like a python call with its own inputs\n    inference_job = inference_component(\n        test_data=preprocessing_test_job.outputs.preprocessed_data,\n        test_data_file_name=pipeline_test_file_name,\n        model=training_job.outputs.model,  # note: using outputs from previous step\n    )\n    \nthree_components_pipeline = three_components_pipeline(\n    pipeline_job_data_input=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    pipeline_job_x=10,\n    pipeline_job_test_input=Input(type=\"uri_file\", path=\"./data/dummy_test.csv\"),\n    pipeline_preprocessed_file_name=\"preprocessed_data.csv\",\n    pipeline_test_file_name=\"preprocessed_test_data.csv\",\n)\n\nthree_components_pipeline_job = ml_client.jobs.create_or_update(\n    three_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_three_components_pipeline_with_uri_folder\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(three_components_pipeline_job.name)\n\nRunId: calm_rice_3cmmmtc5mf\nWeb View: https://ml.azure.com/runs/calm_rice_3cmmmtc5mf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-28 10:15:12Z] Submitting 2 runs, first five are: 47ca85c2:a5595dea-3117-47e9-a99d-186b0c346884,4b1f0180:09aecbcc-aa2c-4cad-b134-eb4837724f58\n[2024-03-28 10:20:13Z] Completing processing run id 09aecbcc-aa2c-4cad-b134-eb4837724f58.\n[2024-03-28 10:20:13Z] Submitting 1 runs, first five are: fece868d:164d1e2a-a5d7-4081-9a68-a07033a3feee\n[2024-03-28 10:20:45Z] Completing processing run id 164d1e2a-a5d7-4081-9a68-a07033a3feee.\n[2024-03-28 10:22:15Z] Completing processing run id a5595dea-3117-47e9-a99d-186b0c346884.\n[2024-03-28 10:22:16Z] Submitting 1 runs, first five are: a9d60b27:6a18ae74-2a3c-4e16-a6cb-a58649235bfe\n[2024-03-28 10:22:52Z] Completing processing run id 6a18ae74-2a3c-4e16-a6cb-a58649235bfe.\n\nExecution Summary\n=================\nRunId: calm_rice_3cmmmtc5mf\nWeb View: https://ml.azure.com/runs/calm_rice_3cmmmtc5mf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nHere we can see the resulting pipeline:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#refactoring",
    "href": "posts/data_science/hello_world.html#refactoring",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "From the development of the different pipelines we can extract a few observations that help us create a better refactored pipeline and, at the same time, compile a small set of “design” rules that may help us in future pipelines. In my case, I find it clearer and with less boilerplate to use the following rules:\n\nUse “uri_folder” type for intermediate outputs, and add another parameter next to it containing the output file, something like:\n\ndef pipeline(\n    ...\n    input_folder: str,\n    input_filename: str,\n    ...\n)\n\nUse “_folder” as a prefix for parameters of type uri_folder, “_file” for those of type uri_file, and “_filename” for those indicating names of file names.\nUse the suffix input for those things that are inputs and ouputfor those that are outputs.\nI’m not clear about this one. Many people usually pass a dataframe called df or a numpy array called X, which is passed from one step of the pipeline to the next, without appending words to the name that talk about the content of the dataframe or the array (e.g., use “X” instead of “preprocessed_X” or “inference_result_X”). I tend to find it easier to do a similar thing here for the inputs of intermediate components, when defining the command for those components. Therefore, for the inputs, I would use input_folder rather than preprocessed_training_data_input_folder for indicating the input to the model component. This means that if we replace later the model component with one that works directly on raw (non-preprocessed) data (e.g., because the preprocessing is implicitly done as part of the model), we don’t need to replace the part of the script that parses the arguments to indicate that now the input folder is just training_data_input_folder.\nFor the outputs, it might be useful to add a short prefix to talk about the type of output, so that the pipeline’s diagram shows what is the ouput of each component is. Again, I’m not clear about this one.\nThe exception to the previous rules is when we have more than one input or output folder. In this case, we clearly need to add more words to their names.\nIt is easier to avoid adding pipeline_job_... for each parameter of the pipeline."
  },
  {
    "objectID": "posts/data_science/hello_world.html#final-pipeline",
    "href": "posts/data_science/hello_world.html#final-pipeline",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "%%writefile preprocessing/preprocessing.py\nimport argparse\nimport pandas as pd\n\ndef preprocessing (\n    df: pd.DataFrame, \n    x: int\n):\n    \"\"\"Adds `x` to input data frame `df`.\n\n    Parameters\n    ----------\n    df: DataFrame\n        Input data frame \n    x: int\n        Integer to add to df.\n\n    Returns\n    -------\n    DataFrame.\n        Preprocessed data.\n    \"\"\"\n    \n    print (\"Input\\n\", df)\n    print (f\"Adding {x} to df\")\n    df = df + x\n    print (\"Output\\n\", df)\n    return df\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_file\", type=str, help=\"path to input data file\")\n    parser.add_argument(\"--output_folder\", type=str, help=\"path to output data folder containing the preprocessed data.\")\n    parser.add_argument(\"--output_filename\", type=str, help=\"name of file containing the output, preprocessed, data.\")\n    parser.add_argument(\"-x\", type=int, help=\"number to add to input data for preprocessing it.\")\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_preprocess (\n    input_file: str,\n    output_folder: str,\n    output_filename: str,\n    x: int,\n):\n    \"\"\"Reads input data, preprocesses it, and writes result as csv file in disk.\n\n    Parameters\n    ----------\n    input_file: str\n        Path to input data file.\n    output_folder: str\n        Path to output data folder containing the preprocessed data.\n    output_filename: str\n        Name of file containing the output, preprocessed, data.\n    x: int\n        Number to add to input data for preprocessing it.\n    \"\"\"\n    df = pd.read_csv (input_file, index_col=0)\n    df = preprocessing (df, x)\n    df.to_csv (f\"{output_folder}/{output_filename}\")\n    \ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_preprocess (\n        input_file=args.input_file, \n        output_folder=args.output_folder,\n        output_filename=args.output_filename,\n        x=args.x, \n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting preprocessing/preprocessing.py\n\n\n\npreprocessing_command = command(\n    inputs=dict(\n        input_file=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py \"\n        \"--input_file ${{inputs.input_file}} \"\n        \"-x ${{inputs.x}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\nUploading preprocessing (0.0 MBs): 100%|██████████| 1985/1985 [00:00&lt;00:00, 64070.90it/s]\n\n\n\n\n\n\n\n\n%%writefile training/training.py\nimport argparse\nimport joblib\nimport pandas as pd\n\ndef train_model (df: pd.DataFrame):\n    \"\"\"Trains a dummy Gaussian model from training set df.\n    \n    Parameters\n    ----------\n    df: DataFrame\n        Input data frame\n    \n    Returns\n    -------\n    np.ndarray\n        Average across rows, one per column.\n    np.ndarray\n        Standard deviation across rows, one per column.\n    \"\"\"\n    \n    print (\"Input\\n\", df)\n    mu = df.mean().values\n    std = df.std().values\n    print (\"mu:\\n\", mu)\n    print (\"std:\\n\", std)\n    return mu, std\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    \n    parser.add_argument(\n        \"--input_folder\", \n        type=str, \n        help=\"path to preprocessed training data folder, \"\n             \"containing training set file.\"\n    )\n    parser.add_argument(\n        \"--input_filename\", \n        type=str, \n        help=\"name of file containing preprocessed, training data.\"\n    )\n    parser.add_argument(\n        \"--output_folder\", \n        type=str, \n        help=\"path to output *folder* containing the trained model.\"\n    )\n    parser.add_argument(\n        \"--output_filename\", \n        type=str, \n        help=\"name of file containing the trained model.\"\n    )\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_train (\n    input_folder: str,\n    input_filename: str,\n    output_folder: str,\n    output_filename: str,\n):\n    \"\"\"Reads training data, trains model, and saves it.\n    \n    Parameters\n    ----------\n    input_folder: str\n        Path to preprocessed training data folder containing training set file.\n    input_filename: str\n        Name of file containing preprocessed, training data.\n    output_folder: str\n        Path to output folder containing the trained model.\n    output_filename: str\n        Name of file containing the trained model.\n    \"\"\"\n    \n    df = pd.read_csv (f\"{input_folder}/{input_filename}\", index_col=0)\n    model = train_model (df)\n    joblib.dump (model, f\"{output_folder}/{output_filename}\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_train (\n        args.input_folder, \n        args.input_filename,\n        args.output_folder,\n        args.output_filename,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting training/training.py\n\n\n\n# Component definition and registration\ntraining_command = command(\n    inputs=dict(\n        input_folder=Input (type=\"uri_folder\"),\n        input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py \"\n        \"--input_folder ${{inputs.input_folder}} \"\n        \"--input_filename ${{inputs.input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\n\ntraining_component = ml_client.create_or_update(training_command.component)\n\nUploading training (0.0 MBs): 100%|██████████| 2309/2309 [00:00&lt;00:00, 50917.16it/s]\n\n\n\n\n\n\n\n\n%%writefile inference/inference.py\nimport argparse\nfrom typing import Tuple\nimport joblib\nimport pandas as pd\nfrom sklearn.metrics import DistanceMetric\nimport numpy as np\n\ndef inference (\n    model: Tuple[np.ndarray, np.ndarray], \n    df: pd.DataFrame,\n):\n    \"\"\"Runs dummy inference on new data `df`.\n\n    Parameters\n    ----------\n    model: Tople (np.ndarray, np.ndarray)\n        Average across rows (one per column), and \n        standard deviation across rows (one per column).\n    df: DataFrame\n        Test data frame on which to perform inference.\n    \n    Returns\n    -------\n    DataFrame\n        One column dataframe giving an approximation of the Mahalanobis distance \n        between each row vector and the mean vector, assuming that the covariance \n        matrix is diagonal. The negative of the scores obtained can be considered \n        as a sort of prediction probability for each row of belonging to the Gaussian \n        class estimated from the training data. In this sense this function provides\n        inference about how \"normal\" the test samples are. \n    \"\"\"\n    (mu, std) = model\n    dist = DistanceMetric.get_metric('mahalanobis', V=np.diag(std**2))\n    ndims = df.shape[1]\n    mah_dist = dist.pairwise (mu.reshape(1, ndims), df)\n    mah_dist = pd.DataFrame (mah_dist.ravel(), columns=[\"distance\"])\n    print (\"Inference result:\")\n    print (mah_dist)\n    return mah_dist\n\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--preprocessed_input_folder\", \n        type=str, \n        help=\"path to input, preprocessed, test data folder, \"\n             \"containing file on which to perform inference.\"\n    )\n    parser.add_argument(\n        \"--preprocessed_input_filename\", \n        type=str, \n        help=\"name of file containing the input, preprocessed, test data.\"\n    )\n    parser.add_argument(\n        \"--model_input_folder\", \n        type=str, \n        help=\"path to model folder.\"\n    )\n    parser.add_argument(\n        \"--model_input_filename\", \n        type=str, \n        help=\"name of model file.\"\n    )\n    parser.add_argument(\n        \"--output_folder\", \n        type=str, \n        help=\"path to output data *folder* with inference results.\"\n    )\n    parser.add_argument(\n        \"--output_filename\", \n        type=str, \n        help=\"name of file containing the output data with inference results.\"\n    )\n    \n    args = parser.parse_args()\n\n    args = parser.parse_args()\n    \n    return args\n\ndef read_and_inference (\n    preprocessed_input_folder: str,\n    preprocessed_input_filename: str,\n    model_input_folder: str,\n    model_input_filename: str,\n    output_folder: str,    \n    output_filename: str,\n):\n    \"\"\"\n    Reads test data and model, performs inference, and writes to output inference file.\n    \n    Parameters\n    ----------\n    preprocessed_input_folder: str\n        Path to test (preprocessed) data folder.\n    preprocessed_input_filename: str\n        Name of test data file.\n    model_input_folder: str\n        Path to built model folder.\n    model_input_filename: str\n        Path to inference result folder.\n    output_folder: str\n        Path to output data folder with inference results.\n    output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    df = pd.read_csv (f\"{preprocessed_input_folder}/{preprocessed_input_filename}\", index_col=0)\n    model = joblib.load (f\"{model_input_folder}/{model_input_filename}\")\n    z_df = inference (model, df)\n    z_df.to_csv (f\"{output_folder}/{output_filename}\")\n\ndef main():\n    \"\"\"Main function of the script.\"\"\"\n    \n    args = parse_args ()\n    read_and_inference (\n        preprocessed_input_folder=args.preprocessed_input_folder,\n        preprocessed_input_filename=args.preprocessed_input_filename,\n        model_input_folder=args.model_input_folder,\n        model_input_filename=args.model_input_filename,\n        output_folder=args.output_folder,\n        output_filename=args.output_filename,\n    )\n\nif __name__ == \"__main__\":\n    main()\n\nOverwriting inference/inference.py\n\n\n\ninference_command = command(\n    inputs=dict(\n        preprocessed_input_folder=Input (type=\"uri_folder\"),\n        preprocessed_input_filename=Input (type=\"string\"),\n        model_input_folder=Input (type=\"uri_folder\"),\n        model_input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n        \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n        \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n        \"--model_input_folder ${{inputs.model_input_folder}} \"\n        \"--model_input_filename ${{inputs.model_input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}} \",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\nUploading inference (0.0 MBs): 100%|██████████| 4046/4046 [00:00&lt;00:00, 151355.71it/s]\n\n\n\n\n\n\n\nBefore submitting the pipeline job, it is very important to test it first, ideally with some dummy or small dataset. For this purpose, in the component implementation above, we have separated the code related with argument parsing and the rest of the code, which is in encapsulated in a function called read_and_&lt;...&gt;. This way, we can easily write a test pipeline before implementing the final one, as follows:\n\n# We will need to change the code as we iteratively refine it \n# while testing the pipeline. For that purpose, we use the \n# reload module\nfrom importlib import reload \nfrom preprocessing import preprocessing\nfrom training import training\nfrom inference import inference\n\nreload (preprocessing)\nreload (training)\nreload (inference)\n\ndef test_pipeline (\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_folder: str, # Not present in final pipeline\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_folder: str, # Not present in final pipeline\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    # input_folder: this is preprocessing_training_output_folder\n    # input_filename: this is preprocessing_training_output_filename\n    training_output_folder: str, # Not present in final pipeline\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    # preprocessed_input_folder: this is preprocessing_test_output_folder\n    # preprocessed_input_filename: this is preprocessing_test_output_filename\n    # model_input_folder: this is training_output_folder\n    # model_input_filename: this is training_output_filename\n    inference_output_folder: str, # Not present in final pipeline\n    inference_output_filename: str,\n):\n    \"\"\"\n    Tests third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_folder: str\n        Path to folder containing the preprocessed, training data file.\n        Not present in final pipeline.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_folder: str\n        Path to folder containing the preprocessed, test data file.\n        Not present in final pipeline.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_folder: str\n        Path to output folder containing the trained model.\n        Not present in final pipeline.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_folder: str\n        Path to output data folder with inference results.\n        Not present in final pipeline.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    \n    preprocessing.read_and_preprocess (\n        input_file=preprocessing_training_input_file,\n        output_folder=preprocessing_training_output_folder, # Not present in final component\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing.read_and_preprocess (\n        input_file=preprocessing_test_input_file,\n        output_folder=preprocessing_test_output_folder,\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training.read_and_train (\n        input_folder=preprocessing_training_output_folder,\n        input_filename=preprocessing_training_output_filename,\n        output_folder=training_output_folder,\n        output_filename=training_output_filename,\n    )\n    inference.read_and_inference (\n        preprocessed_input_folder=preprocessing_test_output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_output_folder,\n        model_input_filename=training_output_filename,\n        output_folder=inference_output_folder,\n        output_filename=inference_output_filename,\n    )\n\nos.makedirs (\"test_pipeline\", exist_ok=True)\n\ntest_pipeline (\n    # first preprocessing component\n    preprocessing_training_input_file=\"./data/dummy_input.csv\",\n    preprocessing_training_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    preprocessing_training_output_filename=\"preprocessed_data.csv\",\n    x=10,\n    \n    # second preprocessing component\n    preprocessing_test_input_file=\"./data/dummy_test.csv\",\n    preprocessing_test_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    preprocessing_test_output_filename=\"preprocessed_test.csv\",\n    \n    # Training component parameters:\n    training_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    training_output_filename=\"model.pk\",\n    \n    # Inference component parameters:\n    inference_output_folder=\"./test_pipeline\", # Not present in final pipeline\n    inference_output_filename=\"inference_result.csv\",\n)\n\nInput\n    a  b\n0  1  4\n1  2  5\n2  3  6\nAdding 10 to df\nOutput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nInput\n       a     b\n0  11.0  14.1\n1  12.1  15.1\n2  13.1  16.1\nAdding 10 to df\nOutput\n       a     b\n0  21.0  24.1\n1  22.1  25.1\n2  23.1  26.1\nInput\n     a   b\n0  11  14\n1  12  15\n2  13  16\nmu:\n [12. 15.]\nstd:\n [1. 1.]\nInference result:\n    distance\n0  12.798828\n1  14.283557\n2  15.697771\n\n\n\n\n\n\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \nthree_components_pipeline = three_components_pipeline(\n    # first preprocessing component\n    preprocessing_training_input_file=Input(type=\"uri_file\", path=\"./data/dummy_input.csv\"),\n    preprocessing_training_output_filename=\"preprocessed_training_data.csv\",\n    x=10,\n    \n    # second preprocessing component\n    preprocessing_test_input_file=Input(type=\"uri_file\", path=\"./data/dummy_test.csv\"),\n    preprocessing_test_output_filename=\"preprocessed_test_data.csv\",\n    \n    # Training component parameters:\n    training_output_filename=\"model.pk\",\n    \n    # Inference component parameters:\n    inference_output_filename=\"inference_results.csv\",\n)\n\nthree_components_pipeline_job = ml_client.jobs.create_or_update(\n    three_components_pipeline,\n    # Project's name\n    experiment_name=\"e2e_three_components_refactored\",\n)\n\n# ----------------------------------------------------\n# Pipeline running\n# ----------------------------------------------------\nml_client.jobs.stream(three_components_pipeline_job.name)\n\nRunId: blue_sugar_ns1v5dpj4c\nWeb View: https://ml.azure.com/runs/blue_sugar_ns1v5dpj4c?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-03-29 09:00:10Z] Completing processing run id 2319106a-3802-4727-8e58-c347521ab38f.\n[2024-03-29 09:00:10Z] Completing processing run id caf9c677-ff96-4cd8-ac83-0439f16bc635.\n[2024-03-29 09:00:11Z] Completing processing run id 3c7a3956-de79-4e6c-90d1-e012ed8ccaa8.\n[2024-03-29 09:00:12Z] Submitting 1 runs, first five are: eeca7330:4a267c73-32ee-451d-9d53-b144842236ee\n[2024-03-29 09:00:52Z] Completing processing run id 4a267c73-32ee-451d-9d53-b144842236ee.\n\nExecution Summary\n=================\nRunId: blue_sugar_ns1v5dpj4c\nWeb View: https://ml.azure.com/runs/blue_sugar_ns1v5dpj4c?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\nHere we can see the resulting pipeline:"
  },
  {
    "objectID": "posts/data_science/hello_world.html#putting-everything-into-a-script",
    "href": "posts/data_science/hello_world.html#putting-everything-into-a-script",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "Let’s see how to put all the code needed for creating a pipeline into a script.\n\n\n\n%%writefile pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \n    \"training_output_filename\": \"model.pk\",\n    \n    \"inference_output_filename\": \"inference_results.csv\",\n\n    \"experiment_name\": \"e2e_three_components_in_script\"\n}\n\nWriting pipeline_input.json\n\n\n\n\n\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\n# authenticate\ncredential = DefaultAzureCredential()\n\n# Get a handle to the workspace\nml_client = MLClient.from_config (\n    credential=credential\n)\n\n# -------------------------------------------------------------------------------------\n# Interface for each component\n# -------------------------------------------------------------------------------------\n# Preprocessing\npreprocessing_command = command(\n    inputs=dict(\n        input_file=Input (type=\"uri_file\"),\n        x=Input (type=\"number\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n    command=\"python preprocessing.py \"\n        \"--input_file ${{inputs.input_file}} \"\n        \"-x ${{inputs.x}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Pre-processing\",\n)\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n# Training\ntraining_command = command(\n    inputs=dict(\n        input_folder=Input (type=\"uri_folder\"),\n        input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./training/\",  # location of source code: in this case, the root folder\n    command=\"python training.py \"\n        \"--input_folder ${{inputs.input_folder}} \"\n        \"--input_filename ${{inputs.input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}}\",\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"Training\",\n)\ntraining_component = ml_client.create_or_update(training_command.component)\n\n# Inference\ninference_command = command(\n    inputs=dict(\n        preprocessed_input_folder=Input (type=\"uri_folder\"),\n        preprocessed_input_filename=Input (type=\"string\"),\n        model_input_folder=Input (type=\"uri_folder\"),\n        model_input_filename=Input (type=\"string\"),\n        output_filename=Input (type=\"string\"),\n    ),\n    outputs=dict(\n        output_folder=Output (type=\"uri_folder\"),\n    ),\n    code=f\"./inference/\",  # location of source code: in this case, the root folder\n    command=\"python inference.py \" \n        \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n        \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n        \"--model_input_folder ${{inputs.model_input_folder}} \"\n        \"--model_input_filename ${{inputs.model_input_filename}} \"\n        \"--output_folder ${{outputs.output_folder}} \"\n        \"--output_filename ${{inputs.output_filename}} \",\n\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    display_name=\"inference\",\n)\ninference_component = ml_client.create_or_update(inference_command.component)\n\n# -------------------------------------------------------------------------------------\n# Pipeline definition\n# -------------------------------------------------------------------------------------\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    # using data_prep_function like a python call with its own inputs\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object. This is a \n    # sub-class of dict which allows to get access to fields \n    # as object attributes (a bit more convenient IMO) in addition \n    # to also allowing the dict syntax.\n    config = Bunch (**config)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    three_components_pipeline_job = ml_client.jobs.create_or_update(\n        three_components_pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(three_components_pipeline_job.name)\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py\n\n\nBad pipe message: %s [b'1~\\xd1B\\xe9k\\xf8\\x8beF\\x0bi8_~\\n\\xa2F \\xfec\\x82\\xc3\\xb3^P&\\xb5A\\xd2\\xbb\\xa6\\xb1\\xc5\\xef\\x04\\xb7C\\xa9\\xeb\\xb2U\\xed\\x81\\x80M\\x05\\xf7\\x85H\\xc8\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\nBad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\nBad pipe message: %s [b\"\\xcd\\xe4\\xaew\\x91`\\x94\\xc6fO\\xea\\x92 \\xc7b\\xb15G\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00&lt;\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\", b'\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b'\\x0b\"a7\\xfa\\xa1#\\xf3\\x88\\xcc%\\xae\\xb45\\xbc\\xdbY\\xb8\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0\\'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00&lt;\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00']\nBad pipe message: %s [b'\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e']\nBad pipe message: %s [b'7\\x992kK\\xc1\\xdbF\\x8b\\xb1\\xe1l\\x19\\xbfA&lt;\\x1fc\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02']\nBad pipe message: %s [b'\\xcf\\xf4\\xe1\\xe6\\xec\\xa7$\\x0f\\x95\\xd8\\xe3X\\xfcm\\x93\\xc2\\x06?\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00', b'\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12']\nBad pipe message: %s [b'Nv\\xa8\\xf4\\x13\\xe0t\\x12q\\xe1\\xb8\\xa4\\xe0(\\xaflvv']\nBad pipe message: %s [b'\\xd5\\xc3({`3.\\xe2\\xad\\xa8.6\\x01\\xe9\\xb4\\x06\\xba\\xb1\\x00\\x00&gt;\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x15\\x03\\x00']\nBad pipe message: %s [b\"\\xa7\\xe2\\x12\\x89\\xeaUh\\xb9\\x1a\\xc3\\x92\\x85\\x1f\\xd4\\xf7\\xaf\\xb4\\xcd\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\", b'\\x03\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\nBad pipe message: %s [b'\\xc7\\x95X[|\\x00\\xb9,o\\xa7\\x95\\xdd\\xee\\xd3A\\xd2g\\x06\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00', b\":\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00&gt;\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00&lt;\\x00/\\x00\\x96\\x00\"]\nBad pipe message: %s [b'\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00']\nBad pipe message: %s [b'\\x10\\xc0']\nBad pipe message: %s [b'\\x15\\xc0\\x0b\\xc0\\x01']\n\n\nWe can now run the script from command line:\nFirst we open up a terminal and activate a conda environment that uses the python SDK version 2. Let’s see what environments we currently have:\nconda env list\nAs of now, this provides the following list:\n# conda environments:\n#\nbase                     /anaconda\nazureml_py310_sdkv2      /anaconda/envs/azureml_py310_sdkv2\nazureml_py38          *  /anaconda/envs/azureml_py38\nazureml_py38_PT_TF       /anaconda/envs/azureml_py38_PT_TF\njupyter_env              /anaconda/envs/jupyter_env\nFrom that list, the conda environment using SDK v2 is azureml_py310_sdkv2 (use another if that changes when you read this)\nWe activate it and run our script:\nconda activate azureml_py310_sdkv2\npython hello_world_pipeline.py\n\n\n\nLet’s introduce two optional changes:\n\nInstead of defining the preprocessing_command, training_command and inference_command out of the pipeline function, we will define them inside.\nWe will avoid creating the components beforehand, by not calling ml_client.create_or_update (my_component_command.component), as it was done for example here:\n\npreprocessing_component = ml_client.create_or_update(preprocessing_command.component)\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\ndef connect ():\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n# -------------------------------------------------------------------------------------\n# Pipeline definition\n# -------------------------------------------------------------------------------------\n@dsl.pipeline(\n    compute=\"serverless\",  # \"serverless\" value runs pipeline on serverless compute\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n    \n    print (\n        \"Running hello-world pipeline with args\", \n        preprocessing_training_input_file,\n        preprocessing_training_output_filename,\n        x,\n        preprocessing_test_input_file,\n        preprocessing_test_output_filename,\n        training_output_filename,\n        inference_output_filename,\n        sep=\"\\n\",\n    )\n    \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./training/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./inference/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object.\n    # This allows to get access to fields as object attributes\n    # Which I find more convenient.\n    config = Bunch (**config)\n\n    # Connect to AML client\n    ml_client = connect ()\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    three_components_pipeline_job = ml_client.jobs.create_or_update(\n        three_components_pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(three_components_pipeline_job.name)\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py"
  },
  {
    "objectID": "posts/data_science/hello_world.html#indicating-environment-and-compute-instance",
    "href": "posts/data_science/hello_world.html#indicating-environment-and-compute-instance",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "So far we have been using a serverless compute, where Azure automatically creates the compute instances needed for running the pipeline, scaling and deleting them as required. More information can be found here. In this section we opt to use a specific compute instance. This has some advantages: while the serveless mode can shut down our compute when idle, and needs to start it again when new loads arrive, with a compute instance we can ensure that the instance is always running and the functions loaded, which may be important in time critical situations. More information can be found here.\nIn addition to this change, we will also us make the code a bit more modular and reusable. We do so by: - Indicating custom environments that can be adapted to different requirements. - Defining different functions that: - Connect to the AML workspace. - Create the environment. - Create the pipeline. - Set up and run the created pipeline.\nWe will separate the functions into two different files: an aml_utils.py module where we include functions that can be reused across different pipelines, and a hello_world.py script where we have code specific for our “Hello World” pipeline.\nLet us start with the aml_utils.py file. We will be writing the consecutive functions one after the other, appending them together with the magic command %%writefile -a aml_utils.py, which appends when we pass the flag -a.\n\n\n\n\nWe start with the imports:\n\n%%writefile aml_utils.py\n# Standard imports\nimport json\n\n# Third-party imports\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import MLClient\nfrom azure.ai.ml.entities import Environment\nfrom azure.identity import DefaultAzureCredential\n\n\nOverwriting aml_utils.py\n\n\n\n\n\nWe encapsulate the code for connecting to AML in a separate function, which we append to the previous code:\n\n%%writefile -a aml_utils.py\ndef connect ():\n    \"\"\"Connects to Azure ML workspace and returns a handle to use it.\"\"\"\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n\nAppending to aml_utils.py\n\n\n\n\n\nUntil now, we have been using environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\" when defining our component interfaces with the command function. This is one of the environments alreadyt available in the Azure ML studio, and it allows us to use scikit-learn as well as azure ml libraries on a ubuntu20.0.04 OS. Let us create a custom environment instead:\n\n%%writefile hello_world.yml\nname: hello-world\ndependencies:\n- python=3.10\n- pip\n- pandas\n- numpy\n- pip:\n  - scikit-learn\n  - joblib\n  - azure-ai-ml\n\nOverwriting hello_world.yml\n\n\nAvailable docker images can be found here. With this, we can define our envioroment as follows:\n\n%%writefile -a aml_utils.py\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"Creates environment in AML workspace\"\n    env = Environment (\n        image=image,\n        conda_file=conda_file,\n        name=name_env,\n        description=description_env,\n    )\n    ml_client.environments.create_or_update (env)\n\n    \n\nAppending to aml_utils.py\n\n\nAfter this, we can replace the name of our environment in the command functions that we will use belowfor defining the interface of each component, for instance as follows:\npreprocessing_component = command(\n    ...\n    environment=\"hello-world@latest\",\n    ...\n)\n\n\n\nThe compute instance can be indicated with just one line of code, which will be included in the function described in next subsection, called connect_setup_and_run:\n# change this with the name of your compute instance in AML\npipeline.settings.default_compute = \"my-compute-instance\" \nWe will also need to remove the argument compute=\"serverless\" from the pipeline decorator, as we will see below when we define our pipeline function.\n\n\n\nWe now define a connect_setup_and_run where we put all the necessary code for setting up and running any pipeline previously created. The function also connects to the AML workspace by calling connect above:\n\n%%writefile -a aml_utils.py\ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\n\nAppending to aml_utils.py\n\n\n\n\n\nFinally, we will write a helper function that reads the configuration from a json file and converts the resulting dictionary into a Bunch object. The Bunch class inherits from the standard dict class, and allows to get access to each dictionary field as if it was an object attribute. It also allows to get access to the dict fields in the standard way. For instance, both:\nx = my_bunch.my_field\nmy_bunch.my_field = x+1\nand\nx = my_bunch[\"my_field\"]\nmy_bunch[\"my_field\"] = x + 1\nare equivalent.\nHere is the resulting read_config function:\n\n%%writefile -a aml_utils.py\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    config = Bunch (**config)\n\n    return config\n\nAppending to aml_utils.py\n\n\n\n\n\n\nIn this section, we use a config file that is the same as the one in the previous section (“Putting everything into a script”), but adding the following parameters:\n    \"compute_name\": \"jaumecpu\",\n    \"image\" = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\"=\"./hello_world.yml\",\n    \"description_env\"=\"Hello World\"   \nThe added parameters indicate the compute instance and environment details. The final config file is as follows:\n\n%%writefile pipeline_input.json\n{\n    \"preprocessing_training_input_file\": \"./data/dummy_input.csv\",\n    \"preprocessing_training_output_filename\":\"preprocessed_training_data.csv\",\n    \"x\": 10,\n    \"preprocessing_test_input_file\": \"./data/dummy_test.csv\",\n    \"preprocessing_test_output_filename\": \"preprocessed_test_data.csv\",\n    \"training_output_filename\": \"model.pk\",\n    \"inference_output_filename\": \"inference_results.csv\",\n    \"experiment_name\": \"e2e_three_components_in_script\",\n    \"compute_name\": \"jaumecpu\",\n    \"image\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    \"conda_file\": \"./hello_world.yml\",\n    \"name_env\": \"hello-world\",\n    \"description_env\": \"Hello World\"\n}\n\nOverwriting pipeline_input.json\n\n\n\n\n\nLet us know write the functions that are specific for our current pipeline. We do so in the script that we will be running from command line, hello_world_pipeline.py.\n\n\nLet us start again with the imports section:\n\n%%writefile hello_world_pipeline.py\n# Standard imports\nimport argparse\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n)\n\n# Utility functions\nfrom aml_utils import (\n    connect,\n    create_env,\n    connect_setup_and_run,\n    read_config,\n)\n\n\n\n\n\nWe write next our pipeline function, which indicates the components to be used and how they are connected throug inputs and outputs. The only change with respect to previous pipeline functions is that we indicate as environment the one we just created, “hello-world”, when we describe each component through the command function. The rest doesn’t change.\n\n%%writefile -a hello_world_pipeline.py\n@dsl.pipeline(\n    description=\"E2E hello world pipeline with input\",\n)\ndef three_components_pipeline(\n    # Preprocessing component parameters, first component:\n    preprocessing_training_input_file: str,\n    preprocessing_training_output_filename: str,\n    x: int,\n    \n    # Preprocessing component parameters, second component:\n    preprocessing_test_input_file: str,\n    preprocessing_test_output_filename: str,\n    \n    # Training component parameters:\n    training_output_filename: str, \n    \n    # Inference component parameters:\n    inference_output_filename: str,\n):\n    \"\"\"\n    Third pipeline: preprocessing, training and inference.\n    \n    Parameters\n    ----------\n    preprocessing_training_input_file: str\n        Path to file containing training data to be preprocessed.\n    preprocessing_training_output_filename: str\n        Name of file containing the preprocessed, training data.\n    x: int\n        Number to add to input data for preprocessing it.\n    preprocessing_test_input_file: str\n        Path to file containing test data to be preprocessed.\n    preprocessing_test_output_filename: str\n        Name of file containing the preprocessed, test data.\n    training_output_filename: str\n        Name of file containing the trained model.\n    inference_output_filename: str\n        Name of file containing the output data with inference results.\n    \"\"\"\n        \n    # -------------------------------------------------------------------------------------\n    # Preprocessing\n    # -------------------------------------------------------------------------------------\n    # Interface\n    preprocessing_component = command(\n        inputs=dict(\n            input_file=Input (type=\"uri_file\"),\n            x=Input (type=\"number\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n        command=\"python preprocessing.py \"\n            \"--input_file ${{inputs.input_file}} \"\n            \"-x ${{inputs.x}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Pre-processing\",\n    )\n\n    # Instantiation\n    preprocessing_training_job = preprocessing_component(\n        input_file=preprocessing_training_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_training_output_filename,\n        x=x,\n    )\n    preprocessing_test_job = preprocessing_component(\n        input_file=preprocessing_test_input_file,\n        #output_folder: automatically determined\n        output_filename=preprocessing_test_output_filename,\n        x=x,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Training component\n    # -------------------------------------------------------------------------------------\n    # Interface\n    training_component = command(\n        inputs=dict(\n            input_folder=Input (type=\"uri_folder\"),\n            input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./training/\",  # location of source code: in this case, the root folder\n        command=\"python training.py \"\n            \"--input_folder ${{inputs.input_folder}} \"\n            \"--input_filename ${{inputs.input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}}\",\n        environment=\"hello-world@latest\",\n        display_name=\"Training\",\n    )\n\n    # Instantiation\n    training_job = training_component(\n        input_folder=preprocessing_training_job.outputs.output_folder,\n        input_filename=preprocessing_training_output_filename,\n        #output_folder: automatically determined\n        output_filename=training_output_filename,\n    )\n\n    # -------------------------------------------------------------------------------------\n    # Inference\n    # -------------------------------------------------------------------------------------\n    # Interface\n    inference_component = command(\n        inputs=dict(\n            preprocessed_input_folder=Input (type=\"uri_folder\"),\n            preprocessed_input_filename=Input (type=\"string\"),\n            model_input_folder=Input (type=\"uri_folder\"),\n            model_input_filename=Input (type=\"string\"),\n            output_filename=Input (type=\"string\"),\n        ),\n        outputs=dict(\n            output_folder=Output (type=\"uri_folder\"),\n        ),\n        code=f\"./inference/\",  # location of source code: in this case, the root folder\n        command=\"python inference.py \" \n            \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n            \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n            \"--model_input_folder ${{inputs.model_input_folder}} \"\n            \"--model_input_filename ${{inputs.model_input_filename}} \"\n            \"--output_folder ${{outputs.output_folder}} \"\n            \"--output_filename ${{inputs.output_filename}} \",\n\n        environment=\"hello-world@latest\",\n        display_name=\"inference\",\n    )\n\n    # Instantiation\n    inference_job = inference_component(\n        preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n        preprocessed_input_filename=preprocessing_test_output_filename,\n        model_input_folder=training_job.outputs.output_folder,\n        model_input_filename=training_output_filename,\n        #output_folder: automatically determined\n        output_filename=inference_output_filename,\n    )\n    \n\n\n\n\nNext we define a function that both creates and runs the pipeline implemented above. This function performs all the steps implemented so far: it reads a config file, instantiates a pipeline object by calling our three_components_pipeline function, and finally performs the pipeline set-up and runs it by calling connect_setup_and_run:\n\n%%writefile -a hello_world_pipeline.py\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n\n        # name env:\n        name_env=config.name_env,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n    )\n    \n\nOverwriting hello_world_pipeline.py\n\n\n\n\n\nNext, we define a function for parsing the command line arguments:\n\n%%writefile -a hello_world_pipeline.py\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n\n\n\n\nAnd finally, we write our main function which simply calls the argument parser and calls run_pipeline with the parsed arguments:\n\n%%writefile -a hello_world_pipeline.py\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nThis is how the pipeline can be run from ipython, and similarly from the command line:\n\n%run hello_world_pipeline.py\n\nFound the config file in: /config.json\nClass AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\n\nRunning hello-world pipeline with args Namespace(config_path='pipeline_input.json', experiment_name='hello-world-experiment')\nRunId: good_brain_fqtwt959vf\nWeb View: https://ml.azure.com/runs/good_brain_fqtwt959vf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-10 09:06:04Z] Submitting 2 runs, first five are: 56673d93:0ab3c91a-266e-42d1-964b-af6cd9a5a8a9,9dc0f6c7:2a6af947-815b-4014-951e-0a66d370a79b\n[2024-04-10 09:07:08Z] Completing processing run id 0ab3c91a-266e-42d1-964b-af6cd9a5a8a9.\n[2024-04-10 09:07:08Z] Completing processing run id 2a6af947-815b-4014-951e-0a66d370a79b.\n[2024-04-10 09:07:08Z] Submitting 1 runs, first five are: 20670901:7fc64bfc-bee0-4238-be3d-fbd26f2304b6\n[2024-04-10 09:07:30Z] Completing processing run id 7fc64bfc-bee0-4238-be3d-fbd26f2304b6.\n[2024-04-10 09:07:30Z] Submitting 1 runs, first five are: 11635808:7d181008-9749-4ba0-8af0-ee22a9a90a1f\n[2024-04-10 09:07:52Z] Completing processing run id 7d181008-9749-4ba0-8af0-ee22a9a90a1f.\n\nExecution Summary\n=================\nRunId: good_brain_fqtwt959vf\nWeb View: https://ml.azure.com/runs/good_brain_fqtwt959vf?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld"
  },
  {
    "objectID": "posts/data_science/hello_world.html#with-closure",
    "href": "posts/data_science/hello_world.html#with-closure",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "We add the following to our config file:\n    \"name_env\"=\"hello-world\",\n\n%%writefile hello_world_pipeline.py\n# -------------------------------------------------------------------------------------\n# Imports\n# -------------------------------------------------------------------------------------\n# Standard imports\nimport os\nimport argparse\nimport json\n\n# Third-party imports\nimport pandas as pd\nfrom sklearn.utils import Bunch\n\n# AML imports\nfrom azure.ai.ml import (\n    command,\n    dsl,\n    Input,\n    Output,\n    MLClient\n)\nfrom azure.ai.ml.entities import Environment\nfrom azure.identity import DefaultAzureCredential\n\n# -------------------------------------------------------------------------------------\n# Connection\n# -------------------------------------------------------------------------------------\ndef connect ():\n    # authenticate\n    credential = DefaultAzureCredential()\n\n    # Get a handle to the workspace\n    ml_client = MLClient.from_config (\n        credential=credential,\n    )\n    return ml_client\n\n# -------------------------------------------------------------------------------------\n# environment\n# -------------------------------------------------------------------------------------\ndef create_env (\n    ml_client,\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"Creates environment in AML workspace\"\n    env = Environment (\n        image=image,\n        conda_file=conda_file,\n        name=name_env,\n        description=description_env,\n    )\n    ml_client.environments.create_or_update (env)\n\n# -------------------------------------------------------------------------------------\n# connect and setup\n# -------------------------------------------------------------------------------------\ndef connect_setup_and_run (\n    pipeline_object, \n    experiment_name: str=\"pipeline experiment\",\n    compute_name: str=\"jaumecpu\",\n    image: str=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file: str=\"./pipeline.yml\",\n    name_env: str=\"pipeline\",\n    description_env: str=\"Pipeline environment\",\n):\n    \"\"\"Does all the setup required to run the pipeline.\n    \n    This includes: connecting, creating environment, indicating our compute instance,\n    creating and running the pipeline.\n    \"\"\"\n    # connect\n    ml_client = connect ()\n\n    # create env\n    create_env (\n        ml_client,\n        image=image,\n        conda_file=conda_file,\n        name_env=name_env,\n        description_env=description_env,\n    )\n\n    # compute\n    pipeline_object.settings.default_compute = compute_name \n\n    # create pipeline and run\n    pipeline_job = ml_client.jobs.create_or_update(\n        pipeline_object,\n        # Project's name\n        experiment_name=experiment_name,\n    )\n\n    # ----------------------------------------------------\n    # Pipeline running\n    # ----------------------------------------------------\n    ml_client.jobs.stream(pipeline_job.name)\n\ndef read_config (config_path: str):\n    # Read config json file\n    with open (config_path,\"rt\") as config_file:\n        config = json.load (config_file)\n\n    # Convert config dictionary into a Bunch object.\n    # This allows to get access to fields as object attributes\n    # Which I find more convenient.\n    config = Bunch (**config)\n\n    return config\n\n# -------------------------------------------------------------------------------------\n# Pipeline running\n# -------------------------------------------------------------------------------------\ndef run_pipeline (\n    config_path: str=\"./pipeline_input.json\",\n    experiment_name=\"hello-world-experiment\",\n):\n    # read config\n    config = read_config (config_path)\n    \n    # Pipeline definition\n    @dsl.pipeline(\n        description=\"E2E hello world pipeline with input\",\n    )\n    def three_components_pipeline(\n        # Preprocessing component parameters, first component:\n        preprocessing_training_input_file: str,\n        preprocessing_training_output_filename: str,\n        x: int,\n\n        # Preprocessing component parameters, second component:\n        preprocessing_test_input_file: str,\n        preprocessing_test_output_filename: str,\n\n        # Training component parameters:\n        training_output_filename: str, \n\n        # Inference component parameters:\n        inference_output_filename: str,\n    ):\n        \"\"\"\n        Third pipeline: preprocessing, training and inference.\n\n        Parameters\n        ----------\n        preprocessing_training_input_file: str\n            Path to file containing training data to be preprocessed.\n        preprocessing_training_output_filename: str\n            Name of file containing the preprocessed, training data.\n        x: int\n            Number to add to input data for preprocessing it.\n        preprocessing_test_input_file: str\n            Path to file containing test data to be preprocessed.\n        preprocessing_test_output_filename: str\n            Name of file containing the preprocessed, test data.\n        training_output_filename: str\n            Name of file containing the trained model.\n        inference_output_filename: str\n            Name of file containing the output data with inference results.\n        name_env: str\n            Name of environment to use.\n        \"\"\"\n\n        print (f\"using {config.name_env}@latest\")\n        \n        # -------------------------------------------------------------------------------------\n        # Preprocessing\n        # -------------------------------------------------------------------------------------\n        # Interface\n        preprocessing_component = command(\n            inputs=dict(\n                input_file=Input (type=\"uri_file\"),\n                x=Input (type=\"number\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./preprocessing/\",  # location of source code: in this case, the root folder\n            command=\"python preprocessing.py \"\n                \"--input_file ${{inputs.input_file}} \"\n                \"-x ${{inputs.x}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}}\",\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"Pre-processing\",\n        )\n\n        # Instantiation\n        preprocessing_training_job = preprocessing_component(\n            input_file=preprocessing_training_input_file,\n            #output_folder: automatically determined\n            output_filename=preprocessing_training_output_filename,\n            x=x,\n        )\n        preprocessing_test_job = preprocessing_component(\n            input_file=preprocessing_test_input_file,\n            #output_folder: automatically determined\n            output_filename=preprocessing_test_output_filename,\n            x=x,\n        )\n\n        # -------------------------------------------------------------------------------------\n        # Training component\n        # -------------------------------------------------------------------------------------\n        # Interface\n        training_component = command(\n            inputs=dict(\n                input_folder=Input (type=\"uri_folder\"),\n                input_filename=Input (type=\"string\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./training/\",  # location of source code: in this case, the root folder\n            command=\"python training.py \"\n                \"--input_folder ${{inputs.input_folder}} \"\n                \"--input_filename ${{inputs.input_filename}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}}\",\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"Training\",\n        )\n\n        # Instantiation\n        training_job = training_component(\n            input_folder=preprocessing_training_job.outputs.output_folder,\n            input_filename=preprocessing_training_output_filename,\n            #output_folder: automatically determined\n            output_filename=training_output_filename,\n        )\n\n        # -------------------------------------------------------------------------------------\n        # Inference\n        # -------------------------------------------------------------------------------------\n        # Interface\n        inference_component = command(\n            inputs=dict(\n                preprocessed_input_folder=Input (type=\"uri_folder\"),\n                preprocessed_input_filename=Input (type=\"string\"),\n                model_input_folder=Input (type=\"uri_folder\"),\n                model_input_filename=Input (type=\"string\"),\n                output_filename=Input (type=\"string\"),\n            ),\n            outputs=dict(\n                output_folder=Output (type=\"uri_folder\"),\n            ),\n            code=f\"./inference/\",  # location of source code: in this case, the root folder\n            command=\"python inference.py \" \n                \"--preprocessed_input_folder ${{inputs.preprocessed_input_folder}} \"\n                \"--preprocessed_input_filename ${{inputs.preprocessed_input_filename}} \"\n                \"--model_input_folder ${{inputs.model_input_folder}} \"\n                \"--model_input_filename ${{inputs.model_input_filename}} \"\n                \"--output_folder ${{outputs.output_folder}} \"\n                \"--output_filename ${{inputs.output_filename}} \",\n\n            environment=f\"{config.name_env}@latest\",\n            display_name=\"inference\",\n        )\n\n        # Instantiation\n        inference_job = inference_component(\n            preprocessed_input_folder=preprocessing_test_job.outputs.output_folder,\n            preprocessed_input_filename=preprocessing_test_output_filename,\n            model_input_folder=training_job.outputs.output_folder,\n            model_input_filename=training_output_filename,\n            #output_folder: automatically determined\n            output_filename=inference_output_filename,\n        )\n\n    # Build pipeline \n    three_components_pipeline_object = three_components_pipeline(\n        # first preprocessing component\n        preprocessing_training_input_file=Input(type=\"uri_file\", path=config.preprocessing_training_input_file),\n        preprocessing_training_output_filename=config.preprocessing_training_output_filename,\n        x=config.x,\n        \n        # second preprocessing component\n        preprocessing_test_input_file=Input(type=\"uri_file\", path=config.preprocessing_test_input_file),\n        preprocessing_test_output_filename=config.preprocessing_test_output_filename,\n        \n        # Training component parameters:\n        training_output_filename=config.training_output_filename,\n        \n        # Inference component parameters:\n        inference_output_filename=config.inference_output_filename,\n    )\n\n    connect_setup_and_run (\n        three_components_pipeline_object, \n        experiment_name=experiment_name,\n        compute_name=config.compute_name,\n        image=config.image,\n        conda_file=config.conda_file,\n        name_env=config.name_env,\n        description_env=config.description_env,\n    )\n\n# -------------------------------------------------------------------------------------\n# Parsing\n# -------------------------------------------------------------------------------------\ndef parse_args ():\n    \"\"\"Parses input arguments\"\"\"\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument (\n        \"--config-path\", \n        type=str, \n        default=\"pipeline_input.json\",\n        help=\"Path to config file specifying pipeline input parameters.\",\n    )\n    parser.add_argument (\n        \"--experiment-name\", \n        type=str, \n        default=\"hello-world-experiment\",\n        help=\"Name of experiment.\",\n    )\n\n    args = parser.parse_args()\n    \n    print (\"Running hello-world pipeline with args\", args)\n    \n    return args\n\n\n# -------------------------------------------------------------------------------------\n# main\n# -------------------------------------------------------------------------------------\ndef main ():\n    \"\"\"Parses arguments and runs pipeline\"\"\"\n    args = parse_args ()\n    run_pipeline (\n        args.config_path,\n        args.experiment_name,\n    )\n\n# -------------------------------------------------------------------------------------\n# -------------------------------------------------------------------------------------\nif __name__ == \"__main__\":\n    main ()\n\nOverwriting hello_world_pipeline.py\n\n\n\n%run hello_world_pipeline.py\n\nFound the config file in: /config.json\n\n\nRunning hello-world pipeline with args Namespace(config_path='pipeline_input.json', experiment_name='hello-world-experiment')\nusing hello-world@latest\nRunId: lucid_napkin_t6nkwzqqfx\nWeb View: https://ml.azure.com/runs/lucid_napkin_t6nkwzqqfx?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\nStreaming logs/azureml/executionlogs.txt\n========================================\n\n[2024-04-10 09:42:21Z] Submitting 2 runs, first five are: a13baad8:2e78988c-ec3d-42c7-ad94-54617bee7252,e9a47e09:b17a6162-ff6c-48a3-af00-becc887c58d8\n[2024-04-10 09:42:43Z] Completing processing run id 2e78988c-ec3d-42c7-ad94-54617bee7252.\n[2024-04-10 09:42:54Z] Completing processing run id b17a6162-ff6c-48a3-af00-becc887c58d8.\n[2024-04-10 09:42:55Z] Submitting 1 runs, first five are: 9e02ee11:40379116-e551-49fa-b02b-8af7678e75e4\n[2024-04-10 09:43:16Z] Completing processing run id 40379116-e551-49fa-b02b-8af7678e75e4.\n[2024-04-10 09:43:17Z] Submitting 1 runs, first five are: 01e4367a:e69290f9-ce7c-4946-a3b9-db4b0ab5ad0a\n[2024-04-10 09:43:38Z] Completing processing run id e69290f9-ce7c-4946-a3b9-db4b0ab5ad0a.\n\nExecution Summary\n=================\nRunId: lucid_napkin_t6nkwzqqfx\nWeb View: https://ml.azure.com/runs/lucid_napkin_t6nkwzqqfx?wsid=/subscriptions/6af6741b-f140-48c2-84ca-027a27365026/resourcegroups/helloworld/workspaces/helloworld\n\n\n\n\n\n\ndef mydec (f):\n    def mywrap (*args, **kwargs):\n        print (\"hello\")\n        f()\n        print (\"bye\")\n    return mywrap\n\ndef outerf ():\n    x = 3\n    @mydec\n    def myf ():\n        print (f\"myf: {x}\")\n    myf()\n\n\nouterf()\n\nhello\nmyf: 3\nbye\n\n\n\n'${{parent.inputs.name_env}}'\n\n\nfrom hello_world_pipeline import connect, create_env, read_config\n\n\nml_client = connect ()\n\nFound the config file in: /config.json\n\n\n\nconfig = read_config (\"./pipeline_input.json\")\n\n\ncreate_env (\n    ml_client, \n    config.image,\n    config.conda_file,\n    config.name_env,\n    config.description_env,\n)\n\nFound the config file in: /config.json\n\n\n\nx=ml_client.environments.get (config.name_env, version=\"1\")\n\n\nx.name\n\n'hello-world'\n\n\n\nconfig.name_env\n\n'hello-world'\n\n\n\nx.version\n\n'1'"
  },
  {
    "objectID": "posts/data_science/hello_world.html#further-refactorings",
    "href": "posts/data_science/hello_world.html#further-refactorings",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "Create more structure on config input file: one dictionary per pipeline component."
  },
  {
    "objectID": "posts/data_science/hello_world.html#next-steps",
    "href": "posts/data_science/hello_world.html#next-steps",
    "title": "Hello World AML pipeline with component",
    "section": "",
    "text": "Create components using @command_component decorator, see https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python?view=azureml-api-2#create-components-for-building-pipeline"
  }
]